[0m01:21:45.262121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65b04aeb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65ae313d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65ae3123d0>]}


============================== 01:21:45.277368 | e2e9901d-4459-4ad0-844b-a2edca8161e4 ==============================
[0m01:21:45.277368 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:21:45.280266 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt deps', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:21:45.524093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e2e9901d-4459-4ad0-844b-a2edca8161e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65ae306710>]}
[0m01:21:45.530380 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:21:45.537052 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:21:45.540910 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.64927983, "process_user_time": 15.202888, "process_kernel_time": 0.780661, "process_mem_max_rss": "104848", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:21:45.543955 [debug] [MainThread]: Command `dbt deps` succeeded at 01:21:45.543435 after 0.65 seconds
[0m01:21:45.546886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65ae162f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65ae162dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65ae4f1ed0>]}
[0m01:21:45.549551 [debug] [MainThread]: Flushing usage events
[0m01:21:52.277095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa851882dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa851882c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa851883550>]}


============================== 01:21:52.292791 | 6e03eddc-f457-4821-b3c8-4e92ae2de738 ==============================
[0m01:21:52.292791 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:21:52.296586 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt snapshot', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:21:52.819509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa85131cb50>]}
[0m01:21:53.062178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa85188e350>]}
[0m01:21:53.066847 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:21:53.108716 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:21:53.123515 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m01:21:53.125938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8512e8f90>]}
[0m01:21:56.477357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8507e6610>]}
[0m01:21:56.543567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa84fbb64d0>]}
[0m01:21:56.546348 [info ] [MainThread]: Found 4 models, 1 snapshot, 11 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:21:56.549029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa84ff6ae50>]}
[0m01:21:56.557684 [info ] [MainThread]: 
[0m01:21:56.563854 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:21:56.570429 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:21:56.610716 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:21:56.614745 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:21:56.616890 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:21:56.650697 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m01:21:56.657948 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:21:56.664817 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m01:21:56.668021 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m01:21:56.689780 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m01:21:56.692065 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m01:21:56.694840 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:21:56.709578 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:21:56.713271 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m01:21:56.715108 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m01:21:56.719361 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m01:21:56.722715 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m01:21:56.724494 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m01:21:56.726202 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m01:21:56.736763 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m01:21:56.739356 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m01:21:56.745590 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_snapshots)
[0m01:21:56.747607 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:21:56.749766 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:21:56.757129 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:21:56.766833 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:21:56.777142 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:21:56.782929 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:21:56.790145 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:21:56.791621 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:21:56.793395 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:21:56.795190 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:21:56.797135 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:21:56.798638 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:21:56.800335 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:21:56.801703 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:21:56.803346 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:21:56.818038 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:21:56.819182 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:21:56.820883 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:21:56.821644 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:21:56.823748 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:21:56.824603 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:21:56.826251 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:21:56.838618 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:21:56.840533 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:21:56.842376 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:21:56.844370 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:21:56.849744 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:21:56.870544 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m01:21:56.871625 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:21:56.872578 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:21:56.873504 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:21:56.877995 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:21:56.882856 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:21:56.887223 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:21:56.891673 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:21:56.893905 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:21:56.895293 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:21:56.897106 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:21:56.899348 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:21:56.923827 [debug] [MainThread]: Using postgres connection "master"
[0m01:21:56.926274 [debug] [MainThread]: On master: BEGIN
[0m01:21:56.928256 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:21:56.942916 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:21:56.945005 [debug] [MainThread]: Using postgres connection "master"
[0m01:21:56.946910 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:21:56.962190 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:21:56.967019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa84ff587d0>]}
[0m01:21:56.969259 [debug] [MainThread]: On master: ROLLBACK
[0m01:21:56.971470 [debug] [MainThread]: Using postgres connection "master"
[0m01:21:56.973228 [debug] [MainThread]: On master: BEGIN
[0m01:21:56.975753 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:21:56.977428 [debug] [MainThread]: On master: COMMIT
[0m01:21:56.979269 [debug] [MainThread]: Using postgres connection "master"
[0m01:21:56.980970 [debug] [MainThread]: On master: COMMIT
[0m01:21:56.983316 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:21:56.984879 [debug] [MainThread]: On master: Close
[0m01:21:56.987425 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:21:56.989834 [info ] [MainThread]: 
[0m01:21:57.016438 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:21:57.019188 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m01:21:57.022395 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now snapshot.sales_analytics.customers_snapshot)
[0m01:21:57.024683 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:21:57.052283 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:21:57.026942 => 01:21:57.051507
[0m01:21:57.055204 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:21:57.225177 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m01:21:57.260384 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:21:57.267117 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m01:21:57.270490 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:21:57.286741 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:21:57.289744 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:21:57.292195 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  max(updated_at) as updated_at
from "warehouse"."analytics_staging"."src_orders"
group by 1,2,3

    ) sbq



  );
  
  
[0m01:21:57.383542 [debug] [Thread-1 (]: SQL status: SELECT 4845 in 0.0 seconds
[0m01:21:57.430723 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:21:57.433120 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:21:57.435174 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:21:57.442622 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:21:57.445697 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:21:57.057083 => 01:21:57.445288
[0m01:21:57.447589 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m01:21:57.453175 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e03eddc-f457-4821-b3c8-4e92ae2de738', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa84f713a10>]}
[0m01:21:57.459495 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSELECT 4845[0m in 0.43s]
[0m01:21:57.462771 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:21:57.468816 [debug] [MainThread]: Using postgres connection "master"
[0m01:21:57.470635 [debug] [MainThread]: On master: BEGIN
[0m01:21:57.472355 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:21:57.484523 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:21:57.486574 [debug] [MainThread]: On master: COMMIT
[0m01:21:57.488429 [debug] [MainThread]: Using postgres connection "master"
[0m01:21:57.496837 [debug] [MainThread]: On master: COMMIT
[0m01:21:57.499198 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:21:57.500854 [debug] [MainThread]: On master: Close
[0m01:21:57.503362 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:21:57.504778 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m01:21:57.506249 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m01:21:57.507889 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m01:21:57.509738 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m01:21:57.512537 [info ] [MainThread]: 
[0m01:21:57.515399 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.95 seconds (0.95s).
[0m01:21:57.518447 [debug] [MainThread]: Command end result
[0m01:21:57.565811 [info ] [MainThread]: 
[0m01:21:57.572260 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:21:57.575286 [info ] [MainThread]: 
[0m01:21:57.583914 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:21:57.587645 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 5.422212, "process_user_time": 10.059276, "process_kernel_time": 0.338294, "process_mem_max_rss": "131404", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:21:57.590200 [debug] [MainThread]: Command `dbt snapshot` succeeded at 01:21:57.589761 after 5.42 seconds
[0m01:21:57.593516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa852a93590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa84ffa26d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa851879d10>]}
[0m01:21:57.596696 [debug] [MainThread]: Flushing usage events
[0m01:22:12.181248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5bcb7410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5b7d1a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5b986190>]}


============================== 01:22:12.229077 | bf0298cb-0b40-4f32-ad65-acb0fd66f190 ==============================
[0m01:22:12.229077 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:22:12.239654 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m01:22:13.568527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5b888790>]}
[0m01:22:14.156789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5e0cead0>]}
[0m01:22:14.166468 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:22:14.244109 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:22:15.093293 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:22:15.103146 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:22:15.142852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5ab55890>]}
[0m01:22:15.325279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5afe60d0>]}
[0m01:22:15.333018 [info ] [MainThread]: Found 4 models, 1 snapshot, 11 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:22:15.339717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5afb5090>]}
[0m01:22:15.361885 [info ] [MainThread]: 
[0m01:22:15.369615 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:22:15.387654 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:22:15.390802 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:22:15.401359 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:22:15.549108 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:22:15.567445 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:22:15.583951 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:22:15.585049 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:22:15.588358 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:22:15.601078 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:15.597858 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:22:15.593339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:15.612069 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:15.644858 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:22:15.649937 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:22:15.662728 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:22:15.664704 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:22:15.679349 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:22:15.689298 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:22:15.707369 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_intermediate)
[0m01:22:15.710762 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_marts)
[0m01:22:15.713687 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_staging)
[0m01:22:15.720438 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:22:15.776255 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:22:15.779926 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:22:15.791720 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:22:15.821059 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:22:15.824050 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:22:15.814327 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:22:15.809860 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:22:15.832732 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:22:15.835076 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:15.818368 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:22:15.843693 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:22:15.829376 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:22:15.855975 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:15.867633 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:15.873754 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:22:15.878780 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:22:15.888516 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:22:15.885147 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:22:15.902551 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:15.919535 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:22:15.921965 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:22:15.923902 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:15.908444 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:15.925628 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:15.941059 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:22:15.942731 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:15.946095 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:22:15.960834 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:22:15.967118 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:22:15.975428 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:22:15.981503 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:22:15.987584 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:22:16.001351 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:22:16.021917 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:16.037803 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:22:16.045884 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:22:16.083972 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:16.096621 [debug] [MainThread]: On master: BEGIN
[0m01:22:16.100753 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:22:16.141550 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:22:16.147872 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:16.156972 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:22:16.184883 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:16.205021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5af95510>]}
[0m01:22:16.209682 [debug] [MainThread]: On master: ROLLBACK
[0m01:22:16.221263 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:16.227939 [debug] [MainThread]: On master: BEGIN
[0m01:22:16.239260 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:22:16.246536 [debug] [MainThread]: On master: COMMIT
[0m01:22:16.249890 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:16.255002 [debug] [MainThread]: On master: COMMIT
[0m01:22:16.259422 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:22:16.267026 [debug] [MainThread]: On master: Close
[0m01:22:16.271990 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:22:16.285640 [info ] [MainThread]: 
[0m01:22:16.342094 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:22:16.350323 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m01:22:16.356610 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.src_orders)
[0m01:22:16.368132 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:22:16.419052 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:22:16.534918 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:22:16.376639 => 01:22:16.533818
[0m01:22:16.538097 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:22:16.810955 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m01:22:17.014995 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.019440 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m01:22:17.039629 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:22:17.074177 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:22:17.081980 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.087478 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m01:22:17.113922 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m01:22:17.155369 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.161889 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders" rename to "src_orders__dbt_backup"
[0m01:22:17.174705 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:22:17.197928 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.205499 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m01:22:17.224173 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:22:17.423678 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.434519 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m01:22:17.451735 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:22:17.560836 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.566362 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m01:22:17.632411 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m01:22:17.669146 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.673126 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:22:17.682325 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:22:17.691501 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:22:17.697219 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.701491 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:22:17.713840 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:22:17.768457 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m01:22:17.811889 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:22:17.819332 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m01:22:17.833055 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m01:22:17.859632 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:22:16.545350 => 01:22:17.858720
[0m01:22:17.867608 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m01:22:17.873630 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5a389b90>]}
[0m01:22:17.884245 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 1.52s]
[0m01:22:17.893836 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:22:17.904262 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m01:22:17.906904 [debug] [Thread-4 (]: Began running node model.sales_analytics.orders_enriched
[0m01:22:17.911008 [info ] [Thread-3 (]: 2 of 4 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m01:22:17.918582 [info ] [Thread-4 (]: 3 of 4 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m01:22:17.925921 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.dim_customer)
[0m01:22:17.934222 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.orders_enriched)
[0m01:22:17.945853 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:22:17.955346 [debug] [Thread-4 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:22:17.994130 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:22:18.013970 [debug] [Thread-4 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:22:18.084463 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:22:17.997034 => 01:22:18.081445
[0m01:22:18.088731 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:22:17.970489 => 01:22:18.086893
[0m01:22:18.096032 [debug] [Thread-4 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:22:18.101767 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m01:22:18.318034 [debug] [Thread-4 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m01:22:18.319816 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m01:22:18.334946 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.336090 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:22:18.338040 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m01:22:18.340104 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: BEGIN
[0m01:22:18.341971 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:22:18.343663 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:22:18.359491 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m01:22:18.360771 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m01:22:18.370470 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.376240 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:22:18.380287 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m01:22:18.387774 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

with current as (
  select *
  from "warehouse"."snapshots"."customers_snapshot"
  where dbt_is_current = true
)
select
  customer_id,
  country,
  status,
  dbt_valid_from as valid_from
from current;
  );
  
[0m01:22:18.401024 [debug] [Thread-3 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 24: from current;
                     ^

[0m01:22:18.404970 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: ROLLBACK
[0m01:22:18.412102 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:22:18.134236 => 01:22:18.411121
[0m01:22:18.417899 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: Close
[0m01:22:18.453643 [debug] [Thread-3 (]: Database Error in model dim_customer (models/marts/dim_customer.sql)
  syntax error at or near ";"
  LINE 24: from current;
                       ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m01:22:18.458435 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5abce250>]}
[0m01:22:18.465884 [error] [Thread-3 (]: 2 of 4 ERROR creating sql table model analytics_marts.dim_customer ............. [[31mERROR[0m in 0.53s]
[0m01:22:18.481244 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m01:22:18.567775 [debug] [Thread-4 (]: SQL status: SELECT 12873 in 0.0 seconds
[0m01:22:18.601319 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.606171 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched" rename to "orders_enriched__dbt_backup"
[0m01:22:18.616111 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:22:18.655946 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.670117 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m01:22:18.675853 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:22:18.730511 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.754109 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m01:22:18.759797 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:22:18.785166 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.806235 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m01:22:18.882723 [debug] [Thread-4 (]: SQL status: SELECT 12 in 0.0 seconds
[0m01:22:18.916851 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.944861 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:22:18.949766 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:22:18.958490 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:22:18.963452 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:18.968190 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:22:18.978342 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m01:22:19.001729 [debug] [Thread-4 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m01:22:19.026464 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:22:19.029904 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m01:22:19.049207 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m01:22:19.067447 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:22:18.104672 => 01:22:19.066550
[0m01:22:19.076923 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: Close
[0m01:22:19.083563 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5a70b910>]}
[0m01:22:19.088529 [info ] [Thread-4 (]: 3 of 4 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 12873[0m in 1.15s]
[0m01:22:19.097760 [debug] [Thread-4 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:22:19.109643 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:22:19.118099 [info ] [Thread-1 (]: 4 of 4 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m01:22:19.125696 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now model.sales_analytics.fct_daily_sales)
[0m01:22:19.134177 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:22:19.224527 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:22:19.277089 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:22:19.137711 => 01:22:19.271921
[0m01:22:19.287511 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:22:19.513381 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:19.522668 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
    

  create temporary table "fct_daily_sales__dbt_tmp012219477704"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
      and date_trunc('day', order_ts)::date >= (
        coalesce( (select max(sales_date) from "warehouse"."analytics_marts"."fct_daily_sales"), '1900-01-01'::date )
        - interval '2 day'
      )
    
    group by 1
)
select * from base
  );
  
  
[0m01:22:19.528993 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:22:19.626527 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:22:19.649056 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:19.654253 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m01:22:19.661931 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:22:19.666332 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:19.672764 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp012219477704'
        
      order by ordinal_position

  
[0m01:22:19.702427 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:22:19.734735 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:19.747095 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:22:19.771794 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:22:20.112797 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.122720 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp012219477704'
        
      order by ordinal_position

  
[0m01:22:20.138664 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:22:20.168235 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.183025 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:22:20.204208 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:22:20.278686 [debug] [Thread-1 (]: 
    In "warehouse"."analytics_marts"."fct_daily_sales":
        Schema changed: True
        Source columns not in target: []
        Target columns not in source: []
        New column types: [{'column_name': 'gross_revenue', 'new_type': 'numeric'}]
  
[0m01:22:20.366995 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.375271 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    alter table "warehouse"."analytics_marts"."fct_daily_sales" add column "gross_revenue__dbt_alter" numeric;
    update "warehouse"."analytics_marts"."fct_daily_sales" set "gross_revenue__dbt_alter" = "gross_revenue";
    alter table "warehouse"."analytics_marts"."fct_daily_sales" drop column "gross_revenue" cascade;
    alter table "warehouse"."analytics_marts"."fct_daily_sales" rename column "gross_revenue__dbt_alter" to "gross_revenue"
  
[0m01:22:20.398886 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:22:20.411850 [debug] [Thread-1 (]: 
    In "warehouse"."analytics_marts"."fct_daily_sales":
        Schema change approach: sync_all_columns
        Columns added: []
        Columns removed: []
        Data types changed: [{'column_name': 'gross_revenue', 'new_type': 'numeric'}]
  
[0m01:22:20.465571 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m01:22:20.483845 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.486089 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
        
            delete from "warehouse"."analytics_marts"."fct_daily_sales"
            where (
                sales_date) in (
                select (sales_date)
                from "fct_daily_sales__dbt_tmp012219477704"
            );

        
    

    insert into "warehouse"."analytics_marts"."fct_daily_sales" ("sales_date", "orders", "units_sold", "gross_revenue")
    (
        select "sales_date", "orders", "units_sold", "gross_revenue"
        from "fct_daily_sales__dbt_tmp012219477704"
    )
  
[0m01:22:20.489699 [debug] [Thread-1 (]: SQL status: INSERT 0 4 in 0.0 seconds
[0m01:22:20.497836 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.500065 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m01:22:20.502692 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:22:20.514354 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.516867 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:22:20.525227 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:22:20.533916 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.536121 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:22:20.539342 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:22:20.547213 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.549318 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m01:22:20.561228 [debug] [Thread-1 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m01:22:20.564672 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:22:20.566746 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:22:20.568652 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:22:20.574437 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:22:20.577413 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:22:19.291199 => 01:22:20.577037
[0m01:22:20.579187 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: Close
[0m01:22:20.582006 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf0298cb-0b40-4f32-ad65-acb0fd66f190', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a59fa51d0>]}
[0m01:22:20.584165 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mINSERT 0 4[0m in 1.46s]
[0m01:22:20.586570 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:22:20.592171 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:20.594184 [debug] [MainThread]: On master: BEGIN
[0m01:22:20.595863 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:22:20.607792 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:22:20.610299 [debug] [MainThread]: On master: COMMIT
[0m01:22:20.612599 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:20.614646 [debug] [MainThread]: On master: COMMIT
[0m01:22:20.617032 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:22:20.620547 [debug] [MainThread]: On master: Close
[0m01:22:20.623999 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:22:20.628057 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m01:22:20.630085 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m01:22:20.632279 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m01:22:20.634289 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m01:22:20.636306 [info ] [MainThread]: 
[0m01:22:20.638279 [info ] [MainThread]: Finished running 1 view model, 2 table models, 1 incremental model in 0 hours 0 minutes and 5.27 seconds (5.27s).
[0m01:22:20.644580 [debug] [MainThread]: Command end result
[0m01:22:20.697243 [info ] [MainThread]: 
[0m01:22:20.700108 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:22:20.703992 [info ] [MainThread]: 
[0m01:22:20.707061 [error] [MainThread]:   Database Error in model dim_customer (models/marts/dim_customer.sql)
  syntax error at or near ";"
  LINE 24: from current;
                       ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m01:22:20.710394 [info ] [MainThread]: 
[0m01:22:20.712998 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m01:22:20.717291 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 8.79724, "process_user_time": 18.62699, "process_kernel_time": 0.882225, "process_mem_max_rss": "124244", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:22:20.720681 [debug] [MainThread]: Command `dbt run` failed at 01:22:20.720286 after 8.80 seconds
[0m01:22:20.723280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a60373b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a60373950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a5a3d06d0>]}
[0m01:22:20.726622 [debug] [MainThread]: Flushing usage events
[0m01:22:31.250096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e6c41c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e6c77c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e6f2c150>]}


============================== 01:22:31.263630 | 68008938-4303-4b71-a96c-5a418f213f50 ==============================
[0m01:22:31.263630 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:22:31.266845 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m01:22:31.874019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '68008938-4303-4b71-a96c-5a418f213f50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e5f13150>]}
[0m01:22:32.125566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '68008938-4303-4b71-a96c-5a418f213f50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e63f6a50>]}
[0m01:22:32.129833 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:22:32.169133 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:22:32.585856 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:22:32.590039 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:22:32.613140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '68008938-4303-4b71-a96c-5a418f213f50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e6c22dd0>]}
[0m01:22:32.653485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '68008938-4303-4b71-a96c-5a418f213f50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e5ba7890>]}
[0m01:22:32.656982 [info ] [MainThread]: Found 4 models, 1 snapshot, 11 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:22:32.665973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68008938-4303-4b71-a96c-5a418f213f50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97ea1fa2d0>]}
[0m01:22:32.679208 [info ] [MainThread]: 
[0m01:22:32.689909 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:22:32.706549 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:22:32.701202 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:22:32.711053 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:22:32.720841 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:22:32.807762 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:22:32.823851 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:22:32.832245 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:22:32.839786 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:22:32.841670 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:22:32.844312 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:22:32.848234 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:22:32.851063 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:22:32.853312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:32.855608 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:32.857691 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:32.859926 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:32.884110 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:32.885712 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:32.892265 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:32.904182 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:32.901869 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:22:32.909837 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:22:32.915816 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:22:32.922134 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:22:32.925502 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:22:32.929086 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:22:32.934541 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:22:32.937081 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:22:32.950773 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:32.952535 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:32.953936 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:32.959895 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:22:32.961965 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:32.970119 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:22:32.976064 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:22:32.982025 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:22:32.986797 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:22:32.990340 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:22:32.992485 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:22:33.001255 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:22:33.031003 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:33.033879 [debug] [MainThread]: On master: BEGIN
[0m01:22:33.035891 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:22:33.054337 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:22:33.056915 [debug] [MainThread]: Using postgres connection "master"
[0m01:22:33.059522 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:22:33.074977 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:22:33.083238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '68008938-4303-4b71-a96c-5a418f213f50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e5f256d0>]}
[0m01:22:33.085820 [debug] [MainThread]: On master: ROLLBACK
[0m01:22:33.088391 [debug] [MainThread]: On master: Close
[0m01:22:33.098636 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:22:33.103821 [info ] [MainThread]: 
[0m01:22:33.135819 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:22:33.140108 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m01:22:33.142663 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:22:33.169124 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:22:33.190910 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:22:33.145325 => 01:22:33.190110
[0m01:22:33.193462 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:22:33.198001 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:22:33.196231 => 01:22:33.196323
[0m01:22:33.202369 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:22:33.206598 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m01:22:33.207844 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:22:33.209086 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:22:33.211339 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:22:33.215495 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.orders_enriched)
[0m01:22:33.220625 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now snapshot.sales_analytics.customers_snapshot)
[0m01:22:33.223839 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m01:22:33.227106 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m01:22:33.231239 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:22:33.233791 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:22:33.235947 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:22:33.237861 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:22:33.248729 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:22:33.259287 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:22:33.250527 => 01:22:33.258538
[0m01:22:33.331442 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:22:33.329670 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:22:33.335188 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:22:33.340968 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:22:33.340250 => 01:22:33.340293
[0m01:22:33.348301 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:22:33.350330 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:22:33.239872 => 01:22:33.349634
[0m01:22:33.352771 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:22:33.355634 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:22:33.359377 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m01:22:33.363475 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:22:33.362094 => 01:22:33.362141
[0m01:22:33.365427 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 01:22:33.260877 => 01:22:33.364611
[0m01:22:33.366897 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 01:22:33.285125 => 01:22:33.366205
[0m01:22:33.369334 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:22:33.373571 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:22:33.375987 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:22:33.379047 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:22:33.402851 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:22:33.404823 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:22:33.407670 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 01:22:33.406987 => 01:22:33.407017
[0m01:22:33.410212 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 01:22:33.409678 => 01:22:33.409705
[0m01:22:33.415045 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m01:22:33.419299 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:22:33.423358 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:22:33.425374 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:22:33.427789 [debug] [Thread-2 (]: Began running node model.sales_analytics.dim_customer
[0m01:22:33.430512 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:22:33.432918 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 01:22:33.382644 => 01:22:33.432306
[0m01:22:33.444820 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:22:33.447158 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.dim_customer)
[0m01:22:33.450386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m01:22:33.452620 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:22:33.455969 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:22:33.458251 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:22:33.461099 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 01:22:33.460470 => 01:22:33.460507
[0m01:22:33.471278 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:22:33.479360 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 01:22:33.433461 => 01:22:33.478518
[0m01:22:33.500811 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:22:33.506861 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:22:33.511529 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:22:33.514197 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:22:33.518094 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 01:22:33.517295 => 01:22:33.517322
[0m01:22:33.521283 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m01:22:33.526093 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:22:33.527635 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:22:33.462844 => 01:22:33.526953
[0m01:22:33.528855 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:22:33.473221 => 01:22:33.528149
[0m01:22:33.530701 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:22:33.534098 [debug] [Thread-2 (]: Began executing node model.sales_analytics.dim_customer
[0m01:22:33.536327 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:22:33.549924 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:22:33.551739 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:22:33.551100 => 01:22:33.551137
[0m01:22:33.554142 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:22:33.553579 => 01:22:33.553600
[0m01:22:33.559722 [debug] [Thread-2 (]: Finished running node model.sales_analytics.dim_customer
[0m01:22:33.563459 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:22:33.566957 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:22:33.568130 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:22:33.570725 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:22:33.573027 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m01:22:33.575908 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m01:22:33.579334 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m01:22:33.582201 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:22:33.584273 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 01:22:33.538098 => 01:22:33.583729
[0m01:22:33.585201 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:22:33.587498 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:22:33.601509 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:22:33.603323 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:22:33.625863 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:22:33.638521 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:22:33.641817 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 01:22:33.641129 => 01:22:33.641153
[0m01:22:33.649855 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:22:33.652806 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:22:33.655750 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m01:22:33.658698 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:22:33.660255 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 01:22:33.589446 => 01:22:33.659506
[0m01:22:33.663073 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 01:22:33.605068 => 01:22:33.662403
[0m01:22:33.675894 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 01:22:33.626658 => 01:22:33.675190
[0m01:22:33.681730 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:22:33.683464 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:22:33.685790 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:22:33.688393 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:22:33.692979 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 01:22:33.692009 => 01:22:33.692045
[0m01:22:33.696210 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 01:22:33.695377 => 01:22:33.695412
[0m01:22:33.699314 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 01:22:33.698338 => 01:22:33.698363
[0m01:22:33.703649 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:22:33.707948 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:22:33.709791 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 01:22:33.663952 => 01:22:33.708872
[0m01:22:33.714139 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:22:33.716995 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:22:33.719739 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:22:33.722179 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:22:33.727532 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m01:22:33.732328 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.unique_dim_customer_customer_id.b42affccd1, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m01:22:33.735893 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 01:22:33.734762 => 01:22:33.734797
[0m01:22:33.738796 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:22:33.741411 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:22:33.745648 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:22:33.760676 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:22:33.775149 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:22:33.791867 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 01:22:33.747724 => 01:22:33.790882
[0m01:22:33.794935 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:22:33.798086 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 01:22:33.797219 => 01:22:33.797248
[0m01:22:33.799421 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 01:22:33.763286 => 01:22:33.798838
[0m01:22:33.803638 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:22:33.806117 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:22:33.811363 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 01:22:33.810386 => 01:22:33.810421
[0m01:22:33.816211 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:22:33.822874 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:22:33.825168 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m01:22:33.827215 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m01:22:33.829886 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m01:22:33.832156 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m01:22:33.840383 [debug] [MainThread]: Command end result
[0m01:22:33.940393 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m01:22:33.942635 [info ] [MainThread]: Building catalog
[0m01:22:33.952710 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m01:22:33.977705 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:22:33.980486 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m01:22:33.982420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:22:33.998142 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:22:34.000267 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:22:34.002315 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m01:22:34.020555 [debug] [ThreadPool]: SQL status: SELECT 35 in 0.0 seconds
[0m01:22:34.036946 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m01:22:34.040054 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m01:22:34.094900 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m01:22:34.101364 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.9745722, "process_user_time": 8.621957, "process_kernel_time": 0.33929, "process_mem_max_rss": "121240", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:22:34.107257 [debug] [MainThread]: Command `dbt docs generate` succeeded at 01:22:34.106643 after 2.98 seconds
[0m01:22:34.114831 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m01:22:34.117708 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m01:22:34.120946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e6c7fc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e6c7fa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97e85e3fd0>]}
[0m01:22:34.124590 [debug] [MainThread]: Flushing usage events
[0m01:23:59.449380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b5210550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b56d35d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b5223790>]}


============================== 01:23:59.471202 | 09c22c1b-a8c1-4d55-83a2-534b302cdbf2 ==============================
[0m01:23:59.471202 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:23:59.475019 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m01:23:59.729528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '09c22c1b-a8c1-4d55-83a2-534b302cdbf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b5216e90>]}
[0m01:23:59.734848 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:23:59.748094 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:23:59.751590 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.45938522, "process_user_time": 14.920169, "process_kernel_time": 0.570771, "process_mem_max_rss": "105120", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:23:59.753956 [debug] [MainThread]: Command `dbt deps` succeeded at 01:23:59.753563 after 0.46 seconds
[0m01:23:59.755975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b5262b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b52126d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87b5210550>]}
[0m01:23:59.758057 [debug] [MainThread]: Flushing usage events
[0m01:24:08.334709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7756dc110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa77571da50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7756d65d0>]}


============================== 01:24:08.354111 | 32d14609-8e90-4a9a-9dd9-0b1fab16e7be ==============================
[0m01:24:08.354111 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:24:08.357114 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:24:09.060990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '32d14609-8e90-4a9a-9dd9-0b1fab16e7be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa774b95750>]}
[0m01:24:09.325741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '32d14609-8e90-4a9a-9dd9-0b1fab16e7be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa774bfd590>]}
[0m01:24:09.329227 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:24:09.370265 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:24:09.717494 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:24:09.720866 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/dim_customer.sql
[0m01:24:10.596046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32d14609-8e90-4a9a-9dd9-0b1fab16e7be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa773b40e50>]}
[0m01:24:10.666651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32d14609-8e90-4a9a-9dd9-0b1fab16e7be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7743e6d90>]}
[0m01:24:10.669681 [info ] [MainThread]: Found 4 models, 1 snapshot, 11 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:24:10.672564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32d14609-8e90-4a9a-9dd9-0b1fab16e7be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa77478d450>]}
[0m01:24:10.683661 [info ] [MainThread]: 
[0m01:24:10.690973 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:24:10.698008 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:24:10.736477 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:24:10.739074 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:24:10.741245 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:10.769613 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:24:10.775076 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:24:10.787747 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_marts)
[0m01:24:10.790754 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:24:10.793978 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:24:10.809375 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:24:10.830417 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:24:10.837907 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:24:10.952078 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:24:10.958386 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:24:10.960438 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:24:10.962230 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:24:10.964449 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:24:10.966373 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:24:10.968327 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:24:10.970297 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:10.972185 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:10.973918 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:10.994731 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:10.997409 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:10.998921 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:24:11.000149 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:11.002294 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:11.003280 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:24:11.005335 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:24:11.007636 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:24:11.009870 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:24:11.011809 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:24:11.015247 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:24:11.017554 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:24:11.023510 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:11.028895 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:24:11.030230 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:11.031414 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:11.032429 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:11.033966 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:24:11.037677 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:24:11.042003 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:24:11.046643 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:24:11.052656 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:24:11.054576 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:24:11.056738 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:24:11.080565 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:11.082768 [debug] [MainThread]: On master: BEGIN
[0m01:24:11.084694 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:24:11.100670 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:24:11.102691 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:11.105042 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:24:11.116680 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:11.121666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32d14609-8e90-4a9a-9dd9-0b1fab16e7be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7747cdc50>]}
[0m01:24:11.123992 [debug] [MainThread]: On master: ROLLBACK
[0m01:24:11.126728 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:11.131808 [debug] [MainThread]: On master: BEGIN
[0m01:24:11.135233 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:24:11.137181 [debug] [MainThread]: On master: COMMIT
[0m01:24:11.139257 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:11.141433 [debug] [MainThread]: On master: COMMIT
[0m01:24:11.143949 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:24:11.145559 [debug] [MainThread]: On master: Close
[0m01:24:11.148374 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:24:11.150415 [info ] [MainThread]: 
[0m01:24:11.171842 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:24:11.174636 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m01:24:11.179868 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m01:24:11.183037 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:24:11.206508 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:24:11.184633 => 01:24:11.205857
[0m01:24:11.209467 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:24:11.329915 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.332773 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m01:24:11.334821 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:24:11.348613 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:24:11.350737 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.352640 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
[0m01:24:11.371618 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m01:24:11.439335 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.441688 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

        
  
    

  create temporary table "customers_snapshot__dbt_tmp012411406307"
  
  
    as
  
  (
    with snapshot_query as (

        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  max(updated_at) as updated_at
from "warehouse"."analytics_staging"."src_orders"
group by 1,2,3


    ),

    snapshotted_data as (

        select *,
            customer_id as dbt_unique_key

        from "warehouse"."snapshots"."customers_snapshot"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    )

    select * from insertions
    union all
    select * from updates

  );
  
    
[0m01:24:11.574486 [debug] [Thread-1 (]: SQL status: SELECT 14498 in 0.0 seconds
[0m01:24:11.584893 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.587652 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp012411406307'
        
      order by ordinal_position

  
[0m01:24:11.597566 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m01:24:11.609066 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.611991 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
[0m01:24:11.621121 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m01:24:11.633388 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.635815 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp012411406307'
        
      order by ordinal_position

  
[0m01:24:11.645076 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m01:24:11.657406 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.659969 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
[0m01:24:11.667438 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m01:24:11.689027 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.691594 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp012411406307'
        
      order by ordinal_position

  
[0m01:24:11.701299 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m01:24:11.727848 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.754213 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:11.757153 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      update "warehouse"."snapshots"."customers_snapshot"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "customers_snapshot__dbt_tmp012411406307" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "warehouse"."snapshots"."customers_snapshot".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "warehouse"."snapshots"."customers_snapshot".dbt_valid_to is null;

    insert into "warehouse"."snapshots"."customers_snapshot" ("customer_id", "country", "status", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."customer_id",DBT_INTERNAL_SOURCE."country",DBT_INTERNAL_SOURCE."status",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "customers_snapshot__dbt_tmp012411406307" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m01:24:11.954615 [debug] [Thread-1 (]: SQL status: INSERT 0 7249 in 0.0 seconds
[0m01:24:12.064158 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:24:12.068187 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:24:12.071891 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:24:12.082806 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:24:12.099688 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:24:11.212740 => 01:24:12.098811
[0m01:24:12.108215 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m01:24:12.116505 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '32d14609-8e90-4a9a-9dd9-0b1fab16e7be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa774bbff10>]}
[0m01:24:12.141474 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mINSERT 0 7249[0m in 0.94s]
[0m01:24:12.149838 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:24:12.165257 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:12.171984 [debug] [MainThread]: On master: BEGIN
[0m01:24:12.181190 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:24:12.207419 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:24:12.216544 [debug] [MainThread]: On master: COMMIT
[0m01:24:12.219675 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:12.222563 [debug] [MainThread]: On master: COMMIT
[0m01:24:12.226982 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:24:12.236368 [debug] [MainThread]: On master: Close
[0m01:24:12.242182 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:24:12.250602 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m01:24:12.254394 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m01:24:12.257308 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m01:24:12.262673 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m01:24:12.265700 [info ] [MainThread]: 
[0m01:24:12.268619 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 1.58 seconds (1.58s).
[0m01:24:12.272801 [debug] [MainThread]: Command end result
[0m01:24:12.346228 [info ] [MainThread]: 
[0m01:24:12.349845 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:24:12.355007 [info ] [MainThread]: 
[0m01:24:12.360411 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:24:12.366443 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 4.1513715, "process_user_time": 10.474526, "process_kernel_time": 0.469306, "process_mem_max_rss": "128820", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:24:12.370901 [debug] [MainThread]: Command `dbt snapshot` succeeded at 01:24:12.370312 after 4.16 seconds
[0m01:24:12.373458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa775b9f3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa7747a65d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa77a26f910>]}
[0m01:24:12.376090 [debug] [MainThread]: Flushing usage events
[0m01:24:26.847592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ee5c3610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8eea83cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ef7cf8d0>]}


============================== 01:24:26.904474 | 471777de-2c04-4134-8c02-8ac013be99c8 ==============================
[0m01:24:26.904474 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:24:26.914663 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:24:28.188107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ee601110>]}
[0m01:24:28.817882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8edd4b850>]}
[0m01:24:28.834122 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:24:28.963593 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:24:29.807186 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:24:29.813641 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:24:29.857276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ed5a48d0>]}
[0m01:24:30.002697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8edd4b850>]}
[0m01:24:30.009492 [info ] [MainThread]: Found 4 models, 1 snapshot, 11 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:24:30.013320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8eddd8f50>]}
[0m01:24:30.024785 [info ] [MainThread]: 
[0m01:24:30.037000 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:24:30.068949 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:24:30.083429 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:24:30.085356 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:24:30.190632 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:24:30.221579 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:24:30.224310 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:24:30.232479 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:24:30.236041 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:24:30.239026 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:24:30.242079 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:30.245526 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:30.248724 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:30.289873 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:24:30.291345 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:24:30.303861 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:24:30.311076 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:24:30.314840 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:24:30.338729 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:24:30.365138 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_intermediate)
[0m01:24:30.368908 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_marts)
[0m01:24:30.372559 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_snapshots)
[0m01:24:30.378726 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:24:30.423186 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:24:30.426071 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:24:30.443840 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:24:30.457587 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:24:30.462761 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:24:30.467936 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:24:30.471523 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:24:30.474604 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:24:30.479241 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:24:30.484883 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:24:30.488826 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:24:30.491924 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:30.522626 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:30.526058 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:30.532713 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:30.541264 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:24:30.546794 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:30.550679 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:24:30.554254 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:24:30.557377 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:24:30.563367 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:24:30.569783 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:24:30.574503 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:24:30.584716 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:24:30.598449 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:30.601736 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:30.604380 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:30.606275 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:30.614748 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:24:30.623504 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:24:30.635946 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:24:30.649824 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:24:30.660812 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:24:30.664368 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:24:30.667543 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:24:30.669968 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:24:30.725288 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:30.729839 [debug] [MainThread]: On master: BEGIN
[0m01:24:30.735591 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:24:30.761010 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:24:30.764647 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:30.771809 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:24:30.811142 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:30.823741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ed9277d0>]}
[0m01:24:30.833329 [debug] [MainThread]: On master: ROLLBACK
[0m01:24:30.837949 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:30.844897 [debug] [MainThread]: On master: BEGIN
[0m01:24:30.863615 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:24:30.868783 [debug] [MainThread]: On master: COMMIT
[0m01:24:30.871742 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:30.874499 [debug] [MainThread]: On master: COMMIT
[0m01:24:30.878678 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:24:30.881218 [debug] [MainThread]: On master: Close
[0m01:24:30.885709 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:24:30.891473 [info ] [MainThread]: 
[0m01:24:30.942788 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:24:30.951917 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m01:24:30.962475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m01:24:30.966136 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:24:31.024614 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:24:31.084483 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:24:30.970229 => 01:24:31.081877
[0m01:24:31.090927 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:24:31.362931 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m01:24:31.416431 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.419910 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m01:24:31.424547 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:24:31.450657 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:24:31.454046 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.458747 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m01:24:31.469369 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m01:24:31.525472 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.538664 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders" rename to "src_orders__dbt_backup"
[0m01:24:31.544349 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:24:31.567582 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.571464 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m01:24:31.581297 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:24:31.738426 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.744312 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m01:24:31.754877 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:24:31.868723 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.873322 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m01:24:31.920080 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m01:24:31.952272 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.956922 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:24:31.961616 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:24:31.972083 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:24:31.976264 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:31.981139 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:24:32.004352 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:24:32.046470 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m01:24:32.081746 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:24:32.085779 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m01:24:32.096343 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m01:24:32.106304 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:24:31.094290 => 01:24:32.105423
[0m01:24:32.109882 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m01:24:32.116577 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ed516290>]}
[0m01:24:32.129630 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 1.15s]
[0m01:24:32.142891 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:24:32.149207 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m01:24:32.152754 [debug] [Thread-4 (]: Began running node model.sales_analytics.orders_enriched
[0m01:24:32.158532 [info ] [Thread-3 (]: 2 of 4 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m01:24:32.163682 [info ] [Thread-4 (]: 3 of 4 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m01:24:32.168192 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.dim_customer)
[0m01:24:32.172283 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m01:24:32.181284 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:24:32.185792 [debug] [Thread-4 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:24:32.211178 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:24:32.233832 [debug] [Thread-4 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:24:32.304785 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:24:32.189519 => 01:24:32.303416
[0m01:24:32.308519 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m01:24:32.310095 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:24:32.212292 => 01:24:32.309411
[0m01:24:32.337470 [debug] [Thread-4 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:24:32.516098 [debug] [Thread-4 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m01:24:32.528717 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m01:24:32.567143 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:32.571009 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:24:32.572550 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m01:24:32.583409 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: BEGIN
[0m01:24:32.601297 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:24:32.609388 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:24:32.633682 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m01:24:32.638120 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:24:32.647657 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

with current as (
  select *
  from "warehouse"."snapshots"."customers_snapshot"
  where dbt_is_current = true
)
select
  customer_id,
  country,
  status,
  dbt_valid_from as valid_from
from current
  );
  
[0m01:24:32.649441 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m01:24:32.654937 [debug] [Thread-3 (]: Postgres adapter: Postgres error: column "dbt_is_current" does not exist
LINE 17:   where dbt_is_current = true
                 ^

[0m01:24:32.658020 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:32.661336 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: ROLLBACK
[0m01:24:32.664993 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m01:24:32.672543 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:24:32.311706 => 01:24:32.671371
[0m01:24:32.677156 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: Close
[0m01:24:32.698172 [debug] [Thread-3 (]: Database Error in model dim_customer (models/marts/dim_customer.sql)
  column "dbt_is_current" does not exist
  LINE 17:   where dbt_is_current = true
                   ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m01:24:32.712277 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ed9ed890>]}
[0m01:24:32.722024 [error] [Thread-3 (]: 2 of 4 ERROR creating sql table model analytics_marts.dim_customer ............. [[31mERROR[0m in 0.55s]
[0m01:24:32.730826 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m01:24:32.849985 [debug] [Thread-4 (]: SQL status: SELECT 17164 in 0.0 seconds
[0m01:24:32.874365 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:32.882272 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched" rename to "orders_enriched__dbt_backup"
[0m01:24:32.890255 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:24:32.908397 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:32.923665 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m01:24:32.930371 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:24:32.989058 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:32.999176 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m01:24:33.006234 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:24:33.028715 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:33.033725 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m01:24:33.080734 [debug] [Thread-4 (]: SQL status: SELECT 12 in 0.0 seconds
[0m01:24:33.095985 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:33.101693 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:24:33.105645 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:24:33.114528 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:24:33.117661 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:33.121595 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:24:33.132720 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m01:24:33.146029 [debug] [Thread-4 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m01:24:33.170056 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:24:33.181419 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m01:24:33.205859 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m01:24:33.224544 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:24:32.357250 => 01:24:33.223441
[0m01:24:33.228347 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: Close
[0m01:24:33.236574 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ed1a63d0>]}
[0m01:24:33.240738 [info ] [Thread-4 (]: 3 of 4 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 17164[0m in 1.07s]
[0m01:24:33.244941 [debug] [Thread-4 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:24:33.254360 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:24:33.258178 [info ] [Thread-1 (]: 4 of 4 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m01:24:33.267618 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now model.sales_analytics.fct_daily_sales)
[0m01:24:33.273210 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:24:33.352175 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:24:33.390775 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:24:33.275697 => 01:24:33.389541
[0m01:24:33.401749 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:24:33.621577 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:33.625694 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
    

  create temporary table "fct_daily_sales__dbt_tmp012433584931"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
      and date_trunc('day', order_ts)::date >= (
        coalesce( (select max(sales_date) from "warehouse"."analytics_marts"."fct_daily_sales"), '1900-01-01'::date )
        - interval '2 day'
      )
    
    group by 1
)
select * from base
  );
  
  
[0m01:24:33.628849 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:24:33.711785 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.0 seconds
[0m01:24:33.733561 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:33.741573 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m01:24:33.746586 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:24:33.750086 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:33.766651 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp012433584931'
        
      order by ordinal_position

  
[0m01:24:33.805114 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:24:33.829454 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:33.833477 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:24:33.862355 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:24:34.143463 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.149259 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp012433584931'
        
      order by ordinal_position

  
[0m01:24:34.168640 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:24:34.192777 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.197803 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:24:34.221178 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:24:34.292023 [debug] [Thread-1 (]: 
    In "warehouse"."analytics_marts"."fct_daily_sales":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m01:24:34.372955 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m01:24:34.388812 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.391235 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
        
            delete from "warehouse"."analytics_marts"."fct_daily_sales"
            where (
                sales_date) in (
                select (sales_date)
                from "fct_daily_sales__dbt_tmp012433584931"
            );

        
    

    insert into "warehouse"."analytics_marts"."fct_daily_sales" ("sales_date", "orders", "units_sold", "gross_revenue")
    (
        select "sales_date", "orders", "units_sold", "gross_revenue"
        from "fct_daily_sales__dbt_tmp012433584931"
    )
  
[0m01:24:34.394674 [debug] [Thread-1 (]: SQL status: INSERT 0 3 in 0.0 seconds
[0m01:24:34.401282 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.403393 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m01:24:34.406122 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:24:34.415449 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.417562 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:24:34.424490 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:24:34.431121 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.433406 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:24:34.435884 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:24:34.442127 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.443949 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m01:24:34.446507 [debug] [Thread-1 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m01:24:34.449330 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:24:34.450797 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:24:34.452302 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:24:34.474217 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:24:34.479329 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:24:33.405074 => 01:24:34.478629
[0m01:24:34.483638 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: Close
[0m01:24:34.487941 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '471777de-2c04-4134-8c02-8ac013be99c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ee716a10>]}
[0m01:24:34.491812 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mINSERT 0 3[0m in 1.23s]
[0m01:24:34.497449 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:24:34.504255 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:34.507235 [debug] [MainThread]: On master: BEGIN
[0m01:24:34.509880 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:24:34.531362 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:24:34.536474 [debug] [MainThread]: On master: COMMIT
[0m01:24:34.541800 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:34.544299 [debug] [MainThread]: On master: COMMIT
[0m01:24:34.548834 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:24:34.552666 [debug] [MainThread]: On master: Close
[0m01:24:34.556768 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:24:34.559590 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m01:24:34.561761 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m01:24:34.564378 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m01:24:34.567964 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m01:24:34.570675 [info ] [MainThread]: 
[0m01:24:34.573998 [info ] [MainThread]: Finished running 1 view model, 2 table models, 1 incremental model in 0 hours 0 minutes and 4.54 seconds (4.54s).
[0m01:24:34.580652 [debug] [MainThread]: Command end result
[0m01:24:34.666855 [info ] [MainThread]: 
[0m01:24:34.673516 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:24:34.681441 [info ] [MainThread]: 
[0m01:24:34.690440 [error] [MainThread]:   Database Error in model dim_customer (models/marts/dim_customer.sql)
  column "dbt_is_current" does not exist
  LINE 17:   where dbt_is_current = true
                   ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m01:24:34.697624 [info ] [MainThread]: 
[0m01:24:34.711659 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m01:24:34.729304 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 8.276727, "process_user_time": 18.470297, "process_kernel_time": 0.89243, "process_mem_max_rss": "124256", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:24:34.733187 [debug] [MainThread]: Command `dbt run` failed at 01:24:34.732573 after 8.28 seconds
[0m01:24:34.740147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8f3153dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8f3153a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8ecd40c10>]}
[0m01:24:34.747089 [debug] [MainThread]: Flushing usage events
[0m01:24:44.913229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df3607350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df474a1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df3605390>]}


============================== 01:24:44.934523 | 03b4c8db-4e2b-4d25-92b4-ca98ea6fbc45 ==============================
[0m01:24:44.934523 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:24:44.937836 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:24:45.443187 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '03b4c8db-4e2b-4d25-92b4-ca98ea6fbc45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df2b4cdd0>]}
[0m01:24:45.792368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '03b4c8db-4e2b-4d25-92b4-ca98ea6fbc45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df35ffa10>]}
[0m01:24:45.797063 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:24:45.850418 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:24:46.289077 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:24:46.291890 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:24:46.307755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '03b4c8db-4e2b-4d25-92b4-ca98ea6fbc45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df239a090>]}
[0m01:24:46.331179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '03b4c8db-4e2b-4d25-92b4-ca98ea6fbc45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df235b990>]}
[0m01:24:46.336084 [info ] [MainThread]: Found 4 models, 1 snapshot, 11 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:24:46.338732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03b4c8db-4e2b-4d25-92b4-ca98ea6fbc45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df38452d0>]}
[0m01:24:46.346216 [info ] [MainThread]: 
[0m01:24:46.350769 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:24:46.359338 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:24:46.364045 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:24:46.368095 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:24:46.373152 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:24:46.437592 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:24:46.453711 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:24:46.455312 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:24:46.462228 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:24:46.464483 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:24:46.466383 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:24:46.468438 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:24:46.470370 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:24:46.472012 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:46.474118 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:46.476223 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:46.477994 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:46.501264 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:46.502755 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:46.504097 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:46.505355 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:46.506395 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:24:46.508829 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:24:46.511197 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:24:46.513422 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:24:46.515776 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:24:46.518247 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:24:46.520379 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:24:46.522489 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:24:46.537346 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:46.538632 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:46.539602 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:46.541502 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:46.546769 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:24:46.552024 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:24:46.556835 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:24:46.561684 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:24:46.564483 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:24:46.566386 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:24:46.568428 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:24:46.570297 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:24:46.594655 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:46.596932 [debug] [MainThread]: On master: BEGIN
[0m01:24:46.598972 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:24:46.613886 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:24:46.616242 [debug] [MainThread]: Using postgres connection "master"
[0m01:24:46.618200 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:24:46.629857 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:24:46.635963 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '03b4c8db-4e2b-4d25-92b4-ca98ea6fbc45', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df4071890>]}
[0m01:24:46.639153 [debug] [MainThread]: On master: ROLLBACK
[0m01:24:46.642257 [debug] [MainThread]: On master: Close
[0m01:24:46.645874 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:24:46.648417 [info ] [MainThread]: 
[0m01:24:46.670897 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:24:46.674132 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m01:24:46.677391 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:24:46.697611 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:24:46.719264 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:24:46.679719 => 01:24:46.718601
[0m01:24:46.721579 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:24:46.724185 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:24:46.723474 => 01:24:46.723509
[0m01:24:46.728256 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:24:46.732476 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m01:24:46.733859 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:24:46.734742 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:24:46.736080 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:24:46.738327 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.orders_enriched)
[0m01:24:46.741495 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now snapshot.sales_analytics.customers_snapshot)
[0m01:24:46.745150 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m01:24:46.747871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m01:24:46.749852 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:24:46.751707 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:24:46.753447 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:24:46.755260 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:24:46.762673 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:24:46.771930 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:24:46.764447 => 01:24:46.771415
[0m01:24:46.805391 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:24:46.809712 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:24:46.814384 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:24:46.819240 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:24:46.818671 => 01:24:46.818699
[0m01:24:46.823609 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:24:46.824964 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:24:46.756671 => 01:24:46.824339
[0m01:24:46.827143 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:24:46.828657 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 01:24:46.796048 => 01:24:46.828083
[0m01:24:46.830023 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 01:24:46.773431 => 01:24:46.829558
[0m01:24:46.831401 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:24:46.834241 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m01:24:46.836536 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:24:46.838676 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:24:46.840958 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:24:46.840465 => 01:24:46.840496
[0m01:24:46.843125 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:24:46.845395 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 01:24:46.844892 => 01:24:46.844924
[0m01:24:46.847526 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 01:24:46.847103 => 01:24:46.847125
[0m01:24:46.850729 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:24:46.867949 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:24:46.871205 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:24:46.875726 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:24:46.879157 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:24:46.886169 [debug] [Thread-1 (]: Began running node model.sales_analytics.dim_customer
[0m01:24:46.889897 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:24:46.893876 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m01:24:46.897643 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.dim_customer)
[0m01:24:46.901802 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.fct_daily_sales)
[0m01:24:46.905072 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:24:46.908242 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 01:24:46.852407 => 01:24:46.907174
[0m01:24:46.910644 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:24:46.913740 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:24:46.935902 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:24:46.937200 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:24:46.947895 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:24:46.985124 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:24:46.987988 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 01:24:46.987188 => 01:24:46.987225
[0m01:24:46.996824 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:24:47.001696 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:24:47.004012 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 01:24:46.916174 => 01:24:47.003086
[0m01:24:47.005346 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:24:46.939388 => 01:24:47.004630
[0m01:24:47.006809 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:24:46.949555 => 01:24:47.006058
[0m01:24:47.010002 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m01:24:47.012778 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:24:47.015596 [debug] [Thread-1 (]: Began executing node model.sales_analytics.dim_customer
[0m01:24:47.019379 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:24:47.022077 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:24:47.025080 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 01:24:47.024347 => 01:24:47.024377
[0m01:24:47.028400 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:24:47.027695 => 01:24:47.027734
[0m01:24:47.031023 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:24:47.030312 => 01:24:47.030338
[0m01:24:47.046211 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:24:47.049801 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:24:47.054788 [debug] [Thread-1 (]: Finished running node model.sales_analytics.dim_customer
[0m01:24:47.058929 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:24:47.065723 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:24:47.067569 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:24:47.070726 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:24:47.072985 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m01:24:47.076559 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m01:24:47.079881 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m01:24:47.081860 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:24:47.084081 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:24:47.085393 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 01:24:47.033387 => 01:24:47.084876
[0m01:24:47.087276 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:24:47.098848 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:24:47.114817 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:24:47.116372 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:24:47.129216 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:24:47.134603 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 01:24:47.133969 => 01:24:47.134000
[0m01:24:47.139271 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:24:47.142942 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:24:47.146347 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 01:24:47.088773 => 01:24:47.144932
[0m01:24:47.147708 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 01:24:47.118029 => 01:24:47.146994
[0m01:24:47.149399 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 01:24:47.100296 => 01:24:47.148603
[0m01:24:47.151536 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m01:24:47.153677 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:24:47.155604 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:24:47.157649 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:24:47.160179 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:24:47.162223 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 01:24:47.161706 => 01:24:47.161727
[0m01:24:47.164554 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 01:24:47.164065 => 01:24:47.164082
[0m01:24:47.166653 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 01:24:47.166161 => 01:24:47.166178
[0m01:24:47.178566 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:24:47.181515 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:24:47.184556 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:24:47.187848 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:24:47.191471 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:24:47.194047 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:24:47.198526 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m01:24:47.201428 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m01:24:47.203224 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:24:47.205526 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:24:47.207527 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 01:24:47.168391 => 01:24:47.206965
[0m01:24:47.217491 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:24:47.228047 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:24:47.230269 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:24:47.235449 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 01:24:47.234645 => 01:24:47.234675
[0m01:24:47.239656 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:24:47.243769 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 01:24:47.208022 => 01:24:47.242591
[0m01:24:47.245041 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 01:24:47.219136 => 01:24:47.244483
[0m01:24:47.246513 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:24:47.248814 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:24:47.250847 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 01:24:47.250361 => 01:24:47.250379
[0m01:24:47.253256 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 01:24:47.252591 => 01:24:47.252611
[0m01:24:47.256786 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:24:47.260308 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:24:47.266838 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:24:47.269105 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m01:24:47.270774 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m01:24:47.272690 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m01:24:47.275328 [debug] [MainThread]: Connection 'test.sales_analytics.unique_dim_customer_customer_id.b42affccd1' was properly closed.
[0m01:24:47.282054 [debug] [MainThread]: Command end result
[0m01:24:47.371328 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m01:24:47.372640 [info ] [MainThread]: Building catalog
[0m01:24:47.379418 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m01:24:47.397745 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:24:47.400052 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m01:24:47.402235 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:24:47.418840 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:24:47.421455 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:24:47.423904 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m01:24:47.434705 [debug] [ThreadPool]: SQL status: SELECT 35 in 0.0 seconds
[0m01:24:47.451488 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m01:24:47.454797 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m01:24:47.522673 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m01:24:47.528453 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.7661045, "process_user_time": 8.323868, "process_kernel_time": 0.445559, "process_mem_max_rss": "121152", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:24:47.536755 [debug] [MainThread]: Command `dbt docs generate` succeeded at 01:24:47.534962 after 2.77 seconds
[0m01:24:47.541164 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m01:24:47.543751 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m01:24:47.546280 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df343fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df390f890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0df4c2df90>]}
[0m01:24:47.550647 [debug] [MainThread]: Flushing usage events
[0m01:34:29.043825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f320996f290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f320af25950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3209978f50>]}


============================== 01:34:29.056292 | 74d84c30-1bff-47be-8aed-292924916756 ==============================
[0m01:34:29.056292 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:34:29.059628 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:34:29.311469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '74d84c30-1bff-47be-8aed-292924916756', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3209a21450>]}
[0m01:34:29.315035 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:34:29.324200 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:34:29.326453 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.36716375, "process_user_time": 3.782008, "process_kernel_time": 0.150079, "process_mem_max_rss": "104952", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:34:29.328167 [debug] [MainThread]: Command `dbt deps` succeeded at 01:34:29.327888 after 0.37 seconds
[0m01:34:29.329655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32099c6b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32099c71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f320acaa790>]}
[0m01:34:29.332653 [debug] [MainThread]: Flushing usage events
[0m01:34:33.782541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fea4cac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6feb6c7b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6feb0a6e10>]}


============================== 01:34:33.793995 | 4b82cc80-a0db-4161-b612-280ae08358c0 ==============================
[0m01:34:33.793995 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:34:33.796087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m01:34:34.200731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b82cc80-a0db-4161-b612-280ae08358c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6feb0a6e10>]}
[0m01:34:34.442011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4b82cc80-a0db-4161-b612-280ae08358c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe95c8a50>]}
[0m01:34:34.445508 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:34:34.490592 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:34:35.110263 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:34:35.116637 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://snapshots/customers_snapshot.sql
[0m01:34:36.098515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4b82cc80-a0db-4161-b612-280ae08358c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe8974690>]}
[0m01:34:36.241092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4b82cc80-a0db-4161-b612-280ae08358c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe91c6e50>]}
[0m01:34:36.246678 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:34:36.252097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b82cc80-a0db-4161-b612-280ae08358c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe9544650>]}
[0m01:34:36.262424 [info ] [MainThread]: 
[0m01:34:36.269804 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:34:36.279437 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:34:36.347066 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:34:36.352335 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:34:36.355967 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:36.398055 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:34:36.406581 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:34:36.418079 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_marts)
[0m01:34:36.424243 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:34:36.428800 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:34:36.433934 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:34:36.475124 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:34:36.477149 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:34:36.489755 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:34:36.502558 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:34:36.505837 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:34:36.510557 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:34:36.515045 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:34:36.519105 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:34:36.522822 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:36.526724 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:34:36.531171 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:36.536051 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:36.574929 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:36.577165 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:36.580986 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:36.582546 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:34:36.584040 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:36.587613 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:34:36.591192 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:34:36.608339 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:34:36.613542 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:34:36.618532 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:34:36.623190 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:34:36.630765 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:34:36.647945 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:36.653327 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:36.661590 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:36.663234 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:36.659594 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:34:36.672480 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:34:36.680268 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:34:36.688335 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:34:36.693311 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:34:36.696828 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:34:36.699667 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:34:36.704341 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:34:36.749356 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:36.753593 [debug] [MainThread]: On master: BEGIN
[0m01:34:36.758051 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:34:36.785922 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:34:36.790983 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:36.795086 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:34:36.821328 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:36.831663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b82cc80-a0db-4161-b612-280ae08358c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe91c5e50>]}
[0m01:34:36.836715 [debug] [MainThread]: On master: ROLLBACK
[0m01:34:36.842541 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:36.847129 [debug] [MainThread]: On master: BEGIN
[0m01:34:36.853814 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:34:36.857942 [debug] [MainThread]: On master: COMMIT
[0m01:34:36.862446 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:36.867185 [debug] [MainThread]: On master: COMMIT
[0m01:34:36.872714 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:34:36.877630 [debug] [MainThread]: On master: Close
[0m01:34:36.884480 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:34:36.894801 [info ] [MainThread]: 
[0m01:34:36.953827 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:34:36.960240 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m01:34:36.977215 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m01:34:36.988206 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:34:37.053096 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:34:36.991689 => 01:34:37.051380
[0m01:34:37.058787 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:34:37.316151 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:37.321264 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m01:34:37.325301 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:34:37.352375 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:34:37.357468 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:37.362699 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
[0m01:34:37.403245 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m01:34:37.595299 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:37.605107 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

        
  
    

  create temporary table "customers_snapshot__dbt_tmp013437498720"
  
  
    as
  
  (
    with snapshot_query as (

        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"


    ),

    snapshotted_data as (

        select *,
            customer_id as dbt_unique_key

        from "warehouse"."snapshots"."customers_snapshot"
        where dbt_valid_to is null

    ),

    insertions_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            nullif(updated_at, updated_at) as dbt_valid_to,
            md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select
            *,
            customer_id as dbt_unique_key,
            updated_at as dbt_updated_at,
            updated_at as dbt_valid_from,
            updated_at as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where snapshotted_data.dbt_unique_key is null
           or (
                snapshotted_data.dbt_unique_key is not null
            and (
                (snapshotted_data.dbt_valid_from < source_data.updated_at)
            )
        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
        where (
            (snapshotted_data.dbt_valid_from < source_data.updated_at)
        )
    )

    select * from insertions
    union all
    select * from updates

  );
  
    
[0m01:34:38.503110 [debug] [Thread-1 (]: SQL status: SELECT 26682 in 1.0 seconds
[0m01:34:38.521079 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:38.526750 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp013437498720'
        
      order by ordinal_position

  
[0m01:34:38.543700 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m01:34:38.568782 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:38.577553 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
[0m01:34:38.593759 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m01:34:38.614886 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:38.619942 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp013437498720'
        
      order by ordinal_position

  
[0m01:34:38.633706 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m01:34:38.656762 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:38.662118 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot'
        
        and table_schema = 'snapshots'
        
      order by ordinal_position

  
[0m01:34:38.677002 [debug] [Thread-1 (]: SQL status: SELECT 8 in 0.0 seconds
[0m01:34:38.837836 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:38.843206 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'customers_snapshot__dbt_tmp013437498720'
        
      order by ordinal_position

  
[0m01:34:38.857053 [debug] [Thread-1 (]: SQL status: SELECT 10 in 0.0 seconds
[0m01:34:38.891021 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m01:34:38.930826 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:38.935862 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      update "warehouse"."snapshots"."customers_snapshot"
    set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to
    from "customers_snapshot__dbt_tmp013437498720" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_scd_id::text = "warehouse"."snapshots"."customers_snapshot".dbt_scd_id::text
      and DBT_INTERNAL_SOURCE.dbt_change_type::text in ('update'::text, 'delete'::text)
      and "warehouse"."snapshots"."customers_snapshot".dbt_valid_to is null;

    insert into "warehouse"."snapshots"."customers_snapshot" ("customer_id", "country", "status", "updated_at", "dbt_updated_at", "dbt_valid_from", "dbt_valid_to", "dbt_scd_id")
    select DBT_INTERNAL_SOURCE."customer_id",DBT_INTERNAL_SOURCE."country",DBT_INTERNAL_SOURCE."status",DBT_INTERNAL_SOURCE."updated_at",DBT_INTERNAL_SOURCE."dbt_updated_at",DBT_INTERNAL_SOURCE."dbt_valid_from",DBT_INTERNAL_SOURCE."dbt_valid_to",DBT_INTERNAL_SOURCE."dbt_scd_id"
    from "customers_snapshot__dbt_tmp013437498720" as DBT_INTERNAL_SOURCE
    where DBT_INTERNAL_SOURCE.dbt_change_type::text = 'insert'::text;

  
[0m01:34:39.388264 [debug] [Thread-1 (]: SQL status: INSERT 0 13341 in 0.0 seconds
[0m01:34:39.549207 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:34:39.561301 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:34:39.567778 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:34:39.583582 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:34:39.617931 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:34:37.062450 => 01:34:39.615807
[0m01:34:39.630374 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m01:34:39.643965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b82cc80-a0db-4161-b612-280ae08358c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fe8dd1190>]}
[0m01:34:39.652212 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mINSERT 0 13341[0m in 2.67s]
[0m01:34:39.659743 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:34:39.676725 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:39.682555 [debug] [MainThread]: On master: BEGIN
[0m01:34:39.686303 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:34:39.734858 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:34:39.742573 [debug] [MainThread]: On master: COMMIT
[0m01:34:39.748697 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:39.755067 [debug] [MainThread]: On master: COMMIT
[0m01:34:39.761276 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:34:39.767196 [debug] [MainThread]: On master: Close
[0m01:34:39.777443 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:34:39.785138 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m01:34:39.790370 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m01:34:39.804580 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m01:34:39.817802 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m01:34:39.824591 [info ] [MainThread]: 
[0m01:34:39.832135 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 3.56 seconds (3.56s).
[0m01:34:39.842786 [debug] [MainThread]: Command end result
[0m01:34:40.018599 [info ] [MainThread]: 
[0m01:34:40.028981 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:34:40.039067 [info ] [MainThread]: 
[0m01:34:40.047364 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:34:40.071183 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 6.3736086, "process_user_time": 7.081885, "process_kernel_time": 0.415998, "process_mem_max_rss": "123800", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:34:40.078469 [debug] [MainThread]: Command `dbt snapshot` succeeded at 01:34:40.077231 after 6.38 seconds
[0m01:34:40.089254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fea507490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6fea5074d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6febc9fad0>]}
[0m01:34:40.105104 [debug] [MainThread]: Flushing usage events
[0m01:34:47.165736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0f74550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0fa1850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb2292c90>]}


============================== 01:34:47.173907 | 6bd3ea4f-2647-46cf-99f0-11ea6d53158b ==============================
[0m01:34:47.173907 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:34:47.175497 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m01:34:47.427621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0ffc310>]}
[0m01:34:47.546038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0ffc310>]}
[0m01:34:47.548527 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:34:47.569177 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:34:47.713829 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:34:47.715531 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:34:47.724499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8faff700d0>]}
[0m01:34:47.762800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb032d110>]}
[0m01:34:47.764436 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:34:47.765940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8faff8e410>]}
[0m01:34:47.769923 [info ] [MainThread]: 
[0m01:34:47.772168 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:34:47.776718 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:34:47.779170 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:34:47.780688 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:34:47.799047 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:34:47.802614 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:34:47.810054 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:34:47.813086 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:34:47.815440 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:34:47.817710 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:34:47.819757 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:47.821423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:47.825105 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:47.837923 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:34:47.839403 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:34:47.840162 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:34:47.843182 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:34:47.846966 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:34:47.850408 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:34:47.859151 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_snapshots)
[0m01:34:47.860469 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_marts)
[0m01:34:47.861705 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_staging)
[0m01:34:47.863165 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:34:47.872506 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:34:47.876768 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:34:47.881007 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:34:47.884999 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:34:47.887400 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:34:47.890664 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:34:47.892662 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:34:47.894872 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:34:47.896575 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:34:47.898351 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:34:47.899761 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:34:47.900759 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:47.909157 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:47.910661 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:47.911253 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:47.911883 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:34:47.912501 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:47.913891 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:34:47.915548 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:34:47.916877 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:34:47.918481 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:34:47.919795 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:34:47.921030 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:34:47.922441 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:34:47.925423 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:47.926093 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:47.927885 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:34:47.928414 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:47.928890 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:47.930876 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:34:47.932150 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:34:47.934074 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:34:47.936036 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:34:47.937289 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:34:47.939633 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:34:47.940554 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:34:47.951350 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:47.952791 [debug] [MainThread]: On master: BEGIN
[0m01:34:47.954210 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:34:47.962176 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:34:47.963855 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:47.965473 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:34:47.971278 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:47.973952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb1bd5350>]}
[0m01:34:47.975886 [debug] [MainThread]: On master: ROLLBACK
[0m01:34:47.978281 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:47.979464 [debug] [MainThread]: On master: BEGIN
[0m01:34:47.981157 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:34:47.982483 [debug] [MainThread]: On master: COMMIT
[0m01:34:47.983688 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:47.984840 [debug] [MainThread]: On master: COMMIT
[0m01:34:47.986270 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:34:47.987586 [debug] [MainThread]: On master: Close
[0m01:34:47.989415 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:34:47.990665 [info ] [MainThread]: 
[0m01:34:48.002579 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:34:48.004064 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m01:34:48.005894 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.src_orders)
[0m01:34:48.007520 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:34:48.022740 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:34:48.033913 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:34:48.008716 => 01:34:48.033470
[0m01:34:48.035044 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:34:48.098219 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m01:34:48.117059 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.118463 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m01:34:48.119592 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:34:48.128367 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:34:48.130026 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.131387 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m01:34:48.134374 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m01:34:48.143316 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.144960 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders" rename to "src_orders__dbt_backup"
[0m01:34:48.147272 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:34:48.152147 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.153723 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m01:34:48.155539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:34:48.189978 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.192007 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m01:34:48.194436 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:34:48.213254 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.215715 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m01:34:48.226912 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m01:34:48.235887 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.238423 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:34:48.241053 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:34:48.244073 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:34:48.246265 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.248597 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:34:48.254627 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:34:48.266361 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m01:34:48.275239 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:34:48.277641 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m01:34:48.284614 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m01:34:48.288267 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:34:48.035835 => 01:34:48.287994
[0m01:34:48.289773 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m01:34:48.292200 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8faff47f50>]}
[0m01:34:48.294336 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 0.29s]
[0m01:34:48.296091 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:34:48.297909 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m01:34:48.298519 [debug] [Thread-4 (]: Began running node model.sales_analytics.orders_enriched
[0m01:34:48.299523 [info ] [Thread-3 (]: 2 of 4 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m01:34:48.300611 [info ] [Thread-4 (]: 3 of 4 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m01:34:48.302421 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.dim_customer)
[0m01:34:48.304112 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.orders_enriched)
[0m01:34:48.380259 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:34:48.385152 [debug] [Thread-4 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:34:48.394950 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:34:48.410653 [debug] [Thread-4 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:34:48.426876 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:34:48.401462 => 01:34:48.426220
[0m01:34:48.428738 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:34:48.387413 => 01:34:48.428249
[0m01:34:48.430150 [debug] [Thread-4 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:34:48.432636 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m01:34:48.500298 [debug] [Thread-4 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m01:34:48.504243 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m01:34:48.512626 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:34:48.513425 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.514565 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: BEGIN
[0m01:34:48.515540 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m01:34:48.516426 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:34:48.517299 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:34:48.525562 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m01:34:48.526182 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m01:34:48.527164 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:34:48.528194 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.529326 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

with current as (
  select *
  from "warehouse"."snapshots"."customers_snapshot"
  where dbt_is_current = true
)
select
  customer_id,
  country,
  status,
  dbt_valid_from as valid_from
from current
  );
  
[0m01:34:48.530314 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m01:34:48.531835 [debug] [Thread-3 (]: Postgres adapter: Postgres error: column "dbt_is_current" does not exist
LINE 17:   where dbt_is_current = true
                 ^

[0m01:34:48.532694 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: ROLLBACK
[0m01:34:48.533902 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:34:48.459076 => 01:34:48.533613
[0m01:34:48.534680 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: Close
[0m01:34:48.539820 [debug] [Thread-3 (]: Database Error in model dim_customer (models/marts/dim_customer.sql)
  column "dbt_is_current" does not exist
  LINE 17:   where dbt_is_current = true
                   ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m01:34:48.541213 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0338790>]}
[0m01:34:48.542835 [error] [Thread-3 (]: 2 of 4 ERROR creating sql table model analytics_marts.dim_customer ............. [[31mERROR[0m in 0.24s]
[0m01:34:48.544357 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m01:34:48.575849 [debug] [Thread-4 (]: SQL status: SELECT 21455 in 0.0 seconds
[0m01:34:48.582512 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.584750 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched" rename to "orders_enriched__dbt_backup"
[0m01:34:48.587886 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:34:48.593811 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.595923 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m01:34:48.598456 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:34:48.609443 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.612194 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m01:34:48.615168 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:34:48.622000 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.624179 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m01:34:48.634275 [debug] [Thread-4 (]: SQL status: SELECT 12 in 0.0 seconds
[0m01:34:48.639044 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.640730 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:34:48.643191 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:34:48.646101 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:34:48.647754 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.649193 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:34:48.666122 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m01:34:48.671435 [debug] [Thread-4 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m01:34:48.676484 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:34:48.678470 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m01:34:48.685048 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m01:34:48.687909 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:34:48.434321 => 01:34:48.687701
[0m01:34:48.689793 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: Close
[0m01:34:48.691984 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8faff267d0>]}
[0m01:34:48.693624 [info ] [Thread-4 (]: 3 of 4 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 21455[0m in 0.39s]
[0m01:34:48.695081 [debug] [Thread-4 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:34:48.697130 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:34:48.698079 [info ] [Thread-1 (]: 4 of 4 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m01:34:48.699537 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now model.sales_analytics.fct_daily_sales)
[0m01:34:48.700499 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:34:48.713959 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:34:48.725281 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:34:48.701155 => 01:34:48.724695
[0m01:34:48.726539 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:34:48.780198 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:48.783011 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
    

  create temporary table "fct_daily_sales__dbt_tmp013448770298"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
      and date_trunc('day', order_ts)::date >= (
        coalesce( (select max(sales_date) from "warehouse"."analytics_marts"."fct_daily_sales"), '1900-01-01'::date )
        - interval '2 day'
      )
    
    group by 1
)
select * from base
  );
  
  
[0m01:34:48.785738 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:34:48.809140 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.0 seconds
[0m01:34:48.815732 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:48.818039 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m01:34:48.820171 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:34:48.822371 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:48.824416 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp013448770298'
        
      order by ordinal_position

  
[0m01:34:48.834816 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:34:48.841758 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:48.844178 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:34:48.850351 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:34:48.925510 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:48.928501 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp013448770298'
        
      order by ordinal_position

  
[0m01:34:48.933756 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:34:48.939768 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:48.941758 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:34:48.946713 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:34:48.963043 [debug] [Thread-1 (]: 
    In "warehouse"."analytics_marts"."fct_daily_sales":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m01:34:48.982858 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m01:34:48.996973 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:48.998260 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
        
            delete from "warehouse"."analytics_marts"."fct_daily_sales"
            where (
                sales_date) in (
                select (sales_date)
                from "fct_daily_sales__dbt_tmp013448770298"
            );

        
    

    insert into "warehouse"."analytics_marts"."fct_daily_sales" ("sales_date", "orders", "units_sold", "gross_revenue")
    (
        select "sales_date", "orders", "units_sold", "gross_revenue"
        from "fct_daily_sales__dbt_tmp013448770298"
    )
  
[0m01:34:49.000303 [debug] [Thread-1 (]: SQL status: INSERT 0 3 in 0.0 seconds
[0m01:34:49.004667 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:49.006446 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m01:34:49.010493 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:34:49.017686 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:49.019738 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:34:49.025280 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:34:49.030552 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:49.032450 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:34:49.035136 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:34:49.041126 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:49.043231 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m01:34:49.045906 [debug] [Thread-1 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m01:34:49.049993 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:34:49.052500 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:34:49.054937 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:34:49.061602 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:34:49.065249 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:34:48.727289 => 01:34:49.064825
[0m01:34:49.067581 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: Close
[0m01:34:49.070904 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6bd3ea4f-2647-46cf-99f0-11ea6d53158b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8faf7a7f50>]}
[0m01:34:49.073660 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mINSERT 0 3[0m in 0.37s]
[0m01:34:49.076218 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:34:49.082091 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:49.084555 [debug] [MainThread]: On master: BEGIN
[0m01:34:49.086470 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:34:49.104182 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:34:49.107484 [debug] [MainThread]: On master: COMMIT
[0m01:34:49.109523 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:49.111303 [debug] [MainThread]: On master: COMMIT
[0m01:34:49.113667 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:34:49.115602 [debug] [MainThread]: On master: Close
[0m01:34:49.118352 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:34:49.120265 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m01:34:49.122781 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m01:34:49.128224 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m01:34:49.130532 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m01:34:49.133046 [info ] [MainThread]: 
[0m01:34:49.135144 [info ] [MainThread]: Finished running 1 view model, 2 table models, 1 incremental model in 0 hours 0 minutes and 1.36 seconds (1.36s).
[0m01:34:49.139746 [debug] [MainThread]: Command end result
[0m01:34:49.201458 [info ] [MainThread]: 
[0m01:34:49.210643 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:34:49.213078 [info ] [MainThread]: 
[0m01:34:49.215141 [error] [MainThread]:   Database Error in model dim_customer (models/marts/dim_customer.sql)
  column "dbt_is_current" does not exist
  LINE 17:   where dbt_is_current = true
                   ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m01:34:49.220907 [info ] [MainThread]: 
[0m01:34:49.228529 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m01:34:49.233741 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 2.1319494, "process_user_time": 6.889556, "process_kernel_time": 0.339978, "process_mem_max_rss": "124588", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:34:49.236490 [debug] [MainThread]: Command `dbt run` failed at 01:34:49.235854 after 2.13 seconds
[0m01:34:49.240193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0f62290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0f6fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8fb0f6e550>]}
[0m01:34:49.243717 [debug] [MainThread]: Flushing usage events
[0m01:34:56.435633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4887603cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4888da3f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4887a10e50>]}


============================== 01:34:56.444456 | ee8d9e5c-9235-4709-b5dc-a391e679a8bd ==============================
[0m01:34:56.444456 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:34:56.445990 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'profiles_dir': '/usr/app', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m01:34:56.684867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee8d9e5c-9235-4709-b5dc-a391e679a8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48875b7910>]}
[0m01:34:56.824819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee8d9e5c-9235-4709-b5dc-a391e679a8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4886d49e10>]}
[0m01:34:56.827597 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:34:56.858259 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:34:57.033803 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:34:57.035063 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:34:57.044130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee8d9e5c-9235-4709-b5dc-a391e679a8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4886d66f50>]}
[0m01:34:57.058178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee8d9e5c-9235-4709-b5dc-a391e679a8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48865bfbd0>]}
[0m01:34:57.059467 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:34:57.060924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee8d9e5c-9235-4709-b5dc-a391e679a8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4886d95b50>]}
[0m01:34:57.065075 [info ] [MainThread]: 
[0m01:34:57.067694 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:34:57.072066 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:34:57.074238 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:34:57.077536 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:34:57.080232 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:34:57.102157 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:34:57.108500 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:34:57.113200 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:34:57.118791 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:34:57.121050 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:34:57.123342 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:34:57.125931 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:34:57.128287 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:34:57.130295 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:57.132015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:57.134712 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:57.136984 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:57.148496 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:57.150235 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:57.150832 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:57.151447 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:34:57.152960 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:57.154095 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:34:57.156772 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:34:57.159232 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:34:57.160972 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:34:57.163084 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:34:57.164802 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:34:57.168150 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:34:57.172849 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:57.176580 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:34:57.177467 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:57.178143 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:57.178777 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:57.180682 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:34:57.184325 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:34:57.188399 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:34:57.192526 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:34:57.196869 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:34:57.198344 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:34:57.199445 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:34:57.211614 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:57.213215 [debug] [MainThread]: On master: BEGIN
[0m01:34:57.214746 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:34:57.224085 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:34:57.225727 [debug] [MainThread]: Using postgres connection "master"
[0m01:34:57.227392 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:34:57.234365 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:34:57.237371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee8d9e5c-9235-4709-b5dc-a391e679a8bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4886dbb550>]}
[0m01:34:57.239001 [debug] [MainThread]: On master: ROLLBACK
[0m01:34:57.240948 [debug] [MainThread]: On master: Close
[0m01:34:57.243080 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:34:57.244584 [info ] [MainThread]: 
[0m01:34:57.256230 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:34:57.258122 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m01:34:57.259310 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:34:57.269710 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:34:57.282379 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:34:57.260409 => 01:34:57.281777
[0m01:34:57.284538 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:34:57.286867 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:34:57.286278 => 01:34:57.286326
[0m01:34:57.289466 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:34:57.292141 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m01:34:57.293226 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:34:57.293979 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:34:57.294811 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:34:57.296325 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m01:34:57.298623 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m01:34:57.303055 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m01:34:57.306163 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m01:34:57.307624 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:34:57.309575 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:34:57.311268 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:34:57.312983 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:34:57.319356 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:34:57.327473 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:34:57.321115 => 01:34:57.327055
[0m01:34:57.350157 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:34:57.357791 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:34:57.361000 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:34:57.365237 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:34:57.364810 => 01:34:57.364834
[0m01:34:57.367473 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:34:57.370041 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:34:57.371619 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 01:34:57.350768 => 01:34:57.371069
[0m01:34:57.372730 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:34:57.314280 => 01:34:57.372193
[0m01:34:57.374812 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m01:34:57.375867 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 01:34:57.328774 => 01:34:57.375424
[0m01:34:57.377508 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:34:57.379896 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:34:57.381539 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:34:57.384306 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:34:57.386823 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 01:34:57.386311 => 01:34:57.386342
[0m01:34:57.389390 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:34:57.389039 => 01:34:57.389058
[0m01:34:57.399690 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:34:57.401691 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 01:34:57.401152 => 01:34:57.401182
[0m01:34:57.404436 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:34:57.407868 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:34:57.412616 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:34:57.414098 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:34:57.415778 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m01:34:57.417383 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:34:57.418872 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m01:34:57.420299 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.dim_customer)
[0m01:34:57.421841 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.fct_daily_sales)
[0m01:34:57.422593 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 01:34:57.391169 => 01:34:57.422312
[0m01:34:57.423399 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:34:57.424418 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:34:57.425424 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:34:57.426413 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:34:57.434023 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:34:57.439317 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:34:57.455302 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:34:57.457165 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 01:34:57.456642 => 01:34:57.456662
[0m01:34:57.465376 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:34:57.467123 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:34:57.469038 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m01:34:57.471242 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:34:57.472685 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:34:57.435100 => 01:34:57.472152
[0m01:34:57.473624 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:34:57.440710 => 01:34:57.473268
[0m01:34:57.474547 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 01:34:57.427181 => 01:34:57.474195
[0m01:34:57.482321 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:34:57.484104 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m01:34:57.486225 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:34:57.488821 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:34:57.492400 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:34:57.492027 => 01:34:57.492048
[0m01:34:57.494189 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:34:57.493781 => 01:34:57.493803
[0m01:34:57.495704 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 01:34:57.495362 => 01:34:57.495375
[0m01:34:57.497754 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m01:34:57.499775 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:34:57.502255 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:34:57.503059 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 01:34:57.475020 => 01:34:57.502740
[0m01:34:57.504844 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:34:57.505533 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:34:57.507086 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:34:57.508310 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:34:57.509917 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m01:34:57.511729 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m01:34:57.513387 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m01:34:57.514832 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 01:34:57.514467 => 01:34:57.514482
[0m01:34:57.515962 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:34:57.517074 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:34:57.518154 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:34:57.519998 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:34:57.527800 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:34:57.539535 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:34:57.547907 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:34:57.550188 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:34:57.556373 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m01:34:57.558082 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:34:57.567254 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:34:57.569845 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 01:34:57.529165 => 01:34:57.569067
[0m01:34:57.570829 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 01:34:57.541286 => 01:34:57.570313
[0m01:34:57.572796 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 01:34:57.520979 => 01:34:57.572303
[0m01:34:57.574316 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:34:57.575713 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:34:57.577358 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:34:57.578875 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 01:34:57.578425 => 01:34:57.578440
[0m01:34:57.580472 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 01:34:57.580050 => 01:34:57.580064
[0m01:34:57.582762 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 01:34:57.582274 => 01:34:57.582296
[0m01:34:57.583842 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 01:34:57.559041 => 01:34:57.583428
[0m01:34:57.585544 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:34:57.587470 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:34:57.589462 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:34:57.590713 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:34:57.591966 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:34:57.593214 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:34:57.595151 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 01:34:57.594814 => 01:34:57.594826
[0m01:34:57.596847 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.unique_dim_customer_customer_id.b42affccd1, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m01:34:57.598621 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m01:34:57.600579 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:34:57.601753 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:34:57.602925 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:34:57.611314 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:34:57.619754 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:34:57.631107 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 01:34:57.604538 => 01:34:57.630404
[0m01:34:57.632266 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 01:34:57.612618 => 01:34:57.631755
[0m01:34:57.633609 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:34:57.634876 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:34:57.636154 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 01:34:57.635826 => 01:34:57.635841
[0m01:34:57.637475 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 01:34:57.637126 => 01:34:57.637140
[0m01:34:57.639851 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:34:57.642343 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:34:57.646105 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:34:57.647432 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m01:34:57.648642 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m01:34:57.649882 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m01:34:57.650959 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m01:34:57.655198 [debug] [MainThread]: Command end result
[0m01:34:57.721118 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m01:34:57.722368 [info ] [MainThread]: Building catalog
[0m01:34:57.727819 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m01:34:57.740726 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:34:57.743067 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m01:34:57.744965 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:34:57.757806 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:34:57.760445 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:34:57.762866 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m01:34:57.770758 [debug] [ThreadPool]: SQL status: SELECT 35 in 0.0 seconds
[0m01:34:57.780658 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m01:34:57.782972 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m01:34:57.830339 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m01:34:57.832986 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.4795691, "process_user_time": 4.832537, "process_kernel_time": 0.276145, "process_mem_max_rss": "121360", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:34:57.834687 [debug] [MainThread]: Command `dbt docs generate` succeeded at 01:34:57.834484 after 1.48 seconds
[0m01:34:57.835889 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m01:34:57.837029 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m01:34:57.838569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4887613650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4887613a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f488c1bcf50>]}
[0m01:34:57.840424 [debug] [MainThread]: Flushing usage events
[0m01:49:41.193707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf7b8252d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf7b9e0150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf7b9e2bd0>]}


============================== 01:49:41.209326 | 0cabca6a-13c5-473f-8e4e-ab8921b3e873 ==============================
[0m01:49:41.209326 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:49:41.213034 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m01:49:41.402226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0cabca6a-13c5-473f-8e4e-ab8921b3e873', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf7b82d1d0>]}
[0m01:49:41.406749 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:49:41.421325 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:49:41.424633 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.34604993, "process_user_time": 11.681146, "process_kernel_time": 1.200117, "process_mem_max_rss": "104552", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:49:41.427233 [debug] [MainThread]: Command `dbt deps` succeeded at 01:49:41.426806 after 0.35 seconds
[0m01:49:41.434564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf7b837010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf7b836a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faf7cdf25d0>]}
[0m01:49:41.438531 [debug] [MainThread]: Flushing usage events
[0m01:49:48.222417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd887b56d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd887b54050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd887b57710>]}


============================== 01:49:48.235881 | d56c6c3a-4034-4335-9b0e-d74dc29c4d71 ==============================
[0m01:49:48.235881 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:49:48.238269 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:49:48.601965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd56c6c3a-4034-4335-9b0e-d74dc29c4d71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd887339910>]}
[0m01:49:48.777065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd56c6c3a-4034-4335-9b0e-d74dc29c4d71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd889353390>]}
[0m01:49:48.779245 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:49:48.810809 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:49:49.085537 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m01:49:49.087919 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/dim_customer.sql
[0m01:49:49.712275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd56c6c3a-4034-4335-9b0e-d74dc29c4d71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd885f592d0>]}
[0m01:49:49.782319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd56c6c3a-4034-4335-9b0e-d74dc29c4d71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd886bde2d0>]}
[0m01:49:49.789584 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:49:49.794093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd56c6c3a-4034-4335-9b0e-d74dc29c4d71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd886fd3c90>]}
[0m01:49:49.802166 [info ] [MainThread]: 
[0m01:49:49.813866 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:49:49.825332 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:49:49.875443 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:49:49.878414 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:49:49.881643 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:49:49.904044 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:49:49.909317 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:49:49.915607 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_intermediate)
[0m01:49:49.920067 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:49:49.934251 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:49:49.944207 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:49:49.952715 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:49:49.955938 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:49:50.079271 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:49:50.082146 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:49:50.094368 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:49:50.096811 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:49:50.100035 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:49:50.102906 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:49:50.105665 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:49:50.108538 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:49:50.111298 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:49:50.117451 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:49:50.141247 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.143932 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:49:50.145703 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.147213 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:49:50.149095 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.150614 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:49:50.154291 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.156868 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:49:50.159391 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:49:50.161697 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:49:50.162570 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:49:50.164030 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:49:50.167777 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:49:50.173368 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:49:50.175477 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:49:50.179846 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:49:50.185082 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:49:50.186255 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:49:50.187203 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m01:49:50.192202 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:49:50.195338 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:49:50.199847 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:49:50.205559 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:49:50.207221 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:49:50.229227 [debug] [MainThread]: Using postgres connection "master"
[0m01:49:50.231231 [debug] [MainThread]: On master: BEGIN
[0m01:49:50.232864 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:49:50.245591 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.248641 [debug] [MainThread]: Using postgres connection "master"
[0m01:49:50.250862 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:49:50.263264 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:49:50.267409 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd56c6c3a-4034-4335-9b0e-d74dc29c4d71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd885f7f9d0>]}
[0m01:49:50.269207 [debug] [MainThread]: On master: ROLLBACK
[0m01:49:50.271370 [debug] [MainThread]: Using postgres connection "master"
[0m01:49:50.272773 [debug] [MainThread]: On master: BEGIN
[0m01:49:50.274961 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.276477 [debug] [MainThread]: On master: COMMIT
[0m01:49:50.277922 [debug] [MainThread]: Using postgres connection "master"
[0m01:49:50.279310 [debug] [MainThread]: On master: COMMIT
[0m01:49:50.281237 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:49:50.282701 [debug] [MainThread]: On master: Close
[0m01:49:50.284987 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:49:50.286903 [info ] [MainThread]: 
[0m01:49:50.308764 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:49:50.311237 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m01:49:50.314598 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m01:49:50.316925 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:49:50.340718 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:49:50.318657 => 01:49:50.339758
[0m01:49:50.344961 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:49:50.467365 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m01:49:50.484348 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:49:50.487045 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m01:49:50.489262 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:49:50.503168 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.505133 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:49:50.507327 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m01:49:50.650064 [debug] [Thread-1 (]: SQL status: SELECT 30000 in 0.0 seconds
[0m01:49:50.691164 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:49:50.693668 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m01:49:50.696110 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m01:49:50.717086 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:49:50.720313 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:49:50.347032 => 01:49:50.719937
[0m01:49:50.722221 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m01:49:50.725168 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd56c6c3a-4034-4335-9b0e-d74dc29c4d71', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd887c9c990>]}
[0m01:49:50.727677 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSELECT 30000[0m in 0.41s]
[0m01:49:50.730082 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:49:50.734747 [debug] [MainThread]: Using postgres connection "master"
[0m01:49:50.736229 [debug] [MainThread]: On master: BEGIN
[0m01:49:50.737671 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:49:50.750367 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:49:50.752163 [debug] [MainThread]: On master: COMMIT
[0m01:49:50.753955 [debug] [MainThread]: Using postgres connection "master"
[0m01:49:50.755818 [debug] [MainThread]: On master: COMMIT
[0m01:49:50.758227 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:49:50.760084 [debug] [MainThread]: On master: Close
[0m01:49:50.762615 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:49:50.764321 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m01:49:50.765720 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m01:49:50.767203 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m01:49:50.768789 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m01:49:50.770860 [info ] [MainThread]: 
[0m01:49:50.773917 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.96 seconds (0.96s).
[0m01:49:50.776704 [debug] [MainThread]: Command end result
[0m01:49:50.826618 [info ] [MainThread]: 
[0m01:49:50.829155 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:49:50.831642 [info ] [MainThread]: 
[0m01:49:50.834818 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:49:50.840407 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 2.7126522, "process_user_time": 7.579685, "process_kernel_time": 0.328254, "process_mem_max_rss": "127336", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:49:50.843389 [debug] [MainThread]: Command `dbt snapshot` succeeded at 01:49:50.842878 after 2.72 seconds
[0m01:49:50.846138 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd887f56090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd889327d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd88926e490>]}
[0m01:49:50.850726 [debug] [MainThread]: Flushing usage events
[0m01:50:03.763304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b33087ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b33087f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b33085350>]}


============================== 01:50:03.799553 | 301b3d07-0101-4e56-b492-9d7d0d36df8a ==============================
[0m01:50:03.799553 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:50:03.803855 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m01:50:04.804790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b32a83d10>]}
[0m01:50:05.444682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b33078f10>]}
[0m01:50:05.453297 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:50:05.562638 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:50:06.436477 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:06.444267 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:06.502296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b323ef1d0>]}
[0m01:50:06.632756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b32b528d0>]}
[0m01:50:06.644990 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:50:06.650423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b327de310>]}
[0m01:50:06.666603 [info ] [MainThread]: 
[0m01:50:06.671936 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:50:06.684911 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:50:06.698192 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:50:06.707167 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m01:50:06.810134 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:50:06.841625 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:50:06.843330 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m01:50:06.845208 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:50:06.848056 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:50:06.854878 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m01:50:06.863503 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:06.867694 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:06.871545 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:06.918083 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:50:06.922564 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:50:06.925490 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m01:50:06.933965 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:50:06.940631 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:50:06.948103 [debug] [ThreadPool]: On list_warehouse: Close
[0m01:50:06.983751 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_staging)
[0m01:50:06.987108 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_snapshots)
[0m01:50:06.990970 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_intermediate)
[0m01:50:07.000094 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:50:07.036863 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:50:07.043276 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:50:07.055260 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:50:07.065781 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:50:07.070649 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:50:07.076135 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:50:07.082501 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:50:07.084853 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:50:07.087221 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:50:07.089575 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:50:07.091777 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:50:07.093865 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:07.117300 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:07.118433 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:07.119433 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:07.121741 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:07.122743 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:50:07.125023 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:50:07.127015 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:50:07.129046 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:50:07.131466 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:50:07.133486 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:50:07.135208 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:50:07.137147 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:50:07.147882 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:07.149458 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:07.150365 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:07.151182 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:07.154492 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:50:07.158247 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:50:07.161988 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:50:07.165246 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:50:07.167388 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:50:07.168891 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:50:07.170380 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:50:07.171976 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:50:07.193684 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:07.195728 [debug] [MainThread]: On master: BEGIN
[0m01:50:07.197520 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:50:07.210255 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:50:07.212020 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:07.213671 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:50:07.222970 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:07.229853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b33ce5a90>]}
[0m01:50:07.231841 [debug] [MainThread]: On master: ROLLBACK
[0m01:50:07.233441 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:07.234985 [debug] [MainThread]: On master: BEGIN
[0m01:50:07.237082 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:50:07.238823 [debug] [MainThread]: On master: COMMIT
[0m01:50:07.240336 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:07.241753 [debug] [MainThread]: On master: COMMIT
[0m01:50:07.243264 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:50:07.244688 [debug] [MainThread]: On master: Close
[0m01:50:07.247212 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:50:07.249331 [info ] [MainThread]: 
[0m01:50:07.267615 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:50:07.270048 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m01:50:07.273151 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m01:50:07.276327 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:50:07.297226 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:50:07.317228 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:50:07.279006 => 01:50:07.316388
[0m01:50:07.319762 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:50:07.426972 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m01:50:07.455174 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:07.458876 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m01:50:07.470663 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:50:07.524996 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:07.538829 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:07.548810 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m01:50:07.562210 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m01:50:07.617389 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:07.622030 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders" rename to "src_orders__dbt_backup"
[0m01:50:07.627258 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:50:07.647137 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:07.655354 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m01:50:07.670081 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:50:07.873434 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:07.881220 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m01:50:07.890485 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:07.965847 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:07.970443 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m01:50:08.014415 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m01:50:08.046835 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:08.052008 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:50:08.059016 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:08.066187 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:50:08.069593 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:08.072645 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m01:50:08.108005 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:50:08.148926 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m01:50:08.191530 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m01:50:08.201846 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m01:50:08.211606 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m01:50:08.220070 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:50:07.322193 => 01:50:08.219233
[0m01:50:08.227314 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m01:50:08.233819 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b323aadd0>]}
[0m01:50:08.242230 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 0.96s]
[0m01:50:08.246320 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:50:08.252680 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m01:50:08.254309 [debug] [Thread-4 (]: Began running node model.sales_analytics.orders_enriched
[0m01:50:08.257451 [info ] [Thread-3 (]: 2 of 4 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m01:50:08.264292 [info ] [Thread-4 (]: 3 of 4 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m01:50:08.269087 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.dim_customer)
[0m01:50:08.279958 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:50:08.276165 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.orders_enriched)
[0m01:50:08.302052 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:50:08.304632 [debug] [Thread-4 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:50:08.328032 [debug] [Thread-4 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:50:08.360964 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:50:08.283529 => 01:50:08.358625
[0m01:50:08.364571 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m01:50:08.366368 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:50:08.315703 => 01:50:08.365468
[0m01:50:08.406164 [debug] [Thread-4 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:50:08.568375 [debug] [Thread-4 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m01:50:08.582706 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m01:50:08.603926 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:08.607584 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m01:50:08.610447 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:08.612155 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:50:08.616053 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: BEGIN
[0m01:50:08.625140 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:50:08.649967 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:08.653700 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:08.655896 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:08.659404 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:08.664131 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m01:50:08.669332 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

with current as (
  select *
  from "warehouse"."snapshots"."customers_snapshot"
  where dbt_valid_to is null
)
select
  customer_id,
  country,
  status,
  dbt_valid_from as valid_from
from current
  );
  
[0m01:50:08.828857 [debug] [Thread-3 (]: SQL status: SELECT 30000 in 0.0 seconds
[0m01:50:08.853035 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:08.857241 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
alter table "warehouse"."analytics_marts"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m01:50:08.863424 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:50:08.906939 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:08.912348 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  comment on table "warehouse"."analytics_marts"."dim_customer" is $dbt_comment_literal_block$Current SCD2 customer dimension from snapshots$dbt_comment_literal_block$;

  
[0m01:50:08.916527 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:08.938680 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:08.942846 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:50:08.963185 [debug] [Thread-4 (]: SQL status: SELECT 25746 in 0.0 seconds
[0m01:50:08.994747 [debug] [Thread-3 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:50:08.996618 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:09.007145 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:09.010849 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched" rename to "orders_enriched__dbt_backup"
[0m01:50:09.015560 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".customer_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".status is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".country is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".valid_from is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:50:09.020321 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:50:09.033764 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:09.052962 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:09.058913 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: COMMIT
[0m01:50:09.065440 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m01:50:09.069083 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:09.076103 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m01:50:09.078575 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: COMMIT
[0m01:50:09.097679 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:09.106699 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m01:50:09.119715 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:09.144383 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:09.146026 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m01:50:09.149386 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m01:50:09.168804 [debug] [Thread-3 (]: Applying DROP to: "warehouse"."analytics_marts"."dim_customer__dbt_backup"
[0m01:50:09.200708 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m01:50:09.205464 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
drop table if exists "warehouse"."analytics_marts"."dim_customer__dbt_backup" cascade
[0m01:50:09.210009 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m01:50:09.216722 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:50:08.368700 => 01:50:09.215901
[0m01:50:09.218143 [debug] [Thread-4 (]: SQL status: SELECT 12 in 0.0 seconds
[0m01:50:09.222804 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: Close
[0m01:50:09.241790 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:09.245913 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b31b1db10>]}
[0m01:50:09.249794 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:50:09.253819 [info ] [Thread-3 (]: 2 of 4 OK created sql table model analytics_marts.dim_customer ................. [[32mSELECT 30000[0m in 0.98s]
[0m01:50:09.262146 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:09.265726 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m01:50:09.274547 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:50:09.281369 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:09.285526 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m01:50:09.298338 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m01:50:09.314376 [debug] [Thread-4 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m01:50:09.322968 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m01:50:09.330008 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m01:50:09.343683 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m01:50:09.351681 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:50:08.442158 => 01:50:09.350836
[0m01:50:09.356241 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: Close
[0m01:50:09.364494 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b32368b50>]}
[0m01:50:09.368773 [info ] [Thread-4 (]: 3 of 4 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 25746[0m in 1.09s]
[0m01:50:09.381790 [debug] [Thread-4 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:50:09.387763 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:50:09.391345 [info ] [Thread-1 (]: 4 of 4 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m01:50:09.397359 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now model.sales_analytics.fct_daily_sales)
[0m01:50:09.405764 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:50:09.496691 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:50:09.549999 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:50:09.409099 => 01:50:09.548821
[0m01:50:09.560949 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:50:09.977179 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:09.986288 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
    

  create temporary table "fct_daily_sales__dbt_tmp015009937893"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
      and date_trunc('day', order_ts)::date >= (
        coalesce( (select max(sales_date) from "warehouse"."analytics_marts"."fct_daily_sales"), '1900-01-01'::date )
        - interval '2 day'
      )
    
    group by 1
)
select * from base
  );
  
  
[0m01:50:09.992274 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:50:10.122694 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.0 seconds
[0m01:50:10.144471 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.150992 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m01:50:10.155350 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:10.158976 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.163363 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp015009937893'
        
      order by ordinal_position

  
[0m01:50:10.195714 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:50:10.224752 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.228941 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:50:10.250290 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:50:10.343979 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.356493 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp015009937893'
        
      order by ordinal_position

  
[0m01:50:10.376860 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:50:10.402892 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.407206 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:50:10.424975 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:50:10.488239 [debug] [Thread-1 (]: 
    In "warehouse"."analytics_marts"."fct_daily_sales":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m01:50:10.575631 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m01:50:10.613118 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.615989 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
        
            delete from "warehouse"."analytics_marts"."fct_daily_sales"
            where (
                sales_date) in (
                select (sales_date)
                from "fct_daily_sales__dbt_tmp015009937893"
            );

        
    

    insert into "warehouse"."analytics_marts"."fct_daily_sales" ("sales_date", "orders", "units_sold", "gross_revenue")
    (
        select "sales_date", "orders", "units_sold", "gross_revenue"
        from "fct_daily_sales__dbt_tmp015009937893"
    )
  
[0m01:50:10.623383 [debug] [Thread-1 (]: SQL status: INSERT 0 3 in 0.0 seconds
[0m01:50:10.634295 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.637492 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m01:50:10.641096 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:10.654659 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.658618 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m01:50:10.672336 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m01:50:10.683996 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.691551 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m01:50:10.698327 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m01:50:10.720546 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.725340 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m01:50:10.730315 [debug] [Thread-1 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m01:50:10.737722 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:50:10.742329 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m01:50:10.745791 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m01:50:10.755395 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m01:50:10.763475 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:50:09.569490 => 01:50:10.762724
[0m01:50:10.766434 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: Close
[0m01:50:10.772790 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '301b3d07-0101-4e56-b492-9d7d0d36df8a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b32714910>]}
[0m01:50:10.776344 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mINSERT 0 3[0m in 1.38s]
[0m01:50:10.793990 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:50:10.832073 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:10.844834 [debug] [MainThread]: On master: BEGIN
[0m01:50:10.856257 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:50:10.907809 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:50:10.916852 [debug] [MainThread]: On master: COMMIT
[0m01:50:10.921645 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:10.926442 [debug] [MainThread]: On master: COMMIT
[0m01:50:10.936832 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:50:10.953087 [debug] [MainThread]: On master: Close
[0m01:50:10.968293 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:50:10.977422 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m01:50:10.997521 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m01:50:11.007235 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m01:50:11.012837 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m01:50:11.021285 [info ] [MainThread]: 
[0m01:50:11.036858 [info ] [MainThread]: Finished running 1 view model, 2 table models, 1 incremental model in 0 hours 0 minutes and 4.35 seconds (4.35s).
[0m01:50:11.051185 [debug] [MainThread]: Command end result
[0m01:50:11.217560 [info ] [MainThread]: 
[0m01:50:11.222371 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:50:11.227860 [info ] [MainThread]: 
[0m01:50:11.231907 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m01:50:11.248374 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.796595, "process_user_time": 16.71047, "process_kernel_time": 0.755901, "process_mem_max_rss": "122788", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:50:11.254415 [debug] [MainThread]: Command `dbt run` succeeded at 01:50:11.253687 after 7.80 seconds
[0m01:50:11.258745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b37c03890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b37c03790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b37c03e50>]}
[0m01:50:11.262807 [debug] [MainThread]: Flushing usage events
[0m01:50:19.430630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b5352210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b6686d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b5362850>]}


============================== 01:50:19.447126 | d2ef5af5-8426-4a22-a1bb-b1926602bdd7 ==============================
[0m01:50:19.447126 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:50:19.450456 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt test', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m01:50:20.230589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2ef5af5-8426-4a22-a1bb-b1926602bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b53e6b50>]}
[0m01:50:20.491416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd2ef5af5-8426-4a22-a1bb-b1926602bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b4b3c610>]}
[0m01:50:20.496273 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:50:20.536455 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:50:20.841364 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:20.843872 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:20.859778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2ef5af5-8426-4a22-a1bb-b1926602bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b4374c10>]}
[0m01:50:20.916034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2ef5af5-8426-4a22-a1bb-b1926602bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b4742950>]}
[0m01:50:20.918801 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:50:20.921354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2ef5af5-8426-4a22-a1bb-b1926602bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b4b65650>]}
[0m01:50:20.929392 [info ] [MainThread]: 
[0m01:50:20.933704 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:50:20.939750 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:50:20.941830 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:50:20.944079 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:50:20.946311 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:50:21.001637 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:50:21.006621 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:50:21.007986 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:50:21.014823 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:50:21.017401 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:50:21.019826 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:50:21.021936 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:50:21.023939 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:50:21.025894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:21.028041 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:21.030070 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:21.032027 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:21.048241 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.049366 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.050263 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.051717 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.052583 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:50:21.054772 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:50:21.056523 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:50:21.059901 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:50:21.062299 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:50:21.064725 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:50:21.066929 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:50:21.069090 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:50:21.077940 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.079226 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.080314 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m01:50:21.081622 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.084550 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:50:21.089314 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:50:21.093660 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:50:21.098146 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:50:21.101117 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:50:21.103119 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:50:21.104876 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:50:21.106803 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:50:21.128284 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:21.130373 [debug] [MainThread]: On master: BEGIN
[0m01:50:21.132406 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:50:21.145229 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.147290 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:21.149419 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:50:21.158366 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.162453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2ef5af5-8426-4a22-a1bb-b1926602bdd7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b47f1550>]}
[0m01:50:21.164419 [debug] [MainThread]: On master: ROLLBACK
[0m01:50:21.166354 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:21.168002 [debug] [MainThread]: On master: BEGIN
[0m01:50:21.170492 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.172202 [debug] [MainThread]: On master: COMMIT
[0m01:50:21.174059 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:21.175989 [debug] [MainThread]: On master: COMMIT
[0m01:50:21.178249 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:50:21.180235 [debug] [MainThread]: On master: Close
[0m01:50:21.182789 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:50:21.184604 [info ] [MainThread]: 
[0m01:50:21.206895 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:21.207964 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:21.209096 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:21.210615 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:21.212188 [info ] [Thread-1 (]: 1 of 11 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m01:50:21.214525 [info ] [Thread-2 (]: 2 of 11 START test not_null_fct_daily_sales_gross_revenue ...................... [RUN]
[0m01:50:21.218727 [info ] [Thread-3 (]: 3 of 11 START test not_null_fct_daily_sales_orders ............................. [RUN]
[0m01:50:21.221140 [info ] [Thread-4 (]: 4 of 11 START test not_null_fct_daily_sales_sales_date ......................... [RUN]
[0m01:50:21.225413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m01:50:21.229977 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m01:50:21.233649 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m01:50:21.236450 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m01:50:21.238666 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:21.240671 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:21.242649 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:21.245270 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:21.306685 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:50:21.315636 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:50:21.321289 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:50:21.333092 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:50:21.347833 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 01:50:21.270502 => 01:50:21.346927
[0m01:50:21.350818 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 01:50:21.247315 => 01:50:21.350057
[0m01:50:21.352307 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 01:50:21.323059 => 01:50:21.351722
[0m01:50:21.353416 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:21.355278 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 01:50:21.308012 => 01:50:21.354629
[0m01:50:21.357576 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:21.360316 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:21.385411 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:21.398687 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:50:21.405346 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:50:21.412119 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:50:21.419867 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:50:21.455934 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:50:21.460828 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: BEGIN
[0m01:50:21.462137 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:50:21.466104 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:50:21.467244 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:50:21.471337 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m01:50:21.473878 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: BEGIN
[0m01:50:21.477008 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:50:21.482089 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:50:21.484898 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:50:21.487376 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: BEGIN
[0m01:50:21.495310 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.502685 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:50:21.505678 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.507084 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:50:21.512937 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.514229 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:50:21.516873 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orders
from "warehouse"."analytics_marts"."fct_daily_sales"
where orders is null



      
    ) dbt_internal_test
[0m01:50:21.519146 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:50:21.521491 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "warehouse"."analytics_marts"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m01:50:21.524626 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.526395 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sales_date
from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is null



      
    ) dbt_internal_test
[0m01:50:21.527641 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.531346 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:50:21.541673 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 01:50:21.414314 => 01:50:21.540091
[0m01:50:21.543565 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.544787 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.546659 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select gross_revenue
from "warehouse"."analytics_marts"."fct_daily_sales"
where gross_revenue is null



      
    ) dbt_internal_test
[0m01:50:21.549188 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: ROLLBACK
[0m01:50:21.555330 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 01:50:21.400420 => 01:50:21.554453
[0m01:50:21.561246 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 01:50:21.407269 => 01:50:21.560649
[0m01:50:21.565568 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.566622 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: Close
[0m01:50:21.568087 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m01:50:21.570410 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: ROLLBACK
[0m01:50:21.575865 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 01:50:21.362473 => 01:50:21.574995
[0m01:50:21.580073 [info ] [Thread-3 (]: 3 of 11 PASS not_null_fct_daily_sales_orders ................................... [[32mPASS[0m in 0.35s]
[0m01:50:21.583071 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: Close
[0m01:50:21.585646 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: Close
[0m01:50:21.587652 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: ROLLBACK
[0m01:50:21.590518 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:21.594303 [info ] [Thread-1 (]: 1 of 11 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.37s]
[0m01:50:21.597926 [info ] [Thread-4 (]: 4 of 11 PASS not_null_fct_daily_sales_sales_date ............................... [[32mPASS[0m in 0.36s]
[0m01:50:21.601310 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: Close
[0m01:50:21.603652 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:21.606646 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:21.609796 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:21.614282 [info ] [Thread-2 (]: 2 of 11 PASS not_null_fct_daily_sales_gross_revenue ............................ [[32mPASS[0m in 0.39s]
[0m01:50:21.616618 [info ] [Thread-3 (]: 5 of 11 START test not_null_orders_enriched_line_amount ........................ [RUN]
[0m01:50:21.622571 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:21.625331 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:21.629658 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:21.633487 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m01:50:21.636037 [info ] [Thread-1 (]: 6 of 11 START test not_null_src_orders_order_id ................................ [RUN]
[0m01:50:21.638342 [info ] [Thread-4 (]: 7 of 11 START test not_null_src_orders_order_line_id ........................... [RUN]
[0m01:50:21.646474 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:21.654546 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:21.657760 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m01:50:21.662046 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m01:50:21.664985 [info ] [Thread-2 (]: 8 of 11 START test not_null_src_orders_order_ts ................................ [RUN]
[0m01:50:21.685004 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:50:21.686075 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:21.688384 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:21.691955 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m01:50:21.710760 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:50:21.723950 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:50:21.727550 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:21.732326 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 01:50:21.667935 => 01:50:21.731348
[0m01:50:21.751891 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:50:21.753743 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:21.756979 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 01:50:21.712856 => 01:50:21.756235
[0m01:50:21.758942 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 01:50:21.695138 => 01:50:21.757743
[0m01:50:21.768958 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:50:21.771331 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:21.773095 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 01:50:21.736377 => 01:50:21.772471
[0m01:50:21.774850 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:21.789138 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:50:21.791516 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:21.799117 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:50:21.808598 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:50:21.812221 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:50:21.814756 [debug] [Thread-3 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: BEGIN
[0m01:50:21.816796 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:50:21.818891 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:50:21.824124 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:50:21.825387 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: BEGIN
[0m01:50:21.828213 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: BEGIN
[0m01:50:21.831190 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:50:21.832516 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:50:21.834394 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:50:21.837424 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.839751 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: BEGIN
[0m01:50:21.847079 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:50:21.849899 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m01:50:21.852476 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.854106 [debug] [Thread-3 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select line_amount
from "warehouse"."analytics_intermediate"."orders_enriched"
where line_amount is null



      
    ) dbt_internal_test
[0m01:50:21.858155 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:50:21.862194 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.863467 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_line_id
from "warehouse"."analytics_staging"."src_orders"
where order_line_id is null



      
    ) dbt_internal_test
[0m01:50:21.865838 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:50:21.870417 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "warehouse"."analytics_staging"."src_orders"
where order_id is null



      
    ) dbt_internal_test
[0m01:50:21.871849 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.872994 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:21.880839 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 01:50:21.761947 => 01:50:21.879975
[0m01:50:21.883555 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.884841 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.886398 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:50:21.888646 [debug] [Thread-3 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: ROLLBACK
[0m01:50:21.893831 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 01:50:21.778906 => 01:50:21.893246
[0m01:50:21.898823 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 01:50:21.793322 => 01:50:21.898125
[0m01:50:21.901631 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_ts
from "warehouse"."analytics_staging"."src_orders"
where order_ts is null



      
    ) dbt_internal_test
[0m01:50:21.904268 [debug] [Thread-3 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: Close
[0m01:50:21.905944 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: ROLLBACK
[0m01:50:21.908445 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: ROLLBACK
[0m01:50:21.913792 [info ] [Thread-3 (]: 5 of 11 PASS not_null_orders_enriched_line_amount .............................. [[32mPASS[0m in 0.28s]
[0m01:50:21.916291 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: Close
[0m01:50:21.919510 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: Close
[0m01:50:21.920657 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:21.922492 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:21.925983 [info ] [Thread-4 (]: 7 of 11 PASS not_null_src_orders_order_line_id ................................. [[32mPASS[0m in 0.26s]
[0m01:50:21.931228 [info ] [Thread-1 (]: 6 of 11 PASS not_null_src_orders_order_id ...................................... [[32mPASS[0m in 0.27s]
[0m01:50:21.936503 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 01:50:21.801659 => 01:50:21.935825
[0m01:50:21.939214 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:21.941952 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:21.944725 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:21.946844 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: ROLLBACK
[0m01:50:21.949873 [info ] [Thread-3 (]: 9 of 11 START test not_null_src_orders_quantity ................................ [RUN]
[0m01:50:21.953915 [debug] [Thread-4 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:21.956704 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:21.960330 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: Close
[0m01:50:21.963347 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m01:50:21.967093 [info ] [Thread-4 (]: 10 of 11 START test unique_dim_customer_customer_id ............................ [RUN]
[0m01:50:21.970043 [info ] [Thread-1 (]: 11 of 11 START test unique_fct_daily_sales_sales_date .......................... [RUN]
[0m01:50:21.975297 [info ] [Thread-2 (]: 8 of 11 PASS not_null_src_orders_order_ts ...................................... [[32mPASS[0m in 0.28s]
[0m01:50:21.979105 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:21.984705 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m01:50:21.989318 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m01:50:21.993015 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:22.014419 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:50:22.017042 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:22.019465 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:22.045534 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:50:22.058762 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 01:50:21.996562 => 01:50:22.057741
[0m01:50:22.060183 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:50:22.062994 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:22.072441 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:50:22.076111 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 01:50:22.023927 => 01:50:22.075356
[0m01:50:22.077733 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 01:50:22.046524 => 01:50:22.076969
[0m01:50:22.079807 [debug] [Thread-4 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:22.082036 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:22.089077 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:50:22.096766 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:50:22.099454 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:50:22.102411 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: BEGIN
[0m01:50:22.105569 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m01:50:22.110479 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:50:22.113538 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: BEGIN
[0m01:50:22.116515 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:50:22.117682 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m01:50:22.120116 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: BEGIN
[0m01:50:22.123173 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:22.125487 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m01:50:22.128148 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:50:22.133723 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "warehouse"."analytics_staging"."src_orders"
where quantity is null



      
    ) dbt_internal_test
[0m01:50:22.137541 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:22.140129 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:50:22.144614 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "warehouse"."analytics_marts"."dim_customer"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m01:50:22.146323 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:22.148355 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m01:50:22.153715 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 01:50:22.065687 => 01:50:22.153148
[0m01:50:22.155953 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:50:22.158447 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: ROLLBACK
[0m01:50:22.160997 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    sales_date as unique_field,
    count(*) as n_records

from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is not null
group by sales_date
having count(*) > 1



      
    ) dbt_internal_test
[0m01:50:22.163814 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: Close
[0m01:50:22.169567 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:22.168403 [info ] [Thread-3 (]: 9 of 11 PASS not_null_src_orders_quantity ...................................... [[32mPASS[0m in 0.21s]
[0m01:50:22.175579 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 01:50:22.090835 => 01:50:22.174876
[0m01:50:22.176901 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:22.179395 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:22.181580 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: ROLLBACK
[0m01:50:22.186709 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 01:50:22.083610 => 01:50:22.186088
[0m01:50:22.191355 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: Close
[0m01:50:22.193479 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: ROLLBACK
[0m01:50:22.197454 [info ] [Thread-1 (]: 11 of 11 PASS unique_fct_daily_sales_sales_date ................................ [[32mPASS[0m in 0.21s]
[0m01:50:22.200140 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: Close
[0m01:50:22.202719 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:22.206453 [error] [Thread-4 (]: 10 of 11 FAIL 3789 unique_dim_customer_customer_id ............................. [[31mFAIL 3789[0m in 0.22s]
[0m01:50:22.212476 [debug] [Thread-4 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:22.220970 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:22.223587 [debug] [MainThread]: On master: BEGIN
[0m01:50:22.226845 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m01:50:22.251464 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:50:22.254346 [debug] [MainThread]: On master: COMMIT
[0m01:50:22.257080 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:22.260621 [debug] [MainThread]: On master: COMMIT
[0m01:50:22.263283 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m01:50:22.266083 [debug] [MainThread]: On master: Close
[0m01:50:22.270382 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:50:22.272073 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992' was properly closed.
[0m01:50:22.273910 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_quantity.741e0fed47' was properly closed.
[0m01:50:22.276199 [debug] [MainThread]: Connection 'test.sales_analytics.unique_dim_customer_customer_id.b42affccd1' was properly closed.
[0m01:50:22.277979 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m01:50:22.279782 [info ] [MainThread]: 
[0m01:50:22.282598 [info ] [MainThread]: Finished running 11 tests in 0 hours 0 minutes and 1.35 seconds (1.35s).
[0m01:50:22.288927 [debug] [MainThread]: Command end result
[0m01:50:22.336287 [info ] [MainThread]: 
[0m01:50:22.338922 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m01:50:22.343106 [info ] [MainThread]: 
[0m01:50:22.346119 [error] [MainThread]: [31mFailure in test unique_dim_customer_customer_id (models/marts/schema.yml)[0m
[0m01:50:22.350613 [error] [MainThread]:   Got 3789 results, configured to fail if != 0
[0m01:50:22.353387 [info ] [MainThread]: 
[0m01:50:22.356066 [info ] [MainThread]:   compiled Code at target/compiled/sales_analytics/models/marts/schema.yml/unique_dim_customer_customer_id.sql
[0m01:50:22.360899 [info ] [MainThread]: 
[0m01:50:22.364190 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=1 SKIP=0 TOTAL=11
[0m01:50:22.368214 [debug] [MainThread]: Resource report: {"command_name": "test", "command_wall_clock_time": 3.0955703, "process_user_time": 8.606376, "process_kernel_time": 0.372004, "process_mem_max_rss": "122268", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:50:22.370709 [debug] [MainThread]: Command `dbt test` failed at 01:50:22.370360 after 3.10 seconds
[0m01:50:22.372586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b53b75d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b53b72d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b53b6e50>]}
[0m01:50:22.376512 [debug] [MainThread]: Flushing usage events
[0m01:50:31.882052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9e3b610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9e3a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9e38450>]}


============================== 01:50:31.897604 | 9e55ab41-5499-42f9-9c59-5f4ac2dbb5e8 ==============================
[0m01:50:31.897604 [info ] [MainThread]: Running with dbt=1.7.11
[0m01:50:31.901268 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m01:50:32.353913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9e55ab41-5499-42f9-9c59-5f4ac2dbb5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9694050>]}
[0m01:50:32.558703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9e55ab41-5499-42f9-9c59-5f4ac2dbb5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ab46d150>]}
[0m01:50:32.561963 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m01:50:32.595362 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m01:50:33.009481 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:33.011725 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:33.028305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9e55ab41-5499-42f9-9c59-5f4ac2dbb5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a8f2d0d0>]}
[0m01:50:33.055478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9e55ab41-5499-42f9-9c59-5f4ac2dbb5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a8f7fb10>]}
[0m01:50:33.058345 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m01:50:33.061598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e55ab41-5499-42f9-9c59-5f4ac2dbb5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aa163790>]}
[0m01:50:33.071823 [info ] [MainThread]: 
[0m01:50:33.076769 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m01:50:33.084490 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m01:50:33.088375 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m01:50:33.091974 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m01:50:33.100140 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m01:50:33.167790 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:50:33.180687 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:50:33.186978 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:50:33.193860 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:50:33.195884 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m01:50:33.198033 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m01:50:33.200090 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m01:50:33.202032 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m01:50:33.203970 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:33.205682 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:33.207508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:33.209296 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:33.225517 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:33.227610 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m01:50:33.228769 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:33.229747 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:33.230698 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:33.232451 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m01:50:33.234553 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m01:50:33.236607 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m01:50:33.238452 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m01:50:33.241355 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m01:50:33.243442 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m01:50:33.245576 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m01:50:33.246557 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:33.255471 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m01:50:33.256448 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m01:50:33.257357 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:33.258352 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:33.260077 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m01:50:33.263886 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m01:50:33.267414 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m01:50:33.270918 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m01:50:33.275392 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m01:50:33.277177 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m01:50:33.278857 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m01:50:33.296177 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:33.298102 [debug] [MainThread]: On master: BEGIN
[0m01:50:33.299652 [debug] [MainThread]: Opening a new connection, currently in state init
[0m01:50:33.310766 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m01:50:33.312650 [debug] [MainThread]: Using postgres connection "master"
[0m01:50:33.314755 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m01:50:33.323776 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m01:50:33.328509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9e55ab41-5499-42f9-9c59-5f4ac2dbb5e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a97569d0>]}
[0m01:50:33.330281 [debug] [MainThread]: On master: ROLLBACK
[0m01:50:33.332685 [debug] [MainThread]: On master: Close
[0m01:50:33.335345 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m01:50:33.337178 [info ] [MainThread]: 
[0m01:50:33.357674 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m01:50:33.360134 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m01:50:33.362046 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m01:50:33.378649 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m01:50:33.401508 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 01:50:33.364026 => 01:50:33.400079
[0m01:50:33.405107 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m01:50:33.407573 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 01:50:33.406906 => 01:50:33.406946
[0m01:50:33.411529 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m01:50:33.415631 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m01:50:33.416840 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m01:50:33.418991 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:33.421771 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:33.424512 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.orders_enriched)
[0m01:50:33.429147 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now snapshot.sales_analytics.customers_snapshot)
[0m01:50:33.433308 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m01:50:33.437363 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m01:50:33.440081 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m01:50:33.442643 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m01:50:33.445349 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:33.448796 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:33.459853 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m01:50:33.472818 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 01:50:33.462002 => 01:50:33.472017
[0m01:50:33.550099 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m01:50:33.553100 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m01:50:33.557121 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m01:50:33.564900 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 01:50:33.562954 => 01:50:33.563146
[0m01:50:33.571774 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m01:50:33.575311 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 01:50:33.451311 => 01:50:33.574478
[0m01:50:33.577196 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:33.579483 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 01:50:33.501855 => 01:50:33.578679
[0m01:50:33.581195 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 01:50:33.477054 => 01:50:33.580648
[0m01:50:33.583445 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m01:50:33.586418 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m01:50:33.589217 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:33.591821 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:33.594506 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 01:50:33.593922 => 01:50:33.593956
[0m01:50:33.596463 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:33.598874 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 01:50:33.598287 => 01:50:33.598312
[0m01:50:33.601055 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 01:50:33.600456 => 01:50:33.600480
[0m01:50:33.604509 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m01:50:33.621111 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m01:50:33.623937 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m01:50:33.627067 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m01:50:33.629225 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:33.632698 [debug] [Thread-1 (]: Began running node model.sales_analytics.dim_customer
[0m01:50:33.635819 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m01:50:33.639312 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m01:50:33.642236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.dim_customer)
[0m01:50:33.645356 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.fct_daily_sales)
[0m01:50:33.647929 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:33.649072 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 01:50:33.606269 => 01:50:33.648544
[0m01:50:33.650801 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.dim_customer
[0m01:50:33.652486 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m01:50:33.663589 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m01:50:33.665482 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:33.674417 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m01:50:33.704302 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m01:50:33.707718 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 01:50:33.706682 => 01:50:33.706718
[0m01:50:33.715819 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m01:50:33.721555 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:33.724250 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 01:50:33.675926 => 01:50:33.723388
[0m01:50:33.726089 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (compile): 01:50:33.667412 => 01:50:33.725209
[0m01:50:33.727950 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 01:50:33.653967 => 01:50:33.727209
[0m01:50:33.730569 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m01:50:33.732574 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m01:50:33.734492 [debug] [Thread-1 (]: Began executing node model.sales_analytics.dim_customer
[0m01:50:33.736668 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:33.739141 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:33.741697 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 01:50:33.741029 => 01:50:33.741059
[0m01:50:33.744047 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (execute): 01:50:33.743482 => 01:50:33.743510
[0m01:50:33.746560 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 01:50:33.745824 => 01:50:33.745844
[0m01:50:33.758774 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m01:50:33.761896 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m01:50:33.765204 [debug] [Thread-1 (]: Finished running node model.sales_analytics.dim_customer
[0m01:50:33.768647 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m01:50:33.772906 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:33.774685 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:33.777518 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:33.780438 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m01:50:33.783078 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m01:50:33.785899 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m01:50:33.787711 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 01:50:33.748381 => 01:50:33.786994
[0m01:50:33.789461 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:33.791383 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:33.793187 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:33.794905 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:33.806566 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m01:50:33.817201 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m01:50:33.828496 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m01:50:33.830654 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 01:50:33.830036 => 01:50:33.830063
[0m01:50:33.838431 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m01:50:33.840417 [debug] [Thread-4 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:33.842933 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m01:50:33.845126 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:33.846446 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 01:50:33.796329 => 01:50:33.845837
[0m01:50:33.854227 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 01:50:33.808397 => 01:50:33.853662
[0m01:50:33.855133 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 01:50:33.819221 => 01:50:33.854682
[0m01:50:33.864108 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m01:50:33.866254 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:33.868236 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:33.870172 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:33.874271 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 01:50:33.873725 => 01:50:33.873771
[0m01:50:33.876156 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 01:50:33.875704 => 01:50:33.875722
[0m01:50:33.878496 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 01:50:33.878015 => 01:50:33.878031
[0m01:50:33.881737 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m01:50:33.884772 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m01:50:33.887783 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m01:50:33.890256 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:33.892168 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 01:50:33.848180 => 01:50:33.891716
[0m01:50:33.893051 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:33.897759 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m01:50:33.900129 [debug] [Thread-4 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:33.903059 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m01:50:33.905612 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:33.908175 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 01:50:33.907735 => 01:50:33.907754
[0m01:50:33.910258 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:33.921882 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m01:50:33.925066 [debug] [Thread-4 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m01:50:33.935976 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m01:50:33.949371 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 01:50:33.927359 => 01:50:33.948686
[0m01:50:33.951352 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 01:50:33.912458 => 01:50:33.950841
[0m01:50:33.952192 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:33.954465 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:33.956686 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 01:50:33.956290 => 01:50:33.956306
[0m01:50:33.958723 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 01:50:33.958340 => 01:50:33.958357
[0m01:50:33.961498 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m01:50:33.964683 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m01:50:33.970473 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:50:33.972046 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m01:50:33.973374 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m01:50:33.974528 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m01:50:33.975746 [debug] [MainThread]: Connection 'test.sales_analytics.unique_dim_customer_customer_id.b42affccd1' was properly closed.
[0m01:50:33.981596 [debug] [MainThread]: Command end result
[0m01:50:34.071373 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m01:50:34.073826 [info ] [MainThread]: Building catalog
[0m01:50:34.081359 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m01:50:34.105334 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:50:34.108128 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m01:50:34.110493 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:34.124447 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m01:50:34.126755 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m01:50:34.128751 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m01:50:34.139883 [debug] [ThreadPool]: SQL status: SELECT 39 in 0.0 seconds
[0m01:50:34.154315 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m01:50:34.156784 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m01:50:34.211283 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m01:50:34.218274 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.4670908, "process_user_time": 7.255617, "process_kernel_time": 0.408626, "process_mem_max_rss": "120712", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m01:50:34.222229 [debug] [MainThread]: Command `dbt docs generate` succeeded at 01:50:34.221666 after 2.47 seconds
[0m01:50:34.224603 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m01:50:34.226674 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m01:50:34.232204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aae83a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9363710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9363650>]}
[0m01:50:34.236388 [debug] [MainThread]: Flushing usage events
[0m02:02:34.121438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdca8ef2810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdca8ee7110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdca8ee50d0>]}


============================== 02:02:34.140196 | b8df217f-a780-4d62-9145-e6be531c9214 ==============================
[0m02:02:34.140196 [info ] [MainThread]: Running with dbt=1.7.11
[0m02:02:34.143382 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:02:34.389071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b8df217f-a780-4d62-9145-e6be531c9214', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdca8f98fd0>]}
[0m02:02:34.394197 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:02:34.412899 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m02:02:34.416943 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.40841997, "process_user_time": 11.286063, "process_kernel_time": 0.519358, "process_mem_max_rss": "105004", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m02:02:34.420743 [debug] [MainThread]: Command `dbt deps` succeeded at 02:02:34.419958 after 0.41 seconds
[0m02:02:34.424254 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdca8f33010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdca8f32dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcada8ba50>]}
[0m02:02:34.428135 [debug] [MainThread]: Flushing usage events
[0m02:02:41.357454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37dbeb050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37e7df290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37dbe2650>]}


============================== 02:02:41.371249 | 17c1aca4-8935-4a27-a515-0261ae8a3ed5 ==============================
[0m02:02:41.371249 [info ] [MainThread]: Running with dbt=1.7.11
[0m02:02:41.373291 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m02:02:41.786514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17c1aca4-8935-4a27-a515-0261ae8a3ed5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37dbe2850>]}
[0m02:02:41.986612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17c1aca4-8935-4a27-a515-0261ae8a3ed5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37dbe2850>]}
[0m02:02:41.989326 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m02:02:42.019316 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m02:02:42.249985 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m02:02:42.252471 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/dim_customer.sql
[0m02:02:42.952320 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '17c1aca4-8935-4a27-a515-0261ae8a3ed5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37c37ea90>]}
[0m02:02:43.006262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '17c1aca4-8935-4a27-a515-0261ae8a3ed5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37cbe3f50>]}
[0m02:02:43.008621 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m02:02:43.010996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17c1aca4-8935-4a27-a515-0261ae8a3ed5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37cfd7dd0>]}
[0m02:02:43.018851 [info ] [MainThread]: 
[0m02:02:43.023616 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m02:02:43.028337 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m02:02:43.059496 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m02:02:43.061969 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m02:02:43.064228 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:02:43.084296 [debug] [ThreadPool]: SQL status: SELECT 16 in 0.0 seconds
[0m02:02:43.088076 [debug] [ThreadPool]: On list_warehouse: Close
[0m02:02:43.093268 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_staging)
[0m02:02:43.096706 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m02:02:43.099485 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m02:02:43.102359 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m02:02:43.117482 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:02:43.122687 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:02:43.216656 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:02:43.223843 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:02:43.225671 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m02:02:43.227616 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m02:02:43.229586 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m02:02:43.231193 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m02:02:43.232859 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:02:43.235501 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:02:43.237016 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:02:43.238508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:02:43.254351 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:02:43.256493 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:02:43.257497 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:02:43.260932 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:02:43.262579 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:02:43.263528 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:02:43.265389 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m02:02:43.267781 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:02:43.270292 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m02:02:43.272267 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:02:43.275432 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m02:02:43.278748 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m02:02:43.281344 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:02:43.287115 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m02:02:43.288073 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m02:02:43.289073 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m02:02:43.291225 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:02:43.292219 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m02:02:43.296046 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m02:02:43.301336 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m02:02:43.306276 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m02:02:43.312415 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m02:02:43.314658 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m02:02:43.316501 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m02:02:43.347274 [debug] [MainThread]: Using postgres connection "master"
[0m02:02:43.349473 [debug] [MainThread]: On master: BEGIN
[0m02:02:43.351241 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:02:43.367060 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:02:43.369433 [debug] [MainThread]: Using postgres connection "master"
[0m02:02:43.371639 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m02:02:43.383203 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m02:02:43.388703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '17c1aca4-8935-4a27-a515-0261ae8a3ed5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37c3ccc50>]}
[0m02:02:43.390902 [debug] [MainThread]: On master: ROLLBACK
[0m02:02:43.393257 [debug] [MainThread]: Using postgres connection "master"
[0m02:02:43.394960 [debug] [MainThread]: On master: BEGIN
[0m02:02:43.397532 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:02:43.399706 [debug] [MainThread]: On master: COMMIT
[0m02:02:43.406008 [debug] [MainThread]: Using postgres connection "master"
[0m02:02:43.408270 [debug] [MainThread]: On master: COMMIT
[0m02:02:43.410628 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m02:02:43.412771 [debug] [MainThread]: On master: Close
[0m02:02:43.416081 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:02:43.418576 [info ] [MainThread]: 
[0m02:02:43.457655 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m02:02:43.460659 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m02:02:43.466876 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now snapshot.sales_analytics.customers_snapshot)
[0m02:02:43.471509 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m02:02:43.508745 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 02:02:43.473771 => 02:02:43.507749
[0m02:02:43.523433 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m02:02:43.678215 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m02:02:43.696468 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m02:02:43.698866 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m02:02:43.701009 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:02:43.714716 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m02:02:43.716820 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m02:02:43.718843 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m02:02:43.912297 [debug] [Thread-1 (]: SQL status: SELECT 35000 in 0.0 seconds
[0m02:02:43.956778 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m02:02:43.959920 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m02:02:43.962026 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m02:02:43.994994 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m02:02:43.998759 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 02:02:43.527802 => 02:02:43.998028
[0m02:02:44.000530 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m02:02:44.003074 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '17c1aca4-8935-4a27-a515-0261ae8a3ed5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37bf7f410>]}
[0m02:02:44.005207 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSELECT 35000[0m in 0.54s]
[0m02:02:44.008034 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m02:02:44.013891 [debug] [MainThread]: Using postgres connection "master"
[0m02:02:44.015731 [debug] [MainThread]: On master: BEGIN
[0m02:02:44.017530 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:02:44.032822 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:02:44.034762 [debug] [MainThread]: On master: COMMIT
[0m02:02:44.036390 [debug] [MainThread]: Using postgres connection "master"
[0m02:02:44.037845 [debug] [MainThread]: On master: COMMIT
[0m02:02:44.039652 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m02:02:44.041146 [debug] [MainThread]: On master: Close
[0m02:02:44.043375 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:02:44.044834 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m02:02:44.046681 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m02:02:44.048491 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m02:02:44.050889 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m02:02:44.053709 [info ] [MainThread]: 
[0m02:02:44.056222 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m02:02:44.059665 [debug] [MainThread]: Command end result
[0m02:02:44.111452 [info ] [MainThread]: 
[0m02:02:44.114731 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:02:44.117814 [info ] [MainThread]: 
[0m02:02:44.120586 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:02:44.124495 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 2.8729687, "process_user_time": 7.726959, "process_kernel_time": 0.27236, "process_mem_max_rss": "128712", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m02:02:44.127253 [debug] [MainThread]: Command `dbt snapshot` succeeded at 02:02:44.126868 after 2.88 seconds
[0m02:02:44.130840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37defdb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37c7de950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb37e0450d0>]}
[0m02:02:44.133775 [debug] [MainThread]: Flushing usage events
[0m02:02:58.466930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505daf1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505da6c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505daf7d0>]}


============================== 02:02:58.504322 | 2c73f9f8-661b-4889-9eb5-b3c1ab7cd305 ==============================
[0m02:02:58.504322 [info ] [MainThread]: Running with dbt=1.7.11
[0m02:02:58.512348 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m02:02:59.601049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505e3d1d0>]}
[0m02:03:00.065788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505da6c50>]}
[0m02:03:00.075090 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m02:03:00.172011 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m02:03:01.116984 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:03:01.124914 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:03:01.171731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa504da5090>]}
[0m02:03:01.320234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505161410>]}
[0m02:03:01.326678 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m02:03:01.335955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5051da890>]}
[0m02:03:01.354345 [info ] [MainThread]: 
[0m02:03:01.360389 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m02:03:01.375760 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m02:03:01.385529 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m02:03:01.389294 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m02:03:01.494274 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m02:03:01.496974 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m02:03:01.505895 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m02:03:01.520796 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m02:03:01.511401 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m02:03:01.508329 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m02:03:01.526666 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:01.538678 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:01.546900 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:01.587326 [debug] [ThreadPool]: SQL status: SELECT 16 in 0.0 seconds
[0m02:03:01.588968 [debug] [ThreadPool]: SQL status: SELECT 16 in 0.0 seconds
[0m02:03:01.590282 [debug] [ThreadPool]: SQL status: SELECT 16 in 0.0 seconds
[0m02:03:01.604880 [debug] [ThreadPool]: On list_warehouse: Close
[0m02:03:01.614254 [debug] [ThreadPool]: On list_warehouse: Close
[0m02:03:01.622853 [debug] [ThreadPool]: On list_warehouse: Close
[0m02:03:01.651127 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_snapshots)
[0m02:03:01.655491 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_staging)
[0m02:03:01.659043 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_intermediate)
[0m02:03:01.662637 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m02:03:01.725840 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:03:01.740815 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:03:01.743201 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:03:01.759206 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:03:01.762343 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m02:03:01.765464 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m02:03:01.769032 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m02:03:01.771900 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m02:03:01.774819 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:03:01.778007 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:03:01.780803 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:03:01.783601 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:01.809550 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:01.812812 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:01.814581 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:03:01.819336 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:01.820941 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:03:01.825850 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m02:03:01.827730 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:01.830273 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:03:01.833011 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m02:03:01.838251 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:03:01.842655 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m02:03:01.844380 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:01.851764 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m02:03:01.863666 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m02:03:01.868056 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:01.870957 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:01.877065 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m02:03:01.886776 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m02:03:01.895897 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m02:03:01.897427 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m02:03:01.910404 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m02:03:01.914125 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m02:03:01.922975 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m02:03:01.933954 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m02:03:01.967737 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:01.972473 [debug] [MainThread]: On master: BEGIN
[0m02:03:01.981600 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:02.000918 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:03:02.003651 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:02.006263 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m02:03:02.017415 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:02.025507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa504d8f0d0>]}
[0m02:03:02.027965 [debug] [MainThread]: On master: ROLLBACK
[0m02:03:02.031279 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:02.033025 [debug] [MainThread]: On master: BEGIN
[0m02:03:02.035287 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:03:02.036772 [debug] [MainThread]: On master: COMMIT
[0m02:03:02.038344 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:02.040104 [debug] [MainThread]: On master: COMMIT
[0m02:03:02.042227 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m02:03:02.043977 [debug] [MainThread]: On master: Close
[0m02:03:02.046738 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:03:02.048952 [info ] [MainThread]: 
[0m02:03:02.068713 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m02:03:02.072116 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m02:03:02.076310 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.src_orders)
[0m02:03:02.078747 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m02:03:02.102103 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m02:03:02.121894 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 02:03:02.080518 => 02:03:02.121213
[0m02:03:02.124196 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m02:03:02.206178 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m02:03:02.224548 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.227200 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m02:03:02.229477 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:02.241013 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:02.243585 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.245753 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m02:03:02.251224 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m02:03:02.265236 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.267774 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders" rename to "src_orders__dbt_backup"
[0m02:03:02.271242 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m02:03:02.278430 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.280669 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m02:03:02.283357 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m02:03:02.334620 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.337505 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m02:03:02.340631 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:02.367013 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.369376 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m02:03:02.382078 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m02:03:02.392815 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.395427 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m02:03:02.398650 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:02.402920 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m02:03:02.405285 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.407801 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m02:03:02.414690 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m02:03:02.432487 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m02:03:02.447492 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m02:03:02.450338 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m02:03:02.458214 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m02:03:02.463807 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 02:03:02.125952 => 02:03:02.463173
[0m02:03:02.466502 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m02:03:02.469854 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa50511bc10>]}
[0m02:03:02.472564 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 0.39s]
[0m02:03:02.475378 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m02:03:02.479093 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m02:03:02.480168 [debug] [Thread-4 (]: Began running node model.sales_analytics.orders_enriched
[0m02:03:02.482262 [info ] [Thread-3 (]: 2 of 4 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m02:03:02.485147 [info ] [Thread-4 (]: 3 of 4 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m02:03:02.489198 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.dim_customer)
[0m02:03:02.492610 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.orders_enriched)
[0m02:03:02.495193 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m02:03:02.497342 [debug] [Thread-4 (]: Began compiling node model.sales_analytics.orders_enriched
[0m02:03:02.508206 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m02:03:02.519329 [debug] [Thread-4 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m02:03:02.534424 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (compile): 02:03:02.510009 => 02:03:02.533544
[0m02:03:02.537548 [debug] [Thread-4 (]: Began executing node model.sales_analytics.orders_enriched
[0m02:03:02.539059 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 02:03:02.499259 => 02:03:02.538349
[0m02:03:02.564475 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m02:03:02.638918 [debug] [Thread-4 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m02:03:02.645500 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m02:03:02.658379 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.659705 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.661392 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m02:03:02.664187 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: BEGIN
[0m02:03:02.666353 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:03:02.668602 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m02:03:02.684177 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:02.686173 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:02.687059 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.689353 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.690865 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m02:03:02.692931 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    

with current as (
    select *
    from "warehouse"."snapshots"."customers_snapshot"
    where dbt_valid_to is null
),

deduped as (
    select
        customer_id,
        country,
        status,
        dbt_valid_from,
        row_number() over (
            partition by customer_id
            order by dbt_valid_from desc
        ) as rn
    from current
)

select
    customer_id,
    country,
    status,
    dbt_valid_from as valid_from
from deduped
where rn = 1
  );
  
[0m02:03:02.780046 [debug] [Thread-3 (]: SQL status: SELECT 3789 in 0.0 seconds
[0m02:03:02.791776 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.794896 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
alter table "warehouse"."analytics_marts"."dim_customer" rename to "dim_customer__dbt_backup"
[0m02:03:02.798889 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m02:03:02.810774 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.813558 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
alter table "warehouse"."analytics_marts"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m02:03:02.815370 [debug] [Thread-4 (]: SQL status: SELECT 30037 in 0.0 seconds
[0m02:03:02.818408 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m02:03:02.827231 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.848262 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.849306 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched" rename to "orders_enriched__dbt_backup"
[0m02:03:02.851783 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  comment on table "warehouse"."analytics_marts"."dim_customer" is $dbt_comment_literal_block$Current SCD2 customer dimension from snapshots$dbt_comment_literal_block$;

  
[0m02:03:02.854630 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m02:03:02.856367 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:02.866753 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.876733 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.879248 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m02:03:02.881456 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m02:03:02.884734 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m02:03:02.892927 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.895112 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m02:03:02.898084 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:02.899070 [debug] [Thread-3 (]: SQL status: SELECT 4 in 0.0 seconds
[0m02:03:02.909193 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.915778 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.917978 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m02:03:02.920141 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".customer_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".status is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".country is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".valid_from is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m02:03:02.924417 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:02.930026 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: COMMIT
[0m02:03:02.933272 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.935346 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: COMMIT
[0m02:03:02.938784 [debug] [Thread-4 (]: SQL status: SELECT 12 in 0.0 seconds
[0m02:03:02.944659 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.946680 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m02:03:02.949038 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:02.953345 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m02:03:02.955380 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:02.957281 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m02:03:02.964300 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m02:03:02.971075 [debug] [Thread-3 (]: Applying DROP to: "warehouse"."analytics_marts"."dim_customer__dbt_backup"
[0m02:03:02.972346 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m02:03:02.981644 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m02:03:02.992044 [debug] [Thread-4 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m02:03:02.993965 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
drop table if exists "warehouse"."analytics_marts"."dim_customer__dbt_backup" cascade
[0m02:03:02.997695 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m02:03:03.001136 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m02:03:03.006055 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m02:03:03.010334 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 02:03:02.586021 => 02:03:03.009939
[0m02:03:03.011077 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m02:03:03.012675 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: Close
[0m02:03:03.017178 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (execute): 02:03:02.540854 => 02:03:03.016770
[0m02:03:03.020080 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa504579790>]}
[0m02:03:03.021835 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: Close
[0m02:03:03.024476 [info ] [Thread-3 (]: 2 of 4 OK created sql table model analytics_marts.dim_customer ................. [[32mSELECT 3789[0m in 0.53s]
[0m02:03:03.028049 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa504579350>]}
[0m02:03:03.030506 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m02:03:03.033090 [info ] [Thread-4 (]: 3 of 4 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 30037[0m in 0.54s]
[0m02:03:03.037715 [debug] [Thread-4 (]: Finished running node model.sales_analytics.orders_enriched
[0m02:03:03.041846 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m02:03:03.046415 [info ] [Thread-1 (]: 4 of 4 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m02:03:03.052243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now model.sales_analytics.fct_daily_sales)
[0m02:03:03.054649 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m02:03:03.187733 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m02:03:03.206046 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 02:03:03.056468 => 02:03:03.205120
[0m02:03:03.208309 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m02:03:03.301002 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.304164 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
    

  create temporary table "fct_daily_sales__dbt_tmp020303285335"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
      and date_trunc('day', order_ts)::date >= (
        coalesce( (select max(sales_date) from "warehouse"."analytics_marts"."fct_daily_sales"), '1900-01-01'::date )
        - interval '2 day'
      )
    
    group by 1
)
select * from base
  );
  
  
[0m02:03:03.306771 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:03.352075 [debug] [Thread-1 (]: SQL status: SELECT 3 in 0.0 seconds
[0m02:03:03.361506 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.364251 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m02:03:03.368053 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:03.370401 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.372906 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp020303285335'
        
      order by ordinal_position

  
[0m02:03:03.387193 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m02:03:03.397001 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.399524 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m02:03:03.408150 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m02:03:03.450567 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.453598 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp020303285335'
        
      order by ordinal_position

  
[0m02:03:03.462871 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m02:03:03.472271 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.474583 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m02:03:03.487209 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m02:03:03.533334 [debug] [Thread-1 (]: 
    In "warehouse"."analytics_marts"."fct_daily_sales":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m02:03:03.590962 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m02:03:03.613293 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.616222 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
        
            delete from "warehouse"."analytics_marts"."fct_daily_sales"
            where (
                sales_date) in (
                select (sales_date)
                from "fct_daily_sales__dbt_tmp020303285335"
            );

        
    

    insert into "warehouse"."analytics_marts"."fct_daily_sales" ("sales_date", "orders", "units_sold", "gross_revenue")
    (
        select "sales_date", "orders", "units_sold", "gross_revenue"
        from "fct_daily_sales__dbt_tmp020303285335"
    )
  
[0m02:03:03.621055 [debug] [Thread-1 (]: SQL status: INSERT 0 3 in 0.0 seconds
[0m02:03:03.637530 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.642461 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m02:03:03.646362 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:03.662027 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.665531 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m02:03:03.676558 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m02:03:03.686269 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.690502 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m02:03:03.699550 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m02:03:03.709141 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.711939 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m02:03:03.715348 [debug] [Thread-1 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m02:03:03.719000 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m02:03:03.721168 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m02:03:03.723625 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m02:03:03.730018 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m02:03:03.734009 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 02:03:03.210066 => 02:03:03.733265
[0m02:03:03.735956 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: Close
[0m02:03:03.739731 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c73f9f8-661b-4889-9eb5-b3c1ab7cd305', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505df8990>]}
[0m02:03:03.749396 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mINSERT 0 3[0m in 0.69s]
[0m02:03:03.754063 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m02:03:03.764214 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:03.766861 [debug] [MainThread]: On master: BEGIN
[0m02:03:03.769286 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:03:03.793600 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:03:03.797948 [debug] [MainThread]: On master: COMMIT
[0m02:03:03.801664 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:03.804196 [debug] [MainThread]: On master: COMMIT
[0m02:03:03.807462 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m02:03:03.810144 [debug] [MainThread]: On master: Close
[0m02:03:03.814619 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:03:03.817133 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m02:03:03.819764 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m02:03:03.822267 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m02:03:03.824777 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m02:03:03.827539 [info ] [MainThread]: 
[0m02:03:03.830918 [info ] [MainThread]: Finished running 1 view model, 2 table models, 1 incremental model in 0 hours 0 minutes and 2.47 seconds (2.47s).
[0m02:03:03.836516 [debug] [MainThread]: Command end result
[0m02:03:03.910080 [info ] [MainThread]: 
[0m02:03:03.918622 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:03:03.921932 [info ] [MainThread]: 
[0m02:03:03.931792 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m02:03:03.936611 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 5.7993875, "process_user_time": 16.59745, "process_kernel_time": 0.942695, "process_mem_max_rss": "122568", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m02:03:03.939846 [debug] [MainThread]: Command `dbt run` succeeded at 02:03:03.939365 after 5.80 seconds
[0m02:03:03.942633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa50a93fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa50a906b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa505db74d0>]}
[0m02:03:03.947127 [debug] [MainThread]: Flushing usage events
[0m02:03:10.244550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96d903790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96d903410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96e035d90>]}


============================== 02:03:10.257189 | 3b402632-698c-433f-abf1-53a8129ef06f ==============================
[0m02:03:10.257189 [info ] [MainThread]: Running with dbt=1.7.11
[0m02:03:10.259957 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt test', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:03:10.912899 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3b402632-698c-433f-abf1-53a8129ef06f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96c1858d0>]}
[0m02:03:11.146904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3b402632-698c-433f-abf1-53a8129ef06f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96c1e0690>]}
[0m02:03:11.149954 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m02:03:11.190329 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m02:03:11.560199 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:03:11.562611 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:03:11.577461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b402632-698c-433f-abf1-53a8129ef06f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96c1cf990>]}
[0m02:03:11.630892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b402632-698c-433f-abf1-53a8129ef06f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96bdb7e10>]}
[0m02:03:11.632723 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m02:03:11.634585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b402632-698c-433f-abf1-53a8129ef06f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96c159ed0>]}
[0m02:03:11.642185 [info ] [MainThread]: 
[0m02:03:11.645489 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m02:03:11.650014 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m02:03:11.653607 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m02:03:11.656567 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m02:03:11.659709 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m02:03:11.696224 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:03:11.697326 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:03:11.703062 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:03:11.708859 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:03:11.710837 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m02:03:11.712976 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m02:03:11.715043 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m02:03:11.716837 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m02:03:11.718492 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:11.720009 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:11.721893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:11.723723 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:11.739952 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:11.740791 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:11.741969 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:11.742734 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:11.743500 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:03:11.745163 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:03:11.747256 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:03:11.749408 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:03:11.751462 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m02:03:11.753717 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m02:03:11.756039 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m02:03:11.758170 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m02:03:11.766242 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:11.767271 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:11.768089 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:11.768878 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m02:03:11.771902 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m02:03:11.775414 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m02:03:11.778949 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m02:03:11.782283 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m02:03:11.784573 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m02:03:11.786537 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m02:03:11.788540 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m02:03:11.790579 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m02:03:11.808005 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:11.809916 [debug] [MainThread]: On master: BEGIN
[0m02:03:11.811368 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:11.822723 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:03:11.824962 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:11.826881 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m02:03:11.836204 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:11.841062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b402632-698c-433f-abf1-53a8129ef06f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96bd9fd10>]}
[0m02:03:11.843749 [debug] [MainThread]: On master: ROLLBACK
[0m02:03:11.846285 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:11.848397 [debug] [MainThread]: On master: BEGIN
[0m02:03:11.851409 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:03:11.853731 [debug] [MainThread]: On master: COMMIT
[0m02:03:11.855559 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:11.857354 [debug] [MainThread]: On master: COMMIT
[0m02:03:11.859545 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m02:03:11.861400 [debug] [MainThread]: On master: Close
[0m02:03:11.864085 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:03:11.866123 [info ] [MainThread]: 
[0m02:03:11.887196 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:11.888644 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:11.890608 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:11.892830 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:11.894876 [info ] [Thread-1 (]: 1 of 11 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m02:03:11.896917 [info ] [Thread-2 (]: 2 of 11 START test not_null_fct_daily_sales_gross_revenue ...................... [RUN]
[0m02:03:11.899748 [info ] [Thread-3 (]: 3 of 11 START test not_null_fct_daily_sales_orders ............................. [RUN]
[0m02:03:11.902325 [info ] [Thread-4 (]: 4 of 11 START test not_null_fct_daily_sales_sales_date ......................... [RUN]
[0m02:03:11.906114 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m02:03:11.910244 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m02:03:11.913623 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m02:03:11.916844 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m02:03:11.919404 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:11.921963 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:11.925462 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:11.928581 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:12.025269 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m02:03:12.029326 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m02:03:12.030490 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m02:03:12.041396 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m02:03:12.052054 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 02:03:11.931041 => 02:03:12.051272
[0m02:03:12.053325 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 02:03:11.996671 => 02:03:12.052710
[0m02:03:12.055831 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:12.057437 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 02:03:12.031447 => 02:03:12.056502
[0m02:03:12.058653 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 02:03:11.957415 => 02:03:12.058123
[0m02:03:12.059978 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:12.084275 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:12.097756 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m02:03:12.100000 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:12.107562 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m02:03:12.114194 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m02:03:12.123416 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m02:03:12.133898 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m02:03:12.135228 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m02:03:12.137812 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m02:03:12.139113 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m02:03:12.140516 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m02:03:12.142077 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: BEGIN
[0m02:03:12.144596 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:12.147410 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: BEGIN
[0m02:03:12.150018 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: BEGIN
[0m02:03:12.152262 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:03:12.156404 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:03:12.158768 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m02:03:12.167434 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.169679 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m02:03:12.172191 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "warehouse"."analytics_marts"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m02:03:12.174771 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.175969 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.177687 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.179046 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.180205 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m02:03:12.182607 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m02:03:12.184926 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m02:03:12.191102 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 02:03:12.061581 => 02:03:12.190381
[0m02:03:12.193917 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select gross_revenue
from "warehouse"."analytics_marts"."fct_daily_sales"
where gross_revenue is null



      
    ) dbt_internal_test
[0m02:03:12.196559 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sales_date
from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is null



      
    ) dbt_internal_test
[0m02:03:12.199214 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orders
from "warehouse"."analytics_marts"."fct_daily_sales"
where orders is null



      
    ) dbt_internal_test
[0m02:03:12.201819 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m02:03:12.206253 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.207441 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.210679 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.211707 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: Close
[0m02:03:12.216067 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 02:03:12.117268 => 02:03:12.215582
[0m02:03:12.221109 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 02:03:12.108962 => 02:03:12.220585
[0m02:03:12.226218 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 02:03:12.102116 => 02:03:12.225704
[0m02:03:12.229715 [info ] [Thread-1 (]: 1 of 11 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.32s]
[0m02:03:12.231594 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: ROLLBACK
[0m02:03:12.234004 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: ROLLBACK
[0m02:03:12.236143 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: ROLLBACK
[0m02:03:12.239049 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:12.241847 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: Close
[0m02:03:12.243940 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: Close
[0m02:03:12.246781 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: Close
[0m02:03:12.248759 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:12.252226 [info ] [Thread-2 (]: 2 of 11 PASS not_null_fct_daily_sales_gross_revenue ............................ [[32mPASS[0m in 0.34s]
[0m02:03:12.256195 [info ] [Thread-4 (]: 4 of 11 PASS not_null_fct_daily_sales_sales_date ............................... [[32mPASS[0m in 0.34s]
[0m02:03:12.260722 [info ] [Thread-3 (]: 3 of 11 PASS not_null_fct_daily_sales_orders ................................... [[32mPASS[0m in 0.35s]
[0m02:03:12.263353 [info ] [Thread-1 (]: 5 of 11 START test not_null_orders_enriched_line_amount ........................ [RUN]
[0m02:03:12.266211 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:12.268876 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:12.271477 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:12.274907 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m02:03:12.278342 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:12.280801 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:12.283266 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:12.285503 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:12.287834 [info ] [Thread-2 (]: 6 of 11 START test not_null_src_orders_order_id ................................ [RUN]
[0m02:03:12.293135 [info ] [Thread-4 (]: 7 of 11 START test not_null_src_orders_order_line_id ........................... [RUN]
[0m02:03:12.295858 [info ] [Thread-3 (]: 8 of 11 START test not_null_src_orders_order_ts ................................ [RUN]
[0m02:03:12.311996 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m02:03:12.314280 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m02:03:12.317087 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m02:03:12.319630 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m02:03:12.324040 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:12.325988 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:12.327723 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:12.339463 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m02:03:12.348903 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 02:03:12.297899 => 02:03:12.348352
[0m02:03:12.354470 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m02:03:12.365898 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m02:03:12.368949 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:12.382944 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m02:03:12.385901 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 02:03:12.343002 => 02:03:12.385247
[0m02:03:12.387174 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 02:03:12.356677 => 02:03:12.386528
[0m02:03:12.388617 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 02:03:12.329245 => 02:03:12.387731
[0m02:03:12.390233 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:12.392280 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:12.394067 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:12.400179 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m02:03:12.407346 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m02:03:12.408042 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m02:03:12.414179 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m02:03:12.417646 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: BEGIN
[0m02:03:12.422228 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:12.425000 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m02:03:12.427180 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m02:03:12.428746 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: BEGIN
[0m02:03:12.430441 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m02:03:12.431725 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: BEGIN
[0m02:03:12.433501 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:03:12.435352 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: BEGIN
[0m02:03:12.436202 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.437655 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m02:03:12.441371 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m02:03:12.443735 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m02:03:12.450147 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select line_amount
from "warehouse"."analytics_intermediate"."orders_enriched"
where line_amount is null



      
    ) dbt_internal_test
[0m02:03:12.451165 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.454160 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m02:03:12.455941 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_line_id
from "warehouse"."analytics_staging"."src_orders"
where order_line_id is null



      
    ) dbt_internal_test
[0m02:03:12.457840 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.460017 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.461343 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m02:03:12.462852 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.464261 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m02:03:12.466827 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_ts
from "warehouse"."analytics_staging"."src_orders"
where order_ts is null



      
    ) dbt_internal_test
[0m02:03:12.468217 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.474248 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 02:03:12.374095 => 02:03:12.473377
[0m02:03:12.476766 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "warehouse"."analytics_staging"."src_orders"
where order_id is null



      
    ) dbt_internal_test
[0m02:03:12.483385 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 02:03:12.395547 => 02:03:12.482846
[0m02:03:12.485875 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: ROLLBACK
[0m02:03:12.486889 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.490213 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: ROLLBACK
[0m02:03:12.492861 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: Close
[0m02:03:12.497293 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 02:03:12.401773 => 02:03:12.496850
[0m02:03:12.498070 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.500059 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: Close
[0m02:03:12.502790 [info ] [Thread-1 (]: 5 of 11 PASS not_null_orders_enriched_line_amount .............................. [[32mPASS[0m in 0.23s]
[0m02:03:12.504899 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: ROLLBACK
[0m02:03:12.509010 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 02:03:12.409558 => 02:03:12.508548
[0m02:03:12.512265 [info ] [Thread-4 (]: 7 of 11 PASS not_null_src_orders_order_line_id ................................. [[32mPASS[0m in 0.20s]
[0m02:03:12.514454 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:12.516831 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: Close
[0m02:03:12.518275 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: ROLLBACK
[0m02:03:12.521642 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:12.524661 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:12.528138 [info ] [Thread-3 (]: 8 of 11 PASS not_null_src_orders_order_ts ...................................... [[32mPASS[0m in 0.21s]
[0m02:03:12.530606 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: Close
[0m02:03:12.532612 [debug] [Thread-4 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:12.534778 [info ] [Thread-1 (]: 9 of 11 START test not_null_src_orders_quantity ................................ [RUN]
[0m02:03:12.538252 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:12.543475 [info ] [Thread-2 (]: 6 of 11 PASS not_null_src_orders_order_id ...................................... [[32mPASS[0m in 0.23s]
[0m02:03:12.545937 [info ] [Thread-4 (]: 10 of 11 START test unique_dim_customer_customer_id ............................ [RUN]
[0m02:03:12.550351 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m02:03:12.553211 [debug] [Thread-3 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:12.557462 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:12.561086 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m02:03:12.563410 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:12.565914 [info ] [Thread-3 (]: 11 of 11 START test unique_fct_daily_sales_sales_date .......................... [RUN]
[0m02:03:12.571198 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:12.591503 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m02:03:12.594483 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m02:03:12.615753 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m02:03:12.618287 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:12.634464 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m02:03:12.638968 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 02:03:12.596320 => 02:03:12.637957
[0m02:03:12.640796 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 02:03:12.574692 => 02:03:12.640016
[0m02:03:12.642806 [debug] [Thread-4 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:12.646543 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:12.655463 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 02:03:12.622282 => 02:03:12.654275
[0m02:03:12.657613 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m02:03:12.665751 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m02:03:12.667496 [debug] [Thread-3 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:12.677611 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m02:03:12.687655 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m02:03:12.689046 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m02:03:12.691898 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: BEGIN
[0m02:03:12.693645 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m02:03:12.695352 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: BEGIN
[0m02:03:12.697414 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m02:03:12.699415 [debug] [Thread-3 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: BEGIN
[0m02:03:12.701336 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m02:03:12.704937 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m02:03:12.716397 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.720720 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.721991 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m02:03:12.723942 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.725507 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m02:03:12.727306 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "warehouse"."analytics_marts"."dim_customer"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
[0m02:03:12.730219 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m02:03:12.733027 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "warehouse"."analytics_staging"."src_orders"
where quantity is null



      
    ) dbt_internal_test
[0m02:03:12.738801 [debug] [Thread-3 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    sales_date as unique_field,
    count(*) as n_records

from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is not null
group by sales_date
having count(*) > 1



      
    ) dbt_internal_test
[0m02:03:12.744584 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.745760 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.750692 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 02:03:12.648923 => 02:03:12.750116
[0m02:03:12.751746 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:12.756461 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 02:03:12.671967 => 02:03:12.755815
[0m02:03:12.758724 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: ROLLBACK
[0m02:03:12.763422 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 02:03:12.659699 => 02:03:12.762920
[0m02:03:12.766087 [debug] [Thread-3 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: ROLLBACK
[0m02:03:12.768561 [debug] [Thread-4 (]: On test.sales_analytics.unique_dim_customer_customer_id.b42affccd1: Close
[0m02:03:12.769820 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: ROLLBACK
[0m02:03:12.772081 [debug] [Thread-3 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: Close
[0m02:03:12.775084 [info ] [Thread-4 (]: 10 of 11 PASS unique_dim_customer_customer_id .................................. [[32mPASS[0m in 0.21s]
[0m02:03:12.777528 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: Close
[0m02:03:12.781558 [info ] [Thread-3 (]: 11 of 11 PASS unique_fct_daily_sales_sales_date ................................ [[32mPASS[0m in 0.19s]
[0m02:03:12.785154 [debug] [Thread-4 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:12.788816 [info ] [Thread-1 (]: 9 of 11 PASS not_null_src_orders_quantity ...................................... [[32mPASS[0m in 0.24s]
[0m02:03:12.791533 [debug] [Thread-3 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:12.795577 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:12.802792 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:12.804937 [debug] [MainThread]: On master: BEGIN
[0m02:03:12.807943 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m02:03:12.821972 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:03:12.826323 [debug] [MainThread]: On master: COMMIT
[0m02:03:12.828047 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:12.829715 [debug] [MainThread]: On master: COMMIT
[0m02:03:12.832451 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m02:03:12.834831 [debug] [MainThread]: On master: Close
[0m02:03:12.839540 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:03:12.843656 [debug] [MainThread]: Connection 'test.sales_analytics.unique_dim_customer_customer_id.b42affccd1' was properly closed.
[0m02:03:12.845913 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m02:03:12.847667 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_quantity.741e0fed47' was properly closed.
[0m02:03:12.849176 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d' was properly closed.
[0m02:03:12.850929 [info ] [MainThread]: 
[0m02:03:12.853263 [info ] [MainThread]: Finished running 11 tests in 0 hours 0 minutes and 1.21 seconds (1.21s).
[0m02:03:12.860991 [debug] [MainThread]: Command end result
[0m02:03:12.913944 [info ] [MainThread]: 
[0m02:03:12.916780 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:03:12.919333 [info ] [MainThread]: 
[0m02:03:12.924154 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=0 SKIP=0 TOTAL=11
[0m02:03:12.929167 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.7998347, "process_user_time": 7.30164, "process_kernel_time": 0.381129, "process_mem_max_rss": "121976", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m02:03:12.931858 [debug] [MainThread]: Command `dbt test` succeeded at 02:03:12.931417 after 2.80 seconds
[0m02:03:12.934087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96d0082d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa96d1cfc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9718a3b90>]}
[0m02:03:12.935983 [debug] [MainThread]: Flushing usage events
[0m02:03:22.352078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49a427310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49a61a690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49a61a090>]}


============================== 02:03:22.365773 | c0a70dd6-4417-4169-9f59-697a2c32cb31 ==============================
[0m02:03:22.365773 [info ] [MainThread]: Running with dbt=1.7.11
[0m02:03:22.368065 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/logs', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m02:03:22.719183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c0a70dd6-4417-4169-9f59-697a2c32cb31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb499707e90>]}
[0m02:03:22.917449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c0a70dd6-4417-4169-9f59-697a2c32cb31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49a466090>]}
[0m02:03:22.920365 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m02:03:22.960137 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m02:03:23.321717 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:03:23.324250 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:03:23.340423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c0a70dd6-4417-4169-9f59-697a2c32cb31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb499bd1710>]}
[0m02:03:23.365644 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c0a70dd6-4417-4169-9f59-697a2c32cb31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4993b7c50>]}
[0m02:03:23.367809 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m02:03:23.370315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0a70dd6-4417-4169-9f59-697a2c32cb31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49a466d10>]}
[0m02:03:23.379438 [info ] [MainThread]: 
[0m02:03:23.400876 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m02:03:23.413675 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m02:03:23.418402 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m02:03:23.423304 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m02:03:23.429224 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m02:03:23.498510 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:03:23.509584 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:03:23.526596 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:03:23.535115 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:03:23.537435 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m02:03:23.539928 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m02:03:23.542514 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m02:03:23.545236 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m02:03:23.547560 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:23.549921 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:23.552340 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:23.554657 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:23.577517 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:23.578865 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:23.580041 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:23.582370 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:23.583806 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m02:03:23.586273 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m02:03:23.588729 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m02:03:23.590809 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m02:03:23.592995 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m02:03:23.595453 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m02:03:23.597569 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m02:03:23.599756 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m02:03:23.610703 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m02:03:23.611922 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:23.612849 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:23.617349 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m02:03:23.618334 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:23.622312 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m02:03:23.626692 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m02:03:23.629781 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m02:03:23.633793 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m02:03:23.636517 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m02:03:23.638693 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m02:03:23.643939 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m02:03:23.663917 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:23.665906 [debug] [MainThread]: On master: BEGIN
[0m02:03:23.667646 [debug] [MainThread]: Opening a new connection, currently in state init
[0m02:03:23.681606 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m02:03:23.684060 [debug] [MainThread]: Using postgres connection "master"
[0m02:03:23.686004 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m02:03:23.696917 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m02:03:23.701311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0a70dd6-4417-4169-9f59-697a2c32cb31', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb499b8d210>]}
[0m02:03:23.703237 [debug] [MainThread]: On master: ROLLBACK
[0m02:03:23.705458 [debug] [MainThread]: On master: Close
[0m02:03:23.708171 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m02:03:23.710515 [info ] [MainThread]: 
[0m02:03:23.733292 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m02:03:23.736695 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m02:03:23.738897 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m02:03:23.757846 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m02:03:23.778057 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 02:03:23.740574 => 02:03:23.777375
[0m02:03:23.781521 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m02:03:23.785623 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 02:03:23.785065 => 02:03:23.785108
[0m02:03:23.789139 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m02:03:23.793067 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m02:03:23.794094 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m02:03:23.795192 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:23.796731 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:23.798762 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m02:03:23.801455 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m02:03:23.803996 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m02:03:23.806894 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m02:03:23.809009 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m02:03:23.810876 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m02:03:23.812865 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:23.814980 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:23.822984 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m02:03:23.831501 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 02:03:23.824670 => 02:03:23.830945
[0m02:03:23.874492 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m02:03:23.877319 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m02:03:23.879669 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m02:03:23.884860 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 02:03:23.884270 => 02:03:23.884302
[0m02:03:23.888922 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m02:03:23.890337 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 02:03:23.816825 => 02:03:23.889721
[0m02:03:23.891808 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 02:03:23.832849 => 02:03:23.891188
[0m02:03:23.893264 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:23.895552 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 02:03:23.855028 => 02:03:23.894863
[0m02:03:23.896886 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m02:03:23.899106 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:23.901895 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m02:03:23.904067 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:23.906163 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 02:03:23.905698 => 02:03:23.905726
[0m02:03:23.908554 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 02:03:23.908112 => 02:03:23.908133
[0m02:03:23.910684 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:23.913062 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 02:03:23.912562 => 02:03:23.912588
[0m02:03:23.915864 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m02:03:23.918985 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m02:03:23.932014 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m02:03:23.934517 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m02:03:23.936676 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:23.938960 [debug] [Thread-2 (]: Began running node model.sales_analytics.dim_customer
[0m02:03:23.942453 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m02:03:23.945265 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m02:03:23.947782 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.dim_customer)
[0m02:03:23.950254 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m02:03:23.952248 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:23.954177 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.dim_customer
[0m02:03:23.956108 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 02:03:23.920736 => 02:03:23.955660
[0m02:03:23.956827 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m02:03:23.968710 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m02:03:23.978150 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m02:03:23.980973 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:24.009023 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m02:03:24.013398 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 02:03:24.012612 => 02:03:24.012657
[0m02:03:24.020083 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m02:03:24.023038 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:24.024660 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (compile): 02:03:23.970934 => 02:03:24.024025
[0m02:03:24.025759 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 02:03:23.958823 => 02:03:24.025263
[0m02:03:24.026839 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 02:03:23.982906 => 02:03:24.026416
[0m02:03:24.028954 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m02:03:24.031534 [debug] [Thread-2 (]: Began executing node model.sales_analytics.dim_customer
[0m02:03:24.033845 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:24.036065 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m02:03:24.038602 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:24.041185 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (execute): 02:03:24.040670 => 02:03:24.040693
[0m02:03:24.043885 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 02:03:24.043393 => 02:03:24.043415
[0m02:03:24.046503 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 02:03:24.046027 => 02:03:24.046044
[0m02:03:24.058991 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m02:03:24.062433 [debug] [Thread-2 (]: Finished running node model.sales_analytics.dim_customer
[0m02:03:24.066128 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m02:03:24.069709 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m02:03:24.075174 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:24.077316 [debug] [Thread-3 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:24.081463 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:24.085468 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m02:03:24.093591 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m02:03:24.098427 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m02:03:24.100228 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 02:03:24.048831 => 02:03:24.099350
[0m02:03:24.102487 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:24.105119 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:24.107205 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:24.109226 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:24.124614 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m02:03:24.148089 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m02:03:24.159531 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m02:03:24.162163 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 02:03:24.161566 => 02:03:24.161589
[0m02:03:24.171823 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m02:03:24.174620 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:24.177718 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m02:03:24.180652 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:24.197262 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m02:03:24.198994 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 02:03:24.148850 => 02:03:24.198289
[0m02:03:24.201710 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 02:03:24.110841 => 02:03:24.201016
[0m02:03:24.203750 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 02:03:24.125987 => 02:03:24.202961
[0m02:03:24.206091 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:24.208813 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:24.211454 [debug] [Thread-3 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:24.214355 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 02:03:24.213789 => 02:03:24.213813
[0m02:03:24.216828 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 02:03:24.216157 => 02:03:24.216183
[0m02:03:24.220050 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 02:03:24.219335 => 02:03:24.219362
[0m02:03:24.226774 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m02:03:24.230748 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m02:03:24.231997 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 02:03:24.182768 => 02:03:24.231450
[0m02:03:24.235383 [debug] [Thread-3 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m02:03:24.237320 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:24.239936 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:24.242415 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:24.246873 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m02:03:24.249941 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m02:03:24.252177 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 02:03:24.251614 => 02:03:24.251634
[0m02:03:24.254432 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:24.256881 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:24.260540 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m02:03:24.274514 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m02:03:24.285761 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m02:03:24.298402 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 02:03:24.262420 => 02:03:24.297263
[0m02:03:24.301208 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:24.302943 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 02:03:24.275929 => 02:03:24.302215
[0m02:03:24.305247 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 02:03:24.304528 => 02:03:24.304557
[0m02:03:24.307443 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:24.310675 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m02:03:24.312977 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 02:03:24.312485 => 02:03:24.312508
[0m02:03:24.317337 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m02:03:24.322124 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:03:24.324158 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m02:03:24.325837 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m02:03:24.327305 [debug] [MainThread]: Connection 'test.sales_analytics.unique_dim_customer_customer_id.b42affccd1' was properly closed.
[0m02:03:24.328727 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m02:03:24.334649 [debug] [MainThread]: Command end result
[0m02:03:24.422620 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m02:03:24.424477 [info ] [MainThread]: Building catalog
[0m02:03:24.433008 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m02:03:24.456322 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m02:03:24.458362 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m02:03:24.460039 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:03:24.474483 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m02:03:24.476819 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m02:03:24.479267 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m02:03:24.487352 [debug] [ThreadPool]: SQL status: SELECT 39 in 0.0 seconds
[0m02:03:24.502400 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m02:03:24.504949 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m02:03:24.554707 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m02:03:24.558889 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.3069828, "process_user_time": 7.333744, "process_kernel_time": 0.283234, "process_mem_max_rss": "120424", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m02:03:24.562555 [debug] [MainThread]: Command `dbt docs generate` succeeded at 02:03:24.561644 after 2.31 seconds
[0m02:03:24.565157 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m02:03:24.567003 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m02:03:24.569449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49f03b950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49f0a8f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb49c7f3ed0>]}
[0m02:03:24.572066 [debug] [MainThread]: Flushing usage events
[0m03:58:18.550059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ced54a110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ced73e150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ceda17b10>]}


============================== 03:58:18.558251 | a1110388-e4a0-46cb-ac62-f40f2f8bce28 ==============================
[0m03:58:18.558251 [info ] [MainThread]: Running with dbt=1.7.11
[0m03:58:18.559457 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt deps', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:58:18.665765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a1110388-e4a0-46cb-ac62-f40f2f8bce28', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ced73e690>]}
[0m03:58:18.670089 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:58:18.680095 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m03:58:18.682124 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.74817497, "process_user_time": 9.447266, "process_kernel_time": 0.7806, "process_mem_max_rss": "104980", "process_in_blocks": "48", "process_out_blocks": "0"}
[0m03:58:18.683593 [debug] [MainThread]: Command `dbt deps` succeeded at 03:58:18.683309 after 0.75 seconds
[0m03:58:18.684809 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ced597150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ced596ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ced951e10>]}
[0m03:58:18.686281 [debug] [MainThread]: Flushing usage events
[0m03:58:22.944318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19a07c0890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19a1394c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19a0c1ccd0>]}


============================== 03:58:22.956023 | 23425a91-03d8-45e3-945a-7e31b66df99b ==============================
[0m03:58:22.956023 [info ] [MainThread]: Running with dbt=1.7.11
[0m03:58:22.958681 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:58:23.253977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '23425a91-03d8-45e3-945a-7e31b66df99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f199ff1cb50>]}
[0m03:58:23.392484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '23425a91-03d8-45e3-945a-7e31b66df99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f199ff94090>]}
[0m03:58:23.395862 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m03:58:23.430139 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m03:58:23.937135 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m03:58:23.938941 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/schema.yml
[0m03:58:23.940330 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/dim_customer.sql
[0m03:58:24.399432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '23425a91-03d8-45e3-945a-7e31b66df99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f199eb08250>]}
[0m03:58:24.436249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '23425a91-03d8-45e3-945a-7e31b66df99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f199f7c0990>]}
[0m03:58:24.438149 [info ] [MainThread]: Found 4 models, 10 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m03:58:24.439672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23425a91-03d8-45e3-945a-7e31b66df99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f199ffb95d0>]}
[0m03:58:24.443813 [info ] [MainThread]: 
[0m03:58:24.446266 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:58:24.449209 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m03:58:24.467203 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m03:58:24.469058 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m03:58:24.470639 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:24.484593 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m03:58:24.488046 [debug] [ThreadPool]: On list_warehouse: Close
[0m03:58:24.491781 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m03:58:24.495057 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m03:58:24.504242 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m03:58:24.505903 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m03:58:24.507145 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:58:24.515434 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.516969 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m03:58:24.518329 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m03:58:24.520395 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m03:58:24.522613 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m03:58:24.523937 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m03:58:24.525231 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m03:58:24.529975 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m03:58:24.531119 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m03:58:24.535110 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_snapshots)
[0m03:58:24.536426 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m03:58:24.539093 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m03:58:24.542111 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m03:58:24.606847 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m03:58:24.609733 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m03:58:24.612999 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m03:58:24.616207 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m03:58:24.617358 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m03:58:24.618846 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m03:58:24.620253 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m03:58:24.621457 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m03:58:24.622439 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:58:24.623688 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:24.624782 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:24.625855 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:24.634178 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.635175 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.635700 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.636138 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.637057 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m03:58:24.638536 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m03:58:24.640372 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m03:58:24.641512 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m03:58:24.642653 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m03:58:24.643880 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m03:58:24.644922 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m03:58:24.646349 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m03:58:24.651828 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:24.652581 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:24.653186 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:24.653661 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:24.655601 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m03:58:24.658442 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m03:58:24.660955 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m03:58:24.663232 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m03:58:24.665051 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m03:58:24.666363 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m03:58:24.667677 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m03:58:24.668792 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m03:58:24.681185 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:24.682838 [debug] [MainThread]: On master: BEGIN
[0m03:58:24.684688 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:58:24.692516 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.694444 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:24.695724 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:58:24.701876 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:24.705104 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '23425a91-03d8-45e3-945a-7e31b66df99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19a0c83750>]}
[0m03:58:24.706723 [debug] [MainThread]: On master: ROLLBACK
[0m03:58:24.708300 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:24.709761 [debug] [MainThread]: On master: BEGIN
[0m03:58:24.711157 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.712253 [debug] [MainThread]: On master: COMMIT
[0m03:58:24.713346 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:24.714481 [debug] [MainThread]: On master: COMMIT
[0m03:58:24.715732 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m03:58:24.716796 [debug] [MainThread]: On master: Close
[0m03:58:24.718480 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:58:24.719913 [info ] [MainThread]: 
[0m03:58:24.730890 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m03:58:24.732519 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m03:58:24.735484 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now snapshot.sales_analytics.customers_snapshot)
[0m03:58:24.737180 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m03:58:24.750885 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 03:58:24.738328 => 03:58:24.750477
[0m03:58:24.752519 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m03:58:24.849763 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m03:58:24.863006 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m03:58:24.865128 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m03:58:24.867096 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:58:24.877365 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.879433 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m03:58:24.881245 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m03:58:24.884092 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m03:58:24.885764 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m03:58:24.888303 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 03:58:24.753558 => 03:58:24.887908
[0m03:58:24.890270 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m03:58:24.896467 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m03:58:24.898386 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '23425a91-03d8-45e3-945a-7e31b66df99b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f199f78afd0>]}
[0m03:58:24.900458 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.16s]
[0m03:58:24.902790 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m03:58:24.908288 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:24.910184 [debug] [MainThread]: On master: BEGIN
[0m03:58:24.911544 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:58:24.920757 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m03:58:24.922384 [debug] [MainThread]: On master: COMMIT
[0m03:58:24.923895 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:24.925093 [debug] [MainThread]: On master: COMMIT
[0m03:58:24.926988 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m03:58:24.929432 [debug] [MainThread]: On master: Close
[0m03:58:24.931638 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:58:24.933453 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m03:58:24.934577 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m03:58:24.935996 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m03:58:24.937229 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m03:58:24.938436 [info ] [MainThread]: 
[0m03:58:24.939868 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.49 seconds (0.49s).
[0m03:58:24.943722 [debug] [MainThread]: Command end result
[0m03:58:24.977929 [info ] [MainThread]: 
[0m03:58:24.980912 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m03:58:24.982984 [info ] [MainThread]: 
[0m03:58:24.984634 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m03:58:24.986729 [info ] [MainThread]: 
[0m03:58:24.988761 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m03:58:24.991662 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 2.1626396, "process_user_time": 4.777077, "process_kernel_time": 0.150538, "process_mem_max_rss": "128148", "process_in_blocks": "32", "command_success": false, "process_out_blocks": "0"}
[0m03:58:24.993570 [debug] [MainThread]: Command `dbt snapshot` failed at 03:58:24.993309 after 2.16 seconds
[0m03:58:24.995153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19a5353dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19a5353a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f199ffd6e10>]}
[0m03:58:24.996767 [debug] [MainThread]: Flushing usage events
[0m03:58:45.494374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa813d4b690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8138827d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa813d4b5d0>]}


============================== 03:58:45.505740 | 6b9d9195-34b1-42a4-ab94-04c061112625 ==============================
[0m03:58:45.505740 [info ] [MainThread]: Running with dbt=1.7.11
[0m03:58:45.508921 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:58:45.796719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6b9d9195-34b1-42a4-ab94-04c061112625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa813888190>]}
[0m03:58:45.960406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6b9d9195-34b1-42a4-ab94-04c061112625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa814009710>]}
[0m03:58:45.963281 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m03:58:45.990722 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m03:58:46.306982 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:58:46.309280 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:58:46.325650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b9d9195-34b1-42a4-ab94-04c061112625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa812b70e90>]}
[0m03:58:46.343691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b9d9195-34b1-42a4-ab94-04c061112625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa812bb7d90>]}
[0m03:58:46.345880 [info ] [MainThread]: Found 4 models, 10 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m03:58:46.348576 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b9d9195-34b1-42a4-ab94-04c061112625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa812b97c90>]}
[0m03:58:46.354533 [info ] [MainThread]: 
[0m03:58:46.357981 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:58:46.363624 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m03:58:46.366678 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m03:58:46.370280 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m03:58:46.372842 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m03:58:46.401181 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m03:58:46.401984 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m03:58:46.407051 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m03:58:46.412138 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m03:58:46.414723 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m03:58:46.416348 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m03:58:46.417602 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m03:58:46.418861 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m03:58:46.420218 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:46.421827 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:46.423361 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:46.424662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:46.436887 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:46.437738 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:46.439243 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:46.439854 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:46.440490 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m03:58:46.441788 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m03:58:46.442966 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m03:58:46.444114 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m03:58:46.445283 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m03:58:46.446428 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m03:58:46.447592 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m03:58:46.448962 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m03:58:46.454723 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:46.456347 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:46.459138 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m03:58:46.459856 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:46.460533 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:46.463431 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m03:58:46.465356 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m03:58:46.467867 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m03:58:46.470820 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m03:58:46.473068 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m03:58:46.476153 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m03:58:46.477491 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m03:58:46.490971 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:46.493108 [debug] [MainThread]: On master: BEGIN
[0m03:58:46.494730 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:58:46.504515 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m03:58:46.506281 [debug] [MainThread]: Using postgres connection "master"
[0m03:58:46.507753 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:58:46.513797 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:46.517258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b9d9195-34b1-42a4-ab94-04c061112625', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa812b89b50>]}
[0m03:58:46.518617 [debug] [MainThread]: On master: ROLLBACK
[0m03:58:46.520346 [debug] [MainThread]: On master: Close
[0m03:58:46.522737 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:58:46.524426 [info ] [MainThread]: 
[0m03:58:46.541462 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m03:58:46.544875 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m03:58:46.546493 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m03:58:46.559612 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m03:58:46.572692 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 03:58:46.547659 => 03:58:46.572150
[0m03:58:46.574241 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m03:58:46.575803 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 03:58:46.575413 => 03:58:46.575443
[0m03:58:46.578126 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m03:58:46.581096 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m03:58:46.582375 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m03:58:46.583081 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m03:58:46.583765 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m03:58:46.585215 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.orders_enriched)
[0m03:58:46.587230 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m03:58:46.589336 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m03:58:46.591422 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m03:58:46.592779 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m03:58:46.593952 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m03:58:46.595205 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m03:58:46.596507 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m03:58:46.602249 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m03:58:46.608625 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 03:58:46.603702 => 03:58:46.608245
[0m03:58:46.629651 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m03:58:46.636425 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m03:58:46.638895 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m03:58:46.642504 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 03:58:46.642113 => 03:58:46.642141
[0m03:58:46.644685 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m03:58:46.646686 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m03:58:46.647868 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 03:58:46.609740 => 03:58:46.647405
[0m03:58:46.648800 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 03:58:46.597748 => 03:58:46.648275
[0m03:58:46.649976 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 03:58:46.630139 => 03:58:46.649522
[0m03:58:46.651826 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m03:58:46.655921 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m03:58:46.659851 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m03:58:46.661689 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m03:58:46.663547 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m03:58:46.665578 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 03:58:46.665210 => 03:58:46.665228
[0m03:58:46.667587 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 03:58:46.667102 => 03:58:46.667123
[0m03:58:46.669513 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 03:58:46.669156 => 03:58:46.669171
[0m03:58:46.678105 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m03:58:46.680414 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m03:58:46.682886 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m03:58:46.685429 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m03:58:46.688488 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m03:58:46.690237 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m03:58:46.692085 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m03:58:46.694136 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m03:58:46.696324 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.dim_customer)
[0m03:58:46.698514 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m03:58:46.700686 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m03:58:46.702271 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m03:58:46.703007 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 03:58:46.670883 => 03:58:46.702653
[0m03:58:46.704583 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m03:58:46.716111 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m03:58:46.722354 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m03:58:46.723908 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m03:58:46.740498 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m03:58:46.743922 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 03:58:46.743452 => 03:58:46.743474
[0m03:58:46.747653 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m03:58:46.749753 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m03:58:46.751111 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 03:58:46.725253 => 03:58:46.750542
[0m03:58:46.752149 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 03:58:46.717569 => 03:58:46.751678
[0m03:58:46.753173 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 03:58:46.705764 => 03:58:46.752745
[0m03:58:46.754378 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m03:58:46.755838 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m03:58:46.757277 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m03:58:46.758520 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m03:58:46.760181 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m03:58:46.762011 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 03:58:46.761367 => 03:58:46.761394
[0m03:58:46.763832 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 03:58:46.763358 => 03:58:46.763380
[0m03:58:46.765467 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 03:58:46.765103 => 03:58:46.765120
[0m03:58:46.773902 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m03:58:46.776168 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m03:58:46.778462 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m03:58:46.780478 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m03:58:46.783806 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m03:58:46.784895 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m03:58:46.786708 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m03:58:46.788966 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m03:58:46.790924 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m03:58:46.793600 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m03:58:46.794789 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 03:58:46.766699 => 03:58:46.794404
[0m03:58:46.796157 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m03:58:46.797610 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m03:58:46.799462 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m03:58:46.801157 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m03:58:46.811252 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m03:58:46.820833 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m03:58:46.829531 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m03:58:46.831198 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 03:58:46.830725 => 03:58:46.830743
[0m03:58:46.837635 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m03:58:46.839442 [debug] [Thread-4 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m03:58:46.841800 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m03:58:46.843199 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m03:58:46.859282 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m03:58:46.860313 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 03:58:46.812621 => 03:58:46.859885
[0m03:58:46.862515 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 03:58:46.802465 => 03:58:46.861886
[0m03:58:46.863581 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 03:58:46.821985 => 03:58:46.863026
[0m03:58:46.865290 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m03:58:46.866977 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m03:58:46.868817 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m03:58:46.871465 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 03:58:46.870861 => 03:58:46.870886
[0m03:58:46.873958 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 03:58:46.873314 => 03:58:46.873341
[0m03:58:46.876534 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 03:58:46.875908 => 03:58:46.875931
[0m03:58:46.877930 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 03:58:46.844635 => 03:58:46.877378
[0m03:58:46.881021 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m03:58:46.884665 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m03:58:46.887850 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m03:58:46.890170 [debug] [Thread-4 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m03:58:46.892551 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m03:58:46.897801 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 03:58:46.897089 => 03:58:46.897143
[0m03:58:46.900467 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m03:58:46.903211 [debug] [Thread-4 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m03:58:46.905139 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m03:58:46.920486 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m03:58:46.936643 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 03:58:46.908820 => 03:58:46.936053
[0m03:58:46.938880 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m03:58:46.941191 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 03:58:46.940529 => 03:58:46.940547
[0m03:58:46.944890 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m03:58:46.949165 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:58:46.950929 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m03:58:46.952291 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m03:58:46.953894 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m03:58:46.955556 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m03:58:46.960546 [debug] [MainThread]: Command end result
[0m03:58:47.026222 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m03:58:47.027982 [info ] [MainThread]: Building catalog
[0m03:58:47.036197 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m03:58:47.059279 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m03:58:47.061526 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m03:58:47.063257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:58:47.077961 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m03:58:47.079796 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m03:58:47.082081 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m03:58:47.091154 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m03:58:47.096739 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m03:58:47.099193 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m03:58:47.142294 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m03:58:47.146239 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.7403687, "process_user_time": 12.513151, "process_kernel_time": 0.523057, "process_mem_max_rss": "121308", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m03:58:47.149433 [debug] [MainThread]: Command `dbt docs generate` succeeded at 03:58:47.148842 after 1.74 seconds
[0m03:58:47.151869 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m03:58:47.154281 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m03:58:47.156736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa813d4bbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8138e7ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8138e7350>]}
[0m03:58:47.159403 [debug] [MainThread]: Flushing usage events
[0m04:04:12.462413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b15f33290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b15f333d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b15f32250>]}


============================== 04:04:12.471038 | dce7678d-9a9a-4372-86ba-53c95cd84acb ==============================
[0m04:04:12.471038 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:04:12.472816 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:04:12.565103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dce7678d-9a9a-4372-86ba-53c95cd84acb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b1601cd50>]}
[0m04:04:12.570725 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:04:12.577652 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:04:12.579051 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.17383716, "process_user_time": 2.83291, "process_kernel_time": 0.169575, "process_mem_max_rss": "104628", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:04:12.580143 [debug] [MainThread]: Command `dbt deps` succeeded at 04:04:12.579922 after 0.17 seconds
[0m04:04:12.581011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b15f7f190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b15fe6850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0b174ee550>]}
[0m04:04:12.582021 [debug] [MainThread]: Flushing usage events
[0m04:04:16.264539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596ffafd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59703f1450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596ffaeb10>]}


============================== 04:04:16.272566 | a1eaf62c-0186-4289-992a-79edc020fc0b ==============================
[0m04:04:16.272566 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:04:16.274310 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'debug': 'False', 'log_path': '/usr/app/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt snapshot', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:04:16.529224 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a1eaf62c-0186-4289-992a-79edc020fc0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596f7de290>]}
[0m04:04:16.628296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a1eaf62c-0186-4289-992a-79edc020fc0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596ff94990>]}
[0m04:04:16.630892 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:04:16.648458 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:04:16.789789 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m04:04:16.791255 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/schema.yml
[0m04:04:16.792124 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/dim_customer.sql
[0m04:04:17.171016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a1eaf62c-0186-4289-992a-79edc020fc0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596f3f5e90>]}
[0m04:04:17.207533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a1eaf62c-0186-4289-992a-79edc020fc0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596efb4190>]}
[0m04:04:17.209193 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:04:17.210274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a1eaf62c-0186-4289-992a-79edc020fc0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596e7afd90>]}
[0m04:04:17.213223 [info ] [MainThread]: 
[0m04:04:17.215119 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:04:17.217601 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m04:04:17.231856 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m04:04:17.233917 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m04:04:17.235142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:17.245492 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m04:04:17.248921 [debug] [ThreadPool]: On list_warehouse: Close
[0m04:04:17.252779 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m04:04:17.255604 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m04:04:17.263561 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:04:17.264955 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m04:04:17.266338 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:04:17.274805 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.276791 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:04:17.278783 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m04:04:17.281083 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m04:04:17.283414 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m04:04:17.285208 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:04:17.286561 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m04:04:17.298639 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m04:04:17.299756 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m04:04:17.302726 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_analytics_marts)
[0m04:04:17.304460 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:04:17.305437 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:04:17.307034 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:04:17.355880 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:04:17.359405 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:04:17.363612 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:04:17.367339 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:04:17.369092 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:04:17.371397 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:04:17.373785 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:04:17.375945 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:04:17.377541 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:04:17.378927 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:17.380151 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:17.381095 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:17.387769 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.388403 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.389126 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:04:17.389466 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.389790 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.390509 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:04:17.391215 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:04:17.391923 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:04:17.392487 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:04:17.393164 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:04:17.394319 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:04:17.395165 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:04:17.398475 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:17.398982 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:17.399390 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:17.399728 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:17.401283 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:04:17.403153 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:04:17.404801 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:04:17.406381 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:04:17.407535 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:04:17.408218 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:04:17.409084 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:04:17.409811 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:04:17.419172 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:17.420621 [debug] [MainThread]: On master: BEGIN
[0m04:04:17.421658 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:04:17.429410 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.430751 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:17.431844 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:04:17.436601 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:17.438951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a1eaf62c-0186-4289-992a-79edc020fc0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596f3b4f90>]}
[0m04:04:17.440379 [debug] [MainThread]: On master: ROLLBACK
[0m04:04:17.441798 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:17.443185 [debug] [MainThread]: On master: BEGIN
[0m04:04:17.445283 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.446746 [debug] [MainThread]: On master: COMMIT
[0m04:04:17.447921 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:17.448876 [debug] [MainThread]: On master: COMMIT
[0m04:04:17.450142 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:04:17.451212 [debug] [MainThread]: On master: Close
[0m04:04:17.452718 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:04:17.453556 [info ] [MainThread]: 
[0m04:04:17.462582 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:04:17.464970 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m04:04:17.467540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m04:04:17.468803 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:04:17.478641 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:04:17.469738 => 04:04:17.478353
[0m04:04:17.479865 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:04:17.551424 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m04:04:17.563421 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:04:17.564927 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m04:04:17.566235 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:04:17.574405 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.575676 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:04:17.576671 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m04:04:17.578017 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m04:04:17.578839 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m04:04:17.579976 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:04:17.480836 => 04:04:17.579712
[0m04:04:17.580712 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m04:04:17.585409 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:04:17.586469 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a1eaf62c-0186-4289-992a-79edc020fc0b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596efc31d0>]}
[0m04:04:17.587746 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.12s]
[0m04:04:17.589063 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:04:17.592332 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:17.593178 [debug] [MainThread]: On master: BEGIN
[0m04:04:17.593900 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:04:17.601838 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:04:17.602840 [debug] [MainThread]: On master: COMMIT
[0m04:04:17.603607 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:17.604218 [debug] [MainThread]: On master: COMMIT
[0m04:04:17.604943 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:04:17.605545 [debug] [MainThread]: On master: Close
[0m04:04:17.606584 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:04:17.607155 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m04:04:17.607681 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m04:04:17.608189 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m04:04:17.608697 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m04:04:17.609278 [info ] [MainThread]: 
[0m04:04:17.610160 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.39 seconds (0.39s).
[0m04:04:17.611452 [debug] [MainThread]: Command end result
[0m04:04:17.631037 [info ] [MainThread]: 
[0m04:04:17.632353 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:04:17.633811 [info ] [MainThread]: 
[0m04:04:17.635285 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:04:17.637356 [info ] [MainThread]: 
[0m04:04:17.638847 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m04:04:17.640358 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 1.4533106, "process_user_time": 3.875582, "process_kernel_time": 0.169369, "process_mem_max_rss": "127784", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:04:17.641356 [debug] [MainThread]: Command `dbt snapshot` failed at 04:04:17.641192 after 1.45 seconds
[0m04:04:17.642160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596fff37d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f596fff3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5974b27710>]}
[0m04:04:17.642911 [debug] [MainThread]: Flushing usage events
[0m04:04:23.004089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434e0dc490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434e0d6290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434e0d66d0>]}


============================== 04:04:23.012028 | 13ace90e-1e6f-40e1-b0e7-e6c20e392e9f ==============================
[0m04:04:23.012028 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:04:23.013232 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:04:23.221258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '13ace90e-1e6f-40e1-b0e7-e6c20e392e9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434e168ad0>]}
[0m04:04:23.329412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '13ace90e-1e6f-40e1-b0e7-e6c20e392e9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434d545550>]}
[0m04:04:23.331991 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:04:23.350777 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:04:23.495537 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:04:23.496809 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:04:23.506601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '13ace90e-1e6f-40e1-b0e7-e6c20e392e9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434cdd0c10>]}
[0m04:04:23.518553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '13ace90e-1e6f-40e1-b0e7-e6c20e392e9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434cdabf50>]}
[0m04:04:23.520336 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:04:23.521968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13ace90e-1e6f-40e1-b0e7-e6c20e392e9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434e168ad0>]}
[0m04:04:23.526826 [info ] [MainThread]: 
[0m04:04:23.529926 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:04:23.536475 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:04:23.538250 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:04:23.539782 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:04:23.541784 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:04:23.561052 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:04:23.565052 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:04:23.569757 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:04:23.573956 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:04:23.575925 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:04:23.578003 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:04:23.580436 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:04:23.582407 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:04:23.584056 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:23.585618 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:23.586681 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:23.587821 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:23.599030 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:23.600657 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:04:23.601658 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:23.602414 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:04:23.603689 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:23.604093 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:04:23.605689 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:04:23.606121 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:23.607031 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:04:23.608055 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:04:23.608475 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:23.609232 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:04:23.612313 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:04:23.612901 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:23.613373 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:23.614030 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:04:23.615215 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:04:23.617099 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:04:23.619117 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:04:23.622180 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:04:23.623227 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:04:23.623665 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:23.627698 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:04:23.628862 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:04:23.635834 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:23.637306 [debug] [MainThread]: On master: BEGIN
[0m04:04:23.638405 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:04:23.646588 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:04:23.648447 [debug] [MainThread]: Using postgres connection "master"
[0m04:04:23.650032 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:04:23.654475 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:23.657546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '13ace90e-1e6f-40e1-b0e7-e6c20e392e9f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434d11d450>]}
[0m04:04:23.659210 [debug] [MainThread]: On master: ROLLBACK
[0m04:04:23.661079 [debug] [MainThread]: On master: Close
[0m04:04:23.662928 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:04:23.664200 [info ] [MainThread]: 
[0m04:04:23.674839 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m04:04:23.676784 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.src_orders)
[0m04:04:23.678285 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m04:04:23.687553 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m04:04:23.702268 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 04:04:23.679826 => 04:04:23.701843
[0m04:04:23.703421 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m04:04:23.704871 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 04:04:23.704529 => 04:04:23.704551
[0m04:04:23.706619 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m04:04:23.708530 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m04:04:23.709478 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:04:23.710043 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:04:23.710641 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:04:23.714335 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.orders_enriched)
[0m04:04:23.716033 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m04:04:23.718294 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m04:04:23.719763 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m04:04:23.720787 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m04:04:23.721745 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:04:23.722628 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:04:23.723701 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:04:23.728660 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m04:04:23.734562 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:04:23.730113 => 04:04:23.734213
[0m04:04:23.752223 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m04:04:23.760466 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m04:04:23.763142 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:04:23.766196 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:04:23.765858 => 04:04:23.765878
[0m04:04:23.768617 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:04:23.769922 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 04:04:23.724470 => 04:04:23.769574
[0m04:04:23.770788 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:04:23.771799 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 04:04:23.735670 => 04:04:23.771416
[0m04:04:23.772557 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 04:04:23.753172 => 04:04:23.772246
[0m04:04:23.773490 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m04:04:23.775051 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m04:04:23.775998 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:04:23.776981 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:04:23.778136 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 04:04:23.777838 => 04:04:23.777853
[0m04:04:23.779119 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:04:23.780167 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 04:04:23.779868 => 04:04:23.779881
[0m04:04:23.781191 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 04:04:23.780925 => 04:04:23.780935
[0m04:04:23.782845 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m04:04:23.791155 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m04:04:23.793369 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:04:23.795902 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:04:23.798052 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:04:23.801525 [debug] [Thread-2 (]: Began running node model.sales_analytics.dim_customer
[0m04:04:23.803004 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m04:04:23.804543 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m04:04:23.805820 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.dim_customer)
[0m04:04:23.807227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m04:04:23.808364 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:04:23.808940 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 04:04:23.783703 => 04:04:23.808678
[0m04:04:23.809751 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.dim_customer
[0m04:04:23.810698 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m04:04:23.816507 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m04:04:23.817348 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:04:23.821397 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m04:04:23.831681 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m04:04:23.835470 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 04:04:23.835199 => 04:04:23.835212
[0m04:04:23.840243 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:04:23.842084 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:04:23.842938 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (compile): 04:04:23.818232 => 04:04:23.842569
[0m04:04:23.843713 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 04:04:23.822984 => 04:04:23.843356
[0m04:04:23.844481 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 04:04:23.811459 => 04:04:23.844151
[0m04:04:23.845863 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m04:04:23.846893 [debug] [Thread-2 (]: Began executing node model.sales_analytics.dim_customer
[0m04:04:23.848202 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m04:04:23.849233 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:04:23.850559 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:04:23.852483 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (execute): 04:04:23.852036 => 04:04:23.852055
[0m04:04:23.854053 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 04:04:23.853794 => 04:04:23.853806
[0m04:04:23.855380 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 04:04:23.855128 => 04:04:23.855137
[0m04:04:23.861603 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m04:04:23.863366 [debug] [Thread-2 (]: Finished running node model.sales_analytics.dim_customer
[0m04:04:23.865579 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m04:04:23.867412 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:04:23.870712 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:04:23.871372 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:04:23.872605 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:04:23.873981 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m04:04:23.875161 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m04:04:23.876333 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m04:04:23.877283 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:04:23.878048 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 04:04:23.856649 => 04:04:23.877806
[0m04:04:23.878596 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:04:23.879418 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:04:23.884854 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m04:04:23.885800 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:04:23.896012 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m04:04:23.901723 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m04:04:23.904200 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 04:04:23.903868 => 04:04:23.903883
[0m04:04:23.908006 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:04:23.909645 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:04:23.910642 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 04:04:23.886490 => 04:04:23.910238
[0m04:04:23.911378 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 04:04:23.896946 => 04:04:23.911010
[0m04:04:23.912274 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 04:04:23.880095 => 04:04:23.911878
[0m04:04:23.913674 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m04:04:23.915348 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:04:23.916885 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:04:23.918018 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:04:23.919294 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:04:23.920609 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 04:04:23.920269 => 04:04:23.920287
[0m04:04:23.922083 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 04:04:23.921756 => 04:04:23.921771
[0m04:04:23.923745 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 04:04:23.923461 => 04:04:23.923471
[0m04:04:23.932103 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m04:04:23.934232 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:04:23.936376 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:04:23.938730 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:04:23.942039 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:04:23.943468 [debug] [Thread-3 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:04:23.946068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.unique_dim_customer_customer_id.b42affccd1, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m04:04:23.947696 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m04:04:23.948667 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:04:23.949536 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:04:23.956024 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 04:04:23.924846 => 04:04:23.955712
[0m04:04:23.956784 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m04:04:23.962214 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m04:04:23.963890 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:04:23.967915 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 04:04:23.967649 => 04:04:23.967658
[0m04:04:23.969489 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:04:23.973368 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 04:04:23.957628 => 04:04:23.972890
[0m04:04:23.974031 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 04:04:23.950480 => 04:04:23.973663
[0m04:04:23.974962 [debug] [Thread-3 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:04:23.975866 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:04:23.976819 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 04:04:23.976584 => 04:04:23.976594
[0m04:04:23.977696 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 04:04:23.977462 => 04:04:23.977470
[0m04:04:23.979156 [debug] [Thread-3 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:04:23.980577 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:04:23.983272 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:04:23.984099 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m04:04:23.984917 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m04:04:23.985771 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m04:04:23.986584 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m04:04:23.989472 [debug] [MainThread]: Command end result
[0m04:04:24.035339 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m04:04:24.036517 [info ] [MainThread]: Building catalog
[0m04:04:24.040146 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m04:04:24.050870 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:04:24.052458 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m04:04:24.053880 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:04:24.063317 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:04:24.065800 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:04:24.067995 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m04:04:24.074496 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:04:24.078672 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m04:04:24.080512 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m04:04:24.113534 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m04:04:24.115649 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.1747117, "process_user_time": 3.673251, "process_kernel_time": 0.227721, "process_mem_max_rss": "121244", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:04:24.117032 [debug] [MainThread]: Command `dbt docs generate` succeeded at 04:04:24.116821 after 1.18 seconds
[0m04:04:24.117967 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m04:04:24.118949 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m04:04:24.119980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f434eceba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4352cb0f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4352b9d010>]}
[0m04:04:24.120963 [debug] [MainThread]: Flushing usage events
[0m04:05:58.666386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5efd3d410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5efbed9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5ef8d7f50>]}


============================== 04:05:58.672491 | 2b0c05fc-65d1-452f-9a66-afe71568146e ==============================
[0m04:05:58.672491 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:05:58.673641 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m04:05:58.769025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b0c05fc-65d1-452f-9a66-afe71568146e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5ef95da50>]}
[0m04:05:58.775073 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:05:58.786195 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:05:58.787668 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.18674779, "process_user_time": 2.782172, "process_kernel_time": 0.110483, "process_mem_max_rss": "104988", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:05:58.788664 [debug] [MainThread]: Command `dbt deps` succeeded at 04:05:58.788481 after 0.19 seconds
[0m04:05:58.789480 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5ef922f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5ef922c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5f0fe9f90>]}
[0m04:05:58.790443 [debug] [MainThread]: Flushing usage events
[0m04:06:02.305856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee733ded0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee73526d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee7353890>]}


============================== 04:06:02.313001 | f34510de-6620-4108-ab7c-bf2289ecfe4a ==============================
[0m04:06:02.313001 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:06:02.314559 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:06:02.503706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f34510de-6620-4108-ab7c-bf2289ecfe4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee6794e10>]}
[0m04:06:02.609047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f34510de-6620-4108-ab7c-bf2289ecfe4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee7385fd0>]}
[0m04:06:02.611689 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:06:02.634760 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:06:02.733544 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:06:02.734480 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:06:02.741918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f34510de-6620-4108-ab7c-bf2289ecfe4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee5f706d0>]}
[0m04:06:02.769529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f34510de-6620-4108-ab7c-bf2289ecfe4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee636e750>]}
[0m04:06:02.770645 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:06:02.771804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f34510de-6620-4108-ab7c-bf2289ecfe4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee6380d50>]}
[0m04:06:02.774824 [info ] [MainThread]: 
[0m04:06:02.776678 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:06:02.779392 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m04:06:02.793238 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m04:06:02.795373 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m04:06:02.796620 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:02.805323 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m04:06:02.807782 [debug] [ThreadPool]: On list_warehouse: Close
[0m04:06:02.811902 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_snapshots)
[0m04:06:02.813349 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:06:02.814496 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:06:02.815935 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:06:02.822668 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:06:02.826517 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:06:02.831217 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:06:02.834965 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:06:02.836985 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:06:02.838518 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:06:02.839799 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:06:02.841352 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:06:02.843036 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:06:02.844463 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:02.845351 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:02.846159 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:02.852335 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:02.852767 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:02.853496 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:06:02.854378 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:02.854871 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:06:02.855340 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:02.856204 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:06:02.857159 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:06:02.858234 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:06:02.859029 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:06:02.860146 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:06:02.861328 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:06:02.862535 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:02.864452 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:06:02.864896 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:02.865381 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:02.865875 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:02.866919 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:06:02.868726 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:06:02.870783 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:06:02.872726 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:06:02.875334 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:06:02.876081 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:06:02.876762 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:06:02.885806 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:02.887315 [debug] [MainThread]: On master: BEGIN
[0m04:06:02.888600 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:06:02.895628 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:06:02.896923 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:02.898284 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:06:02.902998 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:02.906371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f34510de-6620-4108-ab7c-bf2289ecfe4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee73c0350>]}
[0m04:06:02.908342 [debug] [MainThread]: On master: ROLLBACK
[0m04:06:02.910255 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:02.912157 [debug] [MainThread]: On master: BEGIN
[0m04:06:02.914118 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:06:02.915412 [debug] [MainThread]: On master: COMMIT
[0m04:06:02.916642 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:02.917814 [debug] [MainThread]: On master: COMMIT
[0m04:06:02.919222 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:06:02.920398 [debug] [MainThread]: On master: Close
[0m04:06:02.921776 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:06:02.922686 [info ] [MainThread]: 
[0m04:06:02.931161 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:06:02.932147 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m04:06:02.933601 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m04:06:02.934678 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:06:02.945194 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:06:02.935396 => 04:06:02.944839
[0m04:06:02.946566 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:06:03.012427 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m04:06:03.027482 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:06:03.028667 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m04:06:03.029762 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:06:03.037185 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m04:06:03.038641 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:06:03.040152 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m04:06:03.041901 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m04:06:03.042896 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m04:06:03.044326 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:06:02.947574 => 04:06:03.044057
[0m04:06:03.045333 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m04:06:03.049936 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:06:03.051059 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f34510de-6620-4108-ab7c-bf2289ecfe4a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee5ba08d0>]}
[0m04:06:03.052400 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.12s]
[0m04:06:03.053794 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:06:03.057095 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:03.058002 [debug] [MainThread]: On master: BEGIN
[0m04:06:03.058772 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:06:03.065711 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:06:03.066821 [debug] [MainThread]: On master: COMMIT
[0m04:06:03.067731 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:03.068632 [debug] [MainThread]: On master: COMMIT
[0m04:06:03.069761 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:06:03.070524 [debug] [MainThread]: On master: Close
[0m04:06:03.071700 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:06:03.072537 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m04:06:03.073317 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m04:06:03.074137 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m04:06:03.075099 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m04:06:03.076150 [info ] [MainThread]: 
[0m04:06:03.077779 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.30 seconds (0.30s).
[0m04:06:03.079374 [debug] [MainThread]: Command end result
[0m04:06:03.101111 [info ] [MainThread]: 
[0m04:06:03.102465 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:06:03.103760 [info ] [MainThread]: 
[0m04:06:03.105052 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:06:03.106333 [info ] [MainThread]: 
[0m04:06:03.108250 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m04:06:03.110511 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 0.86729985, "process_user_time": 3.360754, "process_kernel_time": 0.178975, "process_mem_max_rss": "121268", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:06:03.113073 [debug] [MainThread]: Command `dbt snapshot` failed at 04:06:03.112810 after 0.87 seconds
[0m04:06:03.114479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee73a6f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee73a7350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcee73a7590>]}
[0m04:06:03.115795 [debug] [MainThread]: Flushing usage events
[0m04:06:08.260616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1271e84590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1271eb3810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1271e86450>]}


============================== 04:06:08.268830 | fa5dc136-b2b1-40c7-8623-31490fe24051 ==============================
[0m04:06:08.268830 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:06:08.270124 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:06:08.481781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fa5dc136-b2b1-40c7-8623-31490fe24051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12718ffd50>]}
[0m04:06:08.590702 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fa5dc136-b2b1-40c7-8623-31490fe24051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f127196c790>]}
[0m04:06:08.593075 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:06:08.610837 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:06:08.741609 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:06:08.742733 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:06:08.750343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa5dc136-b2b1-40c7-8623-31490fe24051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12718fb410>]}
[0m04:06:08.763091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fa5dc136-b2b1-40c7-8623-31490fe24051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12711b7fd0>]}
[0m04:06:08.764204 [info ] [MainThread]: Found 4 models, 11 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:06:08.765507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fa5dc136-b2b1-40c7-8623-31490fe24051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1272337810>]}
[0m04:06:08.768388 [info ] [MainThread]: 
[0m04:06:08.770143 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:06:08.773285 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:06:08.774284 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:06:08.775271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:06:08.776909 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:06:08.791820 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:06:08.794844 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:06:08.798082 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:06:08.801154 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:06:08.802690 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:06:08.804205 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:06:08.805379 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:06:08.806332 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:06:08.807223 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:08.808084 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:08.808750 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:08.809375 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:08.816171 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:08.817088 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:08.817581 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:08.817930 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:08.818493 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:06:08.819337 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:06:08.820109 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:06:08.820848 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:06:08.821559 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:06:08.822367 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:06:08.823142 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:06:08.823927 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:06:08.827566 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:08.828270 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:08.829701 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:06:08.830163 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:08.830528 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:08.832173 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:06:08.833162 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:06:08.834701 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:06:08.836521 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:06:08.837569 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:06:08.839252 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:06:08.840117 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:06:08.847665 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:08.848789 [debug] [MainThread]: On master: BEGIN
[0m04:06:08.849740 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:06:08.856383 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:06:08.857233 [debug] [MainThread]: Using postgres connection "master"
[0m04:06:08.858054 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:06:08.862783 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:08.865262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fa5dc136-b2b1-40c7-8623-31490fe24051', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1271e7c5d0>]}
[0m04:06:08.866534 [debug] [MainThread]: On master: ROLLBACK
[0m04:06:08.867955 [debug] [MainThread]: On master: Close
[0m04:06:08.869920 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:06:08.870953 [info ] [MainThread]: 
[0m04:06:08.880105 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m04:06:08.881730 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m04:06:08.882615 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m04:06:08.890761 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m04:06:08.900236 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 04:06:08.883358 => 04:06:08.899893
[0m04:06:08.901245 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m04:06:08.902285 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 04:06:08.901989 => 04:06:08.902009
[0m04:06:08.903820 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m04:06:08.907022 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m04:06:08.907950 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:06:08.908473 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:06:08.908960 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:06:08.909952 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m04:06:08.911156 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m04:06:08.912474 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m04:06:08.913679 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m04:06:08.914543 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m04:06:08.915398 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:06:08.916306 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:06:08.917116 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:06:08.922167 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m04:06:08.927152 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:06:08.923247 => 04:06:08.926819
[0m04:06:08.942995 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m04:06:08.948756 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m04:06:08.951858 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:06:08.955537 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:06:08.955163 => 04:06:08.955179
[0m04:06:08.957651 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:06:08.959511 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:06:08.960249 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 04:06:08.928325 => 04:06:08.959986
[0m04:06:08.960895 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 04:06:08.917846 => 04:06:08.960649
[0m04:06:08.961388 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 04:06:08.944142 => 04:06:08.961158
[0m04:06:08.962534 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m04:06:08.963387 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:06:08.964292 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m04:06:08.965175 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:06:08.966124 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:06:08.967072 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 04:06:08.966819 => 04:06:08.966831
[0m04:06:08.967979 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 04:06:08.967704 => 04:06:08.967714
[0m04:06:08.968913 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 04:06:08.968621 => 04:06:08.968631
[0m04:06:08.976095 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m04:06:08.977591 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:06:08.979296 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m04:06:08.980991 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:06:08.982940 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:06:08.984179 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m04:06:08.985333 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m04:06:08.986550 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m04:06:08.987781 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.dim_customer)
[0m04:06:08.989149 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m04:06:08.989659 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 04:06:08.969568 => 04:06:08.989428
[0m04:06:08.990288 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:06:08.991069 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m04:06:08.991850 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m04:06:08.992615 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:06:08.997843 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m04:06:09.001535 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m04:06:09.011236 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m04:06:09.012710 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 04:06:09.012422 => 04:06:09.012437
[0m04:06:09.018590 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:06:09.019755 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:06:09.020544 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 04:06:08.998586 => 04:06:09.020230
[0m04:06:09.021283 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 04:06:09.002762 => 04:06:09.020934
[0m04:06:09.022356 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m04:06:09.022905 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 04:06:08.993233 => 04:06:09.022635
[0m04:06:09.023701 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m04:06:09.024656 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m04:06:09.025528 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:06:09.026338 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:06:09.027316 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 04:06:09.027056 => 04:06:09.027067
[0m04:06:09.028248 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 04:06:09.028007 => 04:06:09.028018
[0m04:06:09.034156 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m04:06:09.035333 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 04:06:09.035007 => 04:06:09.035017
[0m04:06:09.037012 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m04:06:09.038784 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m04:06:09.041525 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:06:09.043042 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:06:09.043738 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:06:09.044868 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:06:09.046078 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m04:06:09.046697 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 04:06:09.028955 => 04:06:09.046467
[0m04:06:09.047749 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.unique_dim_customer_customer_id.b42affccd1)
[0m04:06:09.048912 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m04:06:09.049759 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:06:09.050662 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:06:09.051497 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:06:09.052454 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:06:09.058284 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m04:06:09.059364 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 04:06:09.059110 => 04:06:09.059119
[0m04:06:09.067468 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_dim_customer_customer_id.b42affccd1"
[0m04:06:09.073053 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m04:06:09.077725 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:06:09.081968 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:06:09.083386 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m04:06:09.084608 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:06:09.085274 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 04:06:09.068718 => 04:06:09.084948
[0m04:06:09.085892 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (compile): 04:06:09.060213 => 04:06:09.085592
[0m04:06:09.086499 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 04:06:09.053223 => 04:06:09.086273
[0m04:06:09.091675 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m04:06:09.093001 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:06:09.094365 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:06:09.095587 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:06:09.097877 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 04:06:09.097634 => 04:06:09.097644
[0m04:06:09.098977 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_dim_customer_customer_id.b42affccd1 (execute): 04:06:09.098744 => 04:06:09.098753
[0m04:06:09.100055 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 04:06:09.099847 => 04:06:09.099854
[0m04:06:09.101420 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:06:09.102744 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_dim_customer_customer_id.b42affccd1
[0m04:06:09.104175 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:06:09.104677 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 04:06:09.086993 => 04:06:09.104422
[0m04:06:09.105460 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:06:09.106424 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:06:09.107768 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:06:09.108929 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m04:06:09.110073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.unique_dim_customer_customer_id.b42affccd1, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m04:06:09.111047 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 04:06:09.110812 => 04:06:09.110820
[0m04:06:09.111866 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:06:09.112661 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:06:09.114104 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:06:09.119400 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m04:06:09.124046 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m04:06:09.129969 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 04:06:09.120078 => 04:06:09.129606
[0m04:06:09.130536 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 04:06:09.114926 => 04:06:09.130244
[0m04:06:09.131267 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:06:09.132078 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:06:09.132906 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 04:06:09.132694 => 04:06:09.132703
[0m04:06:09.133743 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 04:06:09.133533 => 04:06:09.133541
[0m04:06:09.135168 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:06:09.136595 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:06:09.139144 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:06:09.140011 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m04:06:09.140642 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m04:06:09.141208 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m04:06:09.141750 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m04:06:09.144263 [debug] [MainThread]: Command end result
[0m04:06:09.185020 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m04:06:09.186066 [info ] [MainThread]: Building catalog
[0m04:06:09.189922 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m04:06:09.199549 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:06:09.201065 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m04:06:09.202411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:06:09.213234 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:06:09.215013 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:06:09.216802 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m04:06:09.222730 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:06:09.226682 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m04:06:09.228649 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m04:06:09.259387 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m04:06:09.261312 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.0608023, "process_user_time": 3.442178, "process_kernel_time": 0.179591, "process_mem_max_rss": "121080", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:06:09.262694 [debug] [MainThread]: Command `dbt docs generate` succeeded at 04:06:09.262512 after 1.06 seconds
[0m04:06:09.263587 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m04:06:09.264549 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m04:06:09.265534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1271ecb890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1271ecbf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1276a74f90>]}
[0m04:06:09.266393 [debug] [MainThread]: Flushing usage events
[0m04:16:33.494988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be32d8790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be33f6190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be32eb5d0>]}


============================== 04:16:33.528006 | 7e05c9dc-4da5-406b-af29-d8d90f62fa7e ==============================
[0m04:16:33.528006 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:16:33.532972 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:16:33.829262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7e05c9dc-4da5-406b-af29-d8d90f62fa7e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be3385bd0>]}
[0m04:16:33.834421 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:16:33.848829 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:16:33.852903 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.606481, "process_user_time": 13.314593, "process_kernel_time": 0.421094, "process_mem_max_rss": "105044", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:16:33.855521 [debug] [MainThread]: Command `dbt deps` succeeded at 04:16:33.855057 after 0.61 seconds
[0m04:16:33.857584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be32de8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be3ecf4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4be33b4990>]}
[0m04:16:33.859742 [debug] [MainThread]: Flushing usage events
[0m04:16:42.207380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb4f075d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb4f1b2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb4f192d0>]}


============================== 04:16:42.257941 | 8f497d57-90bf-4988-bbad-60ac735085ce ==============================
[0m04:16:42.257941 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:16:42.266131 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt snapshot', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:16:43.219572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8f497d57-90bf-4988-bbad-60ac735085ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb4f1a610>]}
[0m04:16:43.666968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8f497d57-90bf-4988-bbad-60ac735085ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb3fc59d0>]}
[0m04:16:43.679885 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:16:43.760282 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:16:44.475520 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m04:16:44.482664 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/schema.yml
[0m04:16:44.490862 [debug] [MainThread]: Partial parsing: updated file: sales_analytics://models/marts/dim_customer.sql
[0m04:16:46.236772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8f497d57-90bf-4988-bbad-60ac735085ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb37a3dd0>]}
[0m04:16:46.311866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f497d57-90bf-4988-bbad-60ac735085ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb3bd0710>]}
[0m04:16:46.314571 [info ] [MainThread]: Found 4 models, 10 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:16:46.319618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f497d57-90bf-4988-bbad-60ac735085ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb3bf7790>]}
[0m04:16:46.339784 [info ] [MainThread]: 
[0m04:16:46.351523 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:16:46.357415 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m04:16:46.413939 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m04:16:46.418684 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m04:16:46.428637 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:16:46.475631 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m04:16:46.482689 [debug] [ThreadPool]: On list_warehouse: Close
[0m04:16:46.493923 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m04:16:46.505554 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m04:16:46.531673 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:16:46.533809 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m04:16:46.538518 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:16:46.557189 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:16:46.561459 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:16:46.567920 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m04:16:46.571344 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m04:16:46.576195 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m04:16:46.579556 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:16:46.581720 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m04:16:46.648106 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m04:16:46.653770 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m04:16:46.662087 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_analytics_intermediate)
[0m04:16:46.665256 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:16:46.668238 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:16:46.694265 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:16:46.906992 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:16:46.893848 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:16:46.897871 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:16:46.875209 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:16:46.910347 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:16:46.919318 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:16:46.930695 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:16:46.924942 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:16:46.928095 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:16:46.922367 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:16:46.936156 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:16:46.940164 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:16:46.949977 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:16:46.952023 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:16:46.954260 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:16:46.956589 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:16:46.960270 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:16:46.962682 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:16:46.966643 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:16:46.978689 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:16:46.967865 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:16:46.987511 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:16:46.973038 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:16:46.999086 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:16:46.979821 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:16:46.993013 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:16:46.982270 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:16:47.001959 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:16:47.007978 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:16:47.024509 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:16:47.026623 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:16:47.048173 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:16:47.049985 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:16:47.060957 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:16:47.067083 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:16:47.097703 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:16:47.131219 [debug] [MainThread]: Using postgres connection "master"
[0m04:16:47.138543 [debug] [MainThread]: On master: BEGIN
[0m04:16:47.142058 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:16:47.175040 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:16:47.190719 [debug] [MainThread]: Using postgres connection "master"
[0m04:16:47.202247 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:16:47.232933 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:16:47.245807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f497d57-90bf-4988-bbad-60ac735085ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb4f0f8d0>]}
[0m04:16:47.256163 [debug] [MainThread]: On master: ROLLBACK
[0m04:16:47.263669 [debug] [MainThread]: Using postgres connection "master"
[0m04:16:47.270654 [debug] [MainThread]: On master: BEGIN
[0m04:16:47.286223 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:16:47.292913 [debug] [MainThread]: On master: COMMIT
[0m04:16:47.301539 [debug] [MainThread]: Using postgres connection "master"
[0m04:16:47.309601 [debug] [MainThread]: On master: COMMIT
[0m04:16:47.317372 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:16:47.322478 [debug] [MainThread]: On master: Close
[0m04:16:47.326281 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:16:47.331644 [info ] [MainThread]: 
[0m04:16:47.370897 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:16:47.375511 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m04:16:47.380082 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m04:16:47.383316 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:16:47.426771 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:16:47.387363 => 04:16:47.425837
[0m04:16:47.433449 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:16:47.725640 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m04:16:47.792767 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:16:47.798076 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m04:16:47.801222 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:16:47.829248 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m04:16:47.831888 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:16:47.836688 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m04:16:47.846770 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m04:16:47.853860 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m04:16:47.860616 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:16:47.438594 => 04:16:47.859703
[0m04:16:47.864704 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m04:16:47.882253 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:16:47.889579 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f497d57-90bf-4988-bbad-60ac735085ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb3ff2090>]}
[0m04:16:47.894697 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.51s]
[0m04:16:47.898802 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:16:47.929050 [debug] [MainThread]: Using postgres connection "master"
[0m04:16:47.931549 [debug] [MainThread]: On master: BEGIN
[0m04:16:47.935382 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:16:47.976672 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:16:47.982375 [debug] [MainThread]: On master: COMMIT
[0m04:16:47.987046 [debug] [MainThread]: Using postgres connection "master"
[0m04:16:47.989228 [debug] [MainThread]: On master: COMMIT
[0m04:16:47.995804 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:16:48.001929 [debug] [MainThread]: On master: Close
[0m04:16:48.007430 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:16:48.012288 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m04:16:48.017103 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m04:16:48.020086 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m04:16:48.022908 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m04:16:48.026619 [info ] [MainThread]: 
[0m04:16:48.029119 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 1.68 seconds (1.68s).
[0m04:16:48.033542 [debug] [MainThread]: Command end result
[0m04:16:48.144627 [info ] [MainThread]: 
[0m04:16:48.147794 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:16:48.150324 [info ] [MainThread]: 
[0m04:16:48.152657 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:16:48.156181 [info ] [MainThread]: 
[0m04:16:48.162456 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m04:16:48.177029 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 6.2606373, "process_user_time": 11.734012, "process_kernel_time": 0.566332, "process_mem_max_rss": "128280", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:16:48.185909 [debug] [MainThread]: Command `dbt snapshot` failed at 04:16:48.185370 after 6.27 seconds
[0m04:16:48.189651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb4f1af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb5b13510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eb62ee850>]}
[0m04:16:48.199532 [debug] [MainThread]: Flushing usage events
[0m04:17:17.416964 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80be9a850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80c35fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80d701b50>]}


============================== 04:17:17.441372 | a43b3dc8-7796-4865-a5ca-4d4ca4e999c1 ==============================
[0m04:17:17.441372 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:17:17.444536 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'profiles_dir': '/usr/app', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:17:17.858785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a43b3dc8-7796-4865-a5ca-4d4ca4e999c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80b513650>]}
[0m04:17:18.028004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a43b3dc8-7796-4865-a5ca-4d4ca4e999c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80b8ee4d0>]}
[0m04:17:18.030849 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:17:18.062303 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:17:18.392340 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:17:18.395148 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:17:18.415465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a43b3dc8-7796-4865-a5ca-4d4ca4e999c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80b197390>]}
[0m04:17:18.439931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a43b3dc8-7796-4865-a5ca-4d4ca4e999c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80b1b7c10>]}
[0m04:17:18.442501 [info ] [MainThread]: Found 4 models, 10 tests, 1 snapshot, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:17:18.445227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a43b3dc8-7796-4865-a5ca-4d4ca4e999c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80b981bd0>]}
[0m04:17:18.453139 [info ] [MainThread]: 
[0m04:17:18.457428 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:17:18.469975 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:17:18.473806 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:17:18.477685 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:17:18.493283 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:17:18.531798 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:17:18.541367 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:17:18.548247 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:17:18.554910 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:17:18.557258 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:17:18.559302 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:17:18.561727 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:17:18.563508 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:17:18.565194 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:17:18.567295 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:17:18.569300 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:17:18.570937 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:17:18.592448 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:17:18.593784 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:17:18.596258 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:17:18.597280 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:17:18.598241 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:17:18.600610 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:17:18.602520 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:17:18.604504 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:17:18.606457 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:17:18.608428 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:17:18.610819 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:17:18.614728 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:17:18.621448 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:17:18.624606 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:17:18.628657 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:17:18.629840 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:17:18.630736 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:17:18.635252 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:17:18.637861 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:17:18.641388 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:17:18.646266 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:17:18.648816 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:17:18.653576 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:17:18.655810 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:17:18.675268 [debug] [MainThread]: Using postgres connection "master"
[0m04:17:18.677238 [debug] [MainThread]: On master: BEGIN
[0m04:17:18.679267 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:17:18.693359 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:17:18.695772 [debug] [MainThread]: Using postgres connection "master"
[0m04:17:18.697936 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:17:18.708464 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:17:18.713618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a43b3dc8-7796-4865-a5ca-4d4ca4e999c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80f471f10>]}
[0m04:17:18.716871 [debug] [MainThread]: On master: ROLLBACK
[0m04:17:18.719219 [debug] [MainThread]: On master: Close
[0m04:17:18.722398 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:17:18.725682 [info ] [MainThread]: 
[0m04:17:18.750236 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m04:17:18.753684 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m04:17:18.756504 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m04:17:18.777401 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m04:17:18.794163 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 04:17:18.759082 => 04:17:18.793375
[0m04:17:18.796166 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m04:17:18.798826 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 04:17:18.798016 => 04:17:18.798074
[0m04:17:18.802659 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m04:17:18.806424 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m04:17:18.807930 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:17:18.808999 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:17:18.810134 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:17:18.812534 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.orders_enriched)
[0m04:17:18.815632 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m04:17:18.818704 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m04:17:18.821365 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m04:17:18.823390 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m04:17:18.825381 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:17:18.827405 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:17:18.829360 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:17:18.838859 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m04:17:18.847369 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:17:18.840390 => 04:17:18.846848
[0m04:17:18.898966 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m04:17:18.900739 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m04:17:18.903607 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:17:18.909014 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:17:18.908227 => 04:17:18.908271
[0m04:17:18.912770 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:17:18.917606 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:17:18.920141 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 04:17:18.830894 => 04:17:18.919441
[0m04:17:18.921328 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 04:17:18.872756 => 04:17:18.920780
[0m04:17:18.922552 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 04:17:18.849154 => 04:17:18.921866
[0m04:17:18.925430 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m04:17:18.927385 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m04:17:18.929299 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:17:18.931272 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:17:18.933734 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:17:18.936313 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 04:17:18.935736 => 04:17:18.935768
[0m04:17:18.938666 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 04:17:18.938127 => 04:17:18.938152
[0m04:17:18.940748 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 04:17:18.940238 => 04:17:18.940263
[0m04:17:18.953469 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m04:17:18.957113 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m04:17:18.960803 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:17:18.964497 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:17:18.968114 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:17:18.970815 [debug] [Thread-1 (]: Began running node model.sales_analytics.dim_customer
[0m04:17:18.973528 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m04:17:18.977039 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m04:17:18.980837 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.dim_customer)
[0m04:17:18.985433 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.fct_daily_sales)
[0m04:17:18.987467 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 04:17:18.942225 => 04:17:18.986700
[0m04:17:18.989705 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:17:18.992298 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.dim_customer
[0m04:17:18.994404 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m04:17:18.996386 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:17:19.015591 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m04:17:19.027186 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m04:17:19.049691 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m04:17:19.051113 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 04:17:19.050346 => 04:17:19.050378
[0m04:17:19.059419 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:17:19.061948 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:17:19.065385 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m04:17:19.068590 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:17:19.070203 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (compile): 04:17:19.016524 => 04:17:19.069375
[0m04:17:19.074032 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 04:17:19.029053 => 04:17:19.072879
[0m04:17:19.081239 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 04:17:18.997947 => 04:17:19.080454
[0m04:17:19.091036 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m04:17:19.093573 [debug] [Thread-1 (]: Began executing node model.sales_analytics.dim_customer
[0m04:17:19.096033 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m04:17:19.097972 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:17:19.102921 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (execute): 04:17:19.102180 => 04:17:19.102215
[0m04:17:19.105769 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 04:17:19.105016 => 04:17:19.105049
[0m04:17:19.108419 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 04:17:19.107662 => 04:17:19.107686
[0m04:17:19.112746 [debug] [Thread-1 (]: Finished running node model.sales_analytics.dim_customer
[0m04:17:19.116913 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m04:17:19.121661 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:17:19.123123 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 04:17:19.075031 => 04:17:19.122411
[0m04:17:19.125920 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:17:19.128825 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:17:19.130288 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:17:19.132537 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:17:19.135941 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m04:17:19.139354 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m04:17:19.142370 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m04:17:19.144946 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 04:17:19.144206 => 04:17:19.144235
[0m04:17:19.147239 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:17:19.149562 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:17:19.151857 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:17:19.155726 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:17:19.168905 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m04:17:19.180425 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m04:17:19.191088 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m04:17:19.193024 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:17:19.200321 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m04:17:19.202581 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:17:19.217836 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m04:17:19.222086 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 04:17:19.157634 => 04:17:19.221330
[0m04:17:19.223594 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 04:17:19.181826 => 04:17:19.222751
[0m04:17:19.225049 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 04:17:19.170100 => 04:17:19.224442
[0m04:17:19.227284 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:17:19.229623 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:17:19.231826 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:17:19.234214 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 04:17:19.233707 => 04:17:19.233732
[0m04:17:19.236776 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 04:17:19.236133 => 04:17:19.236161
[0m04:17:19.239421 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 04:17:19.238597 => 04:17:19.238618
[0m04:17:19.241257 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 04:17:19.204322 => 04:17:19.240547
[0m04:17:19.244781 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:17:19.248435 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:17:19.251681 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:17:19.253562 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:17:19.255516 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:17:19.260234 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 04:17:19.259700 => 04:17:19.259719
[0m04:17:19.262929 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m04:17:19.266403 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:17:19.268970 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:17:19.289666 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m04:17:19.305792 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 04:17:19.272282 => 04:17:19.304568
[0m04:17:19.307634 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:17:19.309581 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 04:17:19.309088 => 04:17:19.309109
[0m04:17:19.312136 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:17:19.316925 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:17:19.318517 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m04:17:19.320494 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m04:17:19.321746 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m04:17:19.323142 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m04:17:19.328068 [debug] [MainThread]: Command end result
[0m04:17:19.416137 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m04:17:19.417952 [info ] [MainThread]: Building catalog
[0m04:17:19.428720 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m04:17:19.476924 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:17:19.479744 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m04:17:19.484250 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:17:19.503465 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:17:19.505756 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:17:19.508174 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m04:17:19.518863 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:17:19.527038 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m04:17:19.529862 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m04:17:19.596881 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m04:17:19.606836 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.4520848, "process_user_time": 16.776966, "process_kernel_time": 0.652604, "process_mem_max_rss": "121216", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:17:19.611817 [debug] [MainThread]: Command `dbt docs generate` succeeded at 04:17:19.611219 after 2.46 seconds
[0m04:17:19.616221 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m04:17:19.625899 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m04:17:19.628678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80bef7b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80c35fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80e267c50>]}
[0m04:17:19.631212 [debug] [MainThread]: Flushing usage events
[0m04:22:09.400732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4569fc4a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4569fc4c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4569fc7dd0>]}


============================== 04:22:09.407760 | 8ade77d4-843e-499c-8331-ba679f38ada9 ==============================
[0m04:22:09.407760 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:22:09.409126 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m04:22:09.508729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8ade77d4-843e-499c-8331-ba679f38ada9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4569ebb2d0>]}
[0m04:22:09.514626 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:22:09.523872 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:22:09.525449 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.19404158, "process_user_time": 3.270698, "process_kernel_time": 0.11036, "process_mem_max_rss": "104964", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:22:09.526580 [debug] [MainThread]: Command `dbt deps` succeeded at 04:22:09.526367 after 0.20 seconds
[0m04:22:09.527583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f456a00ec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f456eb57e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f456eb579d0>]}
[0m04:22:09.529486 [debug] [MainThread]: Flushing usage events
[0m04:22:13.178670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1926522450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1926522fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1926523d10>]}


============================== 04:22:13.186721 | 867e4f90-0827-4417-b92a-aea64247087c ==============================
[0m04:22:13.186721 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:22:13.187899 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m04:22:13.477488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1925513ed0>]}
[0m04:22:13.619946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1926921ad0>]}
[0m04:22:13.622776 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:22:13.650605 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:22:13.656012 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m04:22:13.657593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f192559f150>]}
[0m04:22:15.347392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1925151550>]}
[0m04:22:15.385249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19231b8290>]}
[0m04:22:15.386726 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:22:15.388045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19249fecd0>]}
[0m04:22:15.391875 [info ] [MainThread]: 
[0m04:22:15.394147 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:22:15.396493 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m04:22:15.409232 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m04:22:15.411115 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m04:22:15.412805 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:15.421528 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m04:22:15.425625 [debug] [ThreadPool]: On list_warehouse: Close
[0m04:22:15.428623 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m04:22:15.430878 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m04:22:15.438410 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:22:15.440178 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m04:22:15.442114 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:22:15.450227 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.452225 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:22:15.454029 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m04:22:15.456331 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m04:22:15.459435 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m04:22:15.460892 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m04:22:15.461977 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m04:22:15.467802 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m04:22:15.469074 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m04:22:15.473124 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_analytics_intermediate)
[0m04:22:15.474559 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:22:15.476119 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:22:15.483046 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:22:15.483875 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:22:15.487435 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:22:15.491878 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:22:15.495855 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:22:15.498051 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:22:15.499728 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:22:15.501617 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:22:15.503671 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:22:15.505597 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:22:15.507464 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:15.508764 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:15.510069 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:15.516954 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.517964 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:22:15.518684 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.519020 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.519694 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:22:15.520058 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.520774 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:22:15.521831 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:22:15.523609 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:22:15.525169 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:22:15.526190 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:22:15.526658 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:15.527345 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:22:15.530708 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:22:15.531139 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:15.531500 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:15.533117 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:22:15.534621 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:22:15.534991 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:15.536459 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:22:15.538539 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:22:15.540382 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:22:15.541912 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:22:15.543738 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:22:15.551144 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:15.552285 [debug] [MainThread]: On master: BEGIN
[0m04:22:15.553227 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:22:15.560059 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.561315 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:15.562450 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:22:15.567239 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:15.569483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1923115610>]}
[0m04:22:15.571224 [debug] [MainThread]: On master: ROLLBACK
[0m04:22:15.573389 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:15.575120 [debug] [MainThread]: On master: BEGIN
[0m04:22:15.576981 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.578105 [debug] [MainThread]: On master: COMMIT
[0m04:22:15.579046 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:15.580017 [debug] [MainThread]: On master: COMMIT
[0m04:22:15.581125 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:22:15.582043 [debug] [MainThread]: On master: Close
[0m04:22:15.583517 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:22:15.584554 [info ] [MainThread]: 
[0m04:22:15.594801 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:22:15.596250 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m04:22:15.597843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m04:22:15.598785 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:22:15.609167 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:22:15.599476 => 04:22:15.608784
[0m04:22:15.610751 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:22:15.679177 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m04:22:15.702567 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:22:15.703751 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m04:22:15.704754 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:22:15.712369 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.713499 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:22:15.714434 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m04:22:15.715729 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m04:22:15.716574 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m04:22:15.717761 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:22:15.611877 => 04:22:15.717487
[0m04:22:15.718649 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m04:22:15.723299 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:22:15.724727 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '867e4f90-0827-4417-b92a-aea64247087c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1924548310>]}
[0m04:22:15.726273 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.13s]
[0m04:22:15.728366 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:22:15.732393 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:15.733560 [debug] [MainThread]: On master: BEGIN
[0m04:22:15.734623 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:22:15.742251 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:22:15.743383 [debug] [MainThread]: On master: COMMIT
[0m04:22:15.744279 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:15.745121 [debug] [MainThread]: On master: COMMIT
[0m04:22:15.746219 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:22:15.747254 [debug] [MainThread]: On master: Close
[0m04:22:15.749051 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:22:15.750203 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m04:22:15.751305 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m04:22:15.752394 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m04:22:15.753115 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m04:22:15.754188 [info ] [MainThread]: 
[0m04:22:15.755284 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.36 seconds (0.36s).
[0m04:22:15.757311 [debug] [MainThread]: Command end result
[0m04:22:15.785900 [info ] [MainThread]: 
[0m04:22:15.787784 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:22:15.789660 [info ] [MainThread]: 
[0m04:22:15.792945 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:22:15.796651 [info ] [MainThread]: 
[0m04:22:15.798756 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m04:22:15.801472 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 2.692465, "process_user_time": 5.212347, "process_kernel_time": 0.171392, "process_mem_max_rss": "131208", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:22:15.803570 [debug] [MainThread]: Command `dbt snapshot` failed at 04:22:15.803249 after 2.69 seconds
[0m04:22:15.805466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19265213d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1923125410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f19265164d0>]}
[0m04:22:15.807442 [debug] [MainThread]: Flushing usage events
[0m04:22:21.720891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca4dda810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca4dd9790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca4dd8cd0>]}


============================== 04:22:21.728455 | 5a00e4fc-28fd-4e60-b791-6f35f35f0a24 ==============================
[0m04:22:21.728455 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:22:21.729719 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'profiles_dir': '/usr/app', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:22:21.958788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5a00e4fc-28fd-4e60-b791-6f35f35f0a24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca455a0d0>]}
[0m04:22:22.071127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5a00e4fc-28fd-4e60-b791-6f35f35f0a24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca4598b10>]}
[0m04:22:22.073557 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:22:22.094532 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:22:22.211853 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:22:22.212768 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:22:22.220445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a00e4fc-28fd-4e60-b791-6f35f35f0a24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca3de7090>]}
[0m04:22:22.230194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a00e4fc-28fd-4e60-b791-6f35f35f0a24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca3db7410>]}
[0m04:22:22.231542 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:22:22.232981 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a00e4fc-28fd-4e60-b791-6f35f35f0a24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca521d250>]}
[0m04:22:22.237324 [info ] [MainThread]: 
[0m04:22:22.239827 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:22:22.245449 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:22:22.247211 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:22:22.248793 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:22:22.256267 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:22:22.269942 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:22:22.275383 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:22:22.280180 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:22:22.284564 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:22:22.286579 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:22:22.288592 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:22:22.290837 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:22:22.292213 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:22:22.293520 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:22.294711 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:22.295868 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:22.296899 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:22.308632 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:22.309857 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:22.310448 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:22.311635 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:22:22.312270 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:22.313815 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:22:22.315489 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:22:22.317339 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:22:22.319128 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:22:22.320740 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:22:22.322702 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:22:22.325758 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:22:22.328613 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:22.331525 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:22.334941 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:22:22.335824 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:22.336447 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:22.339570 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:22:22.342214 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:22:22.345356 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:22:22.349105 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:22:22.351714 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:22:22.355639 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:22:22.357651 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:22:22.371665 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:22.373156 [debug] [MainThread]: On master: BEGIN
[0m04:22:22.374679 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:22:22.383811 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:22:22.385359 [debug] [MainThread]: Using postgres connection "master"
[0m04:22:22.387559 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:22:22.392544 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:22.395399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a00e4fc-28fd-4e60-b791-6f35f35f0a24', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca4dc2990>]}
[0m04:22:22.397071 [debug] [MainThread]: On master: ROLLBACK
[0m04:22:22.398822 [debug] [MainThread]: On master: Close
[0m04:22:22.400549 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:22:22.401744 [info ] [MainThread]: 
[0m04:22:22.412450 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m04:22:22.414051 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m04:22:22.415000 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m04:22:22.424647 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m04:22:22.441500 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 04:22:22.415800 => 04:22:22.441086
[0m04:22:22.442453 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m04:22:22.443361 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 04:22:22.443092 => 04:22:22.443112
[0m04:22:22.444958 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m04:22:22.446799 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m04:22:22.447636 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:22:22.448210 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:22:22.448805 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:22:22.450002 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m04:22:22.451535 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m04:22:22.452886 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m04:22:22.454654 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m04:22:22.455865 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m04:22:22.456751 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:22:22.457624 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:22:22.458598 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:22:22.462885 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m04:22:22.467157 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:22:22.463584 => 04:22:22.466889
[0m04:22:22.483483 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m04:22:22.489509 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m04:22:22.492874 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:22:22.496634 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:22:22.496202 => 04:22:22.496221
[0m04:22:22.498782 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:22:22.499928 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:22:22.501331 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 04:22:22.459444 => 04:22:22.501024
[0m04:22:22.502368 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m04:22:22.502919 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 04:22:22.468314 => 04:22:22.502674
[0m04:22:22.504390 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m04:22:22.505318 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:22:22.505894 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 04:22:22.484645 => 04:22:22.505640
[0m04:22:22.506606 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:22:22.507547 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 04:22:22.507306 => 04:22:22.507320
[0m04:22:22.513044 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m04:22:22.514495 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:22:22.515628 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 04:22:22.515370 => 04:22:22.515383
[0m04:22:22.517908 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m04:22:22.520592 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 04:22:22.520336 => 04:22:22.520346
[0m04:22:22.522546 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:22:22.523973 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:22:22.526200 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:22:22.527730 [debug] [Thread-2 (]: Began running node model.sales_analytics.dim_customer
[0m04:22:22.529393 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m04:22:22.530918 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m04:22:22.532339 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.dim_customer)
[0m04:22:22.533023 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 04:22:22.508151 => 04:22:22.532728
[0m04:22:22.533775 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:22:22.534953 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m04:22:22.535815 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.dim_customer
[0m04:22:22.536591 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:22:22.544027 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m04:22:22.545174 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m04:22:22.549931 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m04:22:22.551495 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 04:22:22.551253 => 04:22:22.551267
[0m04:22:22.562454 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m04:22:22.564467 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 04:22:22.537296 => 04:22:22.564180
[0m04:22:22.565788 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:22:22.568064 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:22:22.569633 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:22:22.571403 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 04:22:22.571002 => 04:22:22.571019
[0m04:22:22.572215 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (compile): 04:22:22.546289 => 04:22:22.571917
[0m04:22:22.574023 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m04:22:22.575962 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:22:22.576534 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 04:22:22.553687 => 04:22:22.576269
[0m04:22:22.577520 [debug] [Thread-2 (]: Began executing node model.sales_analytics.dim_customer
[0m04:22:22.578774 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:22:22.581251 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m04:22:22.582689 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (execute): 04:22:22.582422 => 04:22:22.582435
[0m04:22:22.589345 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m04:22:22.590344 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 04:22:22.590024 => 04:22:22.590035
[0m04:22:22.591948 [debug] [Thread-2 (]: Finished running node model.sales_analytics.dim_customer
[0m04:22:22.594332 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m04:22:22.595923 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:22:22.597220 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:22:22.597665 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:22:22.598943 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m04:22:22.600685 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m04:22:22.602375 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m04:22:22.603734 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:22:22.604877 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:22:22.605890 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:22:22.612367 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 04:22:22.583714 => 04:22:22.612040
[0m04:22:22.613536 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m04:22:22.620052 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m04:22:22.625887 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m04:22:22.628295 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:22:22.633629 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 04:22:22.633355 => 04:22:22.633369
[0m04:22:22.635478 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:22:22.636761 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:22:22.638280 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m04:22:22.639344 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:22:22.645039 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m04:22:22.647246 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 04:22:22.620922 => 04:22:22.646809
[0m04:22:22.648076 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 04:22:22.614459 => 04:22:22.647598
[0m04:22:22.649233 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:22:22.649976 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 04:22:22.606792 => 04:22:22.649645
[0m04:22:22.650941 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:22:22.651655 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 04:22:22.640063 => 04:22:22.651378
[0m04:22:22.652817 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 04:22:22.652550 => 04:22:22.652565
[0m04:22:22.654127 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:22:22.655633 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 04:22:22.655197 => 04:22:22.655215
[0m04:22:22.657153 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:22:22.659298 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:22:22.660964 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 04:22:22.660615 => 04:22:22.660632
[0m04:22:22.663219 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:22:22.665015 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 04:22:22.664718 => 04:22:22.664732
[0m04:22:22.666628 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:22:22.669009 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:22:22.672275 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:22:22.674404 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m04:22:22.678886 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:22:22.688898 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m04:22:22.706220 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 04:22:22.680277 => 04:22:22.705897
[0m04:22:22.707058 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:22:22.707881 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 04:22:22.707653 => 04:22:22.707664
[0m04:22:22.709235 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:22:22.711415 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:22:22.712386 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m04:22:22.713295 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m04:22:22.714176 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m04:22:22.715050 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m04:22:22.717943 [debug] [MainThread]: Command end result
[0m04:22:22.762861 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m04:22:22.764161 [info ] [MainThread]: Building catalog
[0m04:22:22.769379 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m04:22:22.784005 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:22:22.785667 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m04:22:22.787284 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:22:22.797381 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:22:22.799183 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:22:22.800770 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m04:22:22.807463 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:22:22.811418 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m04:22:22.813035 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m04:22:22.843702 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m04:22:22.846610 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.1850041, "process_user_time": 3.894473, "process_kernel_time": 0.160184, "process_mem_max_rss": "121692", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:22:22.848275 [debug] [MainThread]: Command `dbt docs generate` succeeded at 04:22:22.848028 after 1.19 seconds
[0m04:22:22.849815 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m04:22:22.851155 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m04:22:22.852743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca987d090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca3904a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ca99c0f90>]}
[0m04:22:22.854273 [debug] [MainThread]: Flushing usage events
[0m04:28:42.773038 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a8c15e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a8c16b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a8c16510>]}


============================== 04:28:42.791534 | cf713a15-6965-4039-b0d9-30f462b50f4f ==============================
[0m04:28:42.791534 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:28:42.794195 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:28:43.023217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cf713a15-6965-4039-b0d9-30f462b50f4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a93ec590>]}
[0m04:28:43.033783 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:28:43.055451 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m04:28:43.058939 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.43591848, "process_user_time": 6.058341, "process_kernel_time": 0.249931, "process_mem_max_rss": "104560", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:28:43.061467 [debug] [MainThread]: Command `dbt deps` succeeded at 04:28:43.061094 after 0.44 seconds
[0m04:28:43.063886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a8c6ef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a8c6e8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53aa1c61d0>]}
[0m04:28:43.073452 [debug] [MainThread]: Flushing usage events
[0m04:28:48.834161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b2632f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b2adfe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b261ba10>]}


============================== 04:28:48.846543 | 060d01ec-81cc-43c9-8556-3df27e53300b ==============================
[0m04:28:48.846543 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:28:48.848732 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt snapshot', 'send_anonymous_usage_stats': 'True'}
[0m04:28:49.199735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '060d01ec-81cc-43c9-8556-3df27e53300b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b1dde550>]}
[0m04:28:49.364174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '060d01ec-81cc-43c9-8556-3df27e53300b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b1d903d0>]}
[0m04:28:49.368262 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:28:49.406493 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:28:49.740378 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:28:49.743591 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:28:49.757568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '060d01ec-81cc-43c9-8556-3df27e53300b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b15d4650>]}
[0m04:28:49.841455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '060d01ec-81cc-43c9-8556-3df27e53300b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b1946b50>]}
[0m04:28:49.844120 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:28:49.846779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '060d01ec-81cc-43c9-8556-3df27e53300b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b2a75690>]}
[0m04:28:49.852839 [info ] [MainThread]: 
[0m04:28:49.856692 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:28:49.863850 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m04:28:49.890197 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m04:28:49.893260 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m04:28:49.894747 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:49.907710 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m04:28:49.911441 [debug] [ThreadPool]: On list_warehouse: Close
[0m04:28:49.916508 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_staging)
[0m04:28:49.918405 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:28:49.920237 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:28:49.922463 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:28:49.935611 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:28:49.939974 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:28:49.945325 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:28:49.951086 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:28:49.952937 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:28:49.955711 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:28:49.957434 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:28:49.959387 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:28:49.961456 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:28:49.962715 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:49.964796 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:49.967147 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:49.979637 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:49.980346 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:49.982087 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:49.982760 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:28:49.984353 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:49.985958 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:28:49.988660 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:28:49.991719 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:28:49.995339 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:28:49.998837 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:28:50.003064 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:28:50.007421 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:28:50.009812 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:50.014639 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:50.019740 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:28:50.020636 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:50.021394 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:50.025010 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:28:50.027961 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:28:50.032100 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:28:50.036901 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:28:50.039937 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:28:50.044772 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:28:50.047066 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:28:50.080836 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:50.083221 [debug] [MainThread]: On master: BEGIN
[0m04:28:50.085995 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:28:50.099037 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:28:50.101105 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:50.103549 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:28:50.112458 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:50.117593 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '060d01ec-81cc-43c9-8556-3df27e53300b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b1968f10>]}
[0m04:28:50.119810 [debug] [MainThread]: On master: ROLLBACK
[0m04:28:50.122352 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:50.124602 [debug] [MainThread]: On master: BEGIN
[0m04:28:50.127321 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:28:50.128836 [debug] [MainThread]: On master: COMMIT
[0m04:28:50.130880 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:50.133344 [debug] [MainThread]: On master: COMMIT
[0m04:28:50.136215 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:28:50.138790 [debug] [MainThread]: On master: Close
[0m04:28:50.142217 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:28:50.144529 [info ] [MainThread]: 
[0m04:28:50.161477 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:28:50.163958 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m04:28:50.168399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m04:28:50.171677 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:28:50.193499 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:28:50.173883 => 04:28:50.192785
[0m04:28:50.198788 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:28:50.332068 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m04:28:50.358830 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:28:50.361974 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m04:28:50.365728 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:28:50.381512 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m04:28:50.385335 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m04:28:50.388586 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m04:28:50.393738 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m04:28:50.395426 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m04:28:50.397388 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:28:50.202217 => 04:28:50.397103
[0m04:28:50.399215 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m04:28:50.404808 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:28:50.406901 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '060d01ec-81cc-43c9-8556-3df27e53300b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b11b8590>]}
[0m04:28:50.409183 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.24s]
[0m04:28:50.410720 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:28:50.414936 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:50.415980 [debug] [MainThread]: On master: BEGIN
[0m04:28:50.417138 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:28:50.424815 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:28:50.426018 [debug] [MainThread]: On master: COMMIT
[0m04:28:50.426948 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:50.427742 [debug] [MainThread]: On master: COMMIT
[0m04:28:50.428766 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m04:28:50.429656 [debug] [MainThread]: On master: Close
[0m04:28:50.431190 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:28:50.432329 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m04:28:50.433433 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m04:28:50.435530 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m04:28:50.437992 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m04:28:50.439323 [info ] [MainThread]: 
[0m04:28:50.440456 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m04:28:50.442166 [debug] [MainThread]: Command end result
[0m04:28:50.510918 [info ] [MainThread]: 
[0m04:28:50.514260 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m04:28:50.518679 [info ] [MainThread]: 
[0m04:28:50.521578 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m04:28:50.524613 [info ] [MainThread]: 
[0m04:28:50.527723 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m04:28:50.531998 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 1.8165622, "process_user_time": 5.750785, "process_kernel_time": 0.211871, "process_mem_max_rss": "121668", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:28:50.535522 [debug] [MainThread]: Command `dbt snapshot` failed at 04:28:50.535109 after 1.82 seconds
[0m04:28:50.538103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b261a7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b3e05b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd2b71af9d0>]}
[0m04:28:50.541758 [debug] [MainThread]: Flushing usage events
[0m04:28:57.571262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2b00b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2ace3110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2ace2cd0>]}


============================== 04:28:57.586357 | 232c49b1-0b67-49b3-9aca-bf6e1d15ed08 ==============================
[0m04:28:57.586357 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:28:57.589119 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'profiles_dir': '/usr/app', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m04:28:57.989188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '232c49b1-0b67-49b3-9aca-bf6e1d15ed08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d29fc59d0>]}
[0m04:28:58.158816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '232c49b1-0b67-49b3-9aca-bf6e1d15ed08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d29f4ce50>]}
[0m04:28:58.161691 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:28:58.195212 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m04:28:58.530605 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:28:58.533632 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:28:58.547771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '232c49b1-0b67-49b3-9aca-bf6e1d15ed08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d29b31c90>]}
[0m04:28:58.581332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '232c49b1-0b67-49b3-9aca-bf6e1d15ed08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2975b650>]}
[0m04:28:58.584641 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m04:28:58.587221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '232c49b1-0b67-49b3-9aca-bf6e1d15ed08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2e10df50>]}
[0m04:28:58.592525 [info ] [MainThread]: 
[0m04:28:58.596297 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:28:58.600966 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m04:28:58.603958 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m04:28:58.606703 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m04:28:58.608957 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m04:28:58.630962 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:28:58.635459 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:28:58.641747 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:28:58.648067 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:28:58.650795 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m04:28:58.653875 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m04:28:58.656662 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m04:28:58.659286 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m04:28:58.662224 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:58.664570 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:58.667710 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:58.671143 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:58.685904 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:58.687498 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:58.688152 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:58.689603 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m04:28:58.690256 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:58.692948 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m04:28:58.696288 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m04:28:58.699175 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m04:28:58.702568 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m04:28:58.705865 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m04:28:58.708759 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m04:28:58.714201 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m04:28:58.716652 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:58.722107 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:58.724570 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m04:28:58.725443 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:58.726213 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:58.729186 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m04:28:58.733146 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m04:28:58.737140 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m04:28:58.741189 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m04:28:58.744084 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m04:28:58.749532 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m04:28:58.751929 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m04:28:58.766951 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:58.769856 [debug] [MainThread]: On master: BEGIN
[0m04:28:58.772917 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:28:58.784996 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m04:28:58.787178 [debug] [MainThread]: Using postgres connection "master"
[0m04:28:58.788716 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:28:58.795261 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:58.799947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '232c49b1-0b67-49b3-9aca-bf6e1d15ed08', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2e10df50>]}
[0m04:28:58.803268 [debug] [MainThread]: On master: ROLLBACK
[0m04:28:58.806111 [debug] [MainThread]: On master: Close
[0m04:28:58.809689 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:28:58.811679 [info ] [MainThread]: 
[0m04:28:58.829921 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m04:28:58.833518 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m04:28:58.836887 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m04:28:58.854361 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m04:28:58.885150 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 04:28:58.839629 => 04:28:58.884576
[0m04:28:58.887980 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m04:28:58.891242 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 04:28:58.890800 => 04:28:58.890829
[0m04:28:58.895952 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m04:28:58.900831 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m04:28:58.902100 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m04:28:58.902981 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:28:58.903991 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:28:58.906460 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m04:28:58.909949 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m04:28:58.914333 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m04:28:58.918678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m04:28:58.922337 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m04:28:58.926335 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m04:28:58.929076 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:28:58.933101 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:28:58.941746 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m04:28:58.950806 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 04:28:58.944443 => 04:28:58.950355
[0m04:28:58.983901 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m04:28:58.987270 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m04:28:58.992232 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m04:28:59.000418 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 04:28:58.999904 => 04:28:58.999928
[0m04:28:59.004009 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m04:28:59.007426 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:28:59.008968 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 04:28:58.978065 => 04:28:59.008457
[0m04:28:59.009802 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 04:28:58.953005 => 04:28:59.009394
[0m04:28:59.010719 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 04:28:58.935800 => 04:28:59.010284
[0m04:28:59.013222 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m04:28:59.016845 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:28:59.019839 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:28:59.022956 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m04:28:59.026604 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:28:59.030314 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 04:28:59.029866 => 04:28:59.029890
[0m04:28:59.033928 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 04:28:59.033502 => 04:28:59.033524
[0m04:28:59.037361 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 04:28:59.036943 => 04:28:59.036962
[0m04:28:59.048936 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m04:28:59.052711 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m04:28:59.057419 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m04:28:59.061254 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m04:28:59.067839 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:28:59.070759 [debug] [Thread-2 (]: Began running node model.sales_analytics.dim_customer
[0m04:28:59.074032 [debug] [Thread-3 (]: Began running node model.sales_analytics.fct_daily_sales
[0m04:28:59.076144 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m04:28:59.078793 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.dim_customer)
[0m04:28:59.081638 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.fct_daily_sales)
[0m04:28:59.083770 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:28:59.086397 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.dim_customer
[0m04:28:59.089096 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m04:28:59.091528 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 04:28:59.040472 => 04:28:59.090992
[0m04:28:59.102712 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m04:28:59.111605 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m04:28:59.127958 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m04:28:59.129570 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:28:59.137433 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 04:28:59.136961 => 04:28:59.136983
[0m04:28:59.140472 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m04:28:59.142955 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:28:59.145980 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m04:28:59.147189 [debug] [Thread-3 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 04:28:59.113699 => 04:28:59.146547
[0m04:28:59.148265 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (compile): 04:28:59.105121 => 04:28:59.147801
[0m04:28:59.151027 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:28:59.153398 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 04:28:59.092093 => 04:28:59.152786
[0m04:28:59.154396 [debug] [Thread-3 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m04:28:59.157932 [debug] [Thread-2 (]: Began executing node model.sales_analytics.dim_customer
[0m04:28:59.169378 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m04:28:59.171841 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:28:59.175449 [debug] [Thread-3 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 04:28:59.175025 => 04:28:59.175043
[0m04:28:59.178239 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (execute): 04:28:59.177824 => 04:28:59.177842
[0m04:28:59.183667 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 04:28:59.182948 => 04:28:59.182969
[0m04:28:59.187590 [debug] [Thread-3 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m04:28:59.190979 [debug] [Thread-2 (]: Finished running node model.sales_analytics.dim_customer
[0m04:28:59.195261 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m04:28:59.199317 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:28:59.200886 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:28:59.203514 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:28:59.207603 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m04:28:59.209777 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 04:28:59.161065 => 04:28:59.209356
[0m04:28:59.211851 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m04:28:59.216234 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m04:28:59.219000 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:28:59.221730 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:28:59.225926 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:28:59.228943 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:28:59.240418 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m04:28:59.242732 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 04:28:59.242303 => 04:28:59.242320
[0m04:28:59.253730 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m04:28:59.263021 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m04:28:59.269930 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m04:28:59.278028 [debug] [Thread-4 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:28:59.281418 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m04:28:59.284494 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:28:59.285595 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 04:28:59.255746 => 04:28:59.285029
[0m04:28:59.286748 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 04:28:59.232110 => 04:28:59.286332
[0m04:28:59.299941 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 04:28:59.246218 => 04:28:59.299493
[0m04:28:59.301457 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m04:28:59.304263 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:28:59.306755 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:28:59.309298 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:28:59.315310 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 04:28:59.314898 => 04:28:59.314916
[0m04:28:59.317936 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 04:28:59.317538 => 04:28:59.317554
[0m04:28:59.320569 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 04:28:59.320177 => 04:28:59.320190
[0m04:28:59.324106 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m04:28:59.327661 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m04:28:59.330965 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m04:28:59.333529 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:28:59.339549 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m04:28:59.341102 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 04:28:59.288440 => 04:28:59.340225
[0m04:28:59.343502 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:28:59.346437 [debug] [Thread-4 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:28:59.358040 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m04:28:59.360967 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 04:28:59.360434 => 04:28:59.360456
[0m04:28:59.367469 [debug] [Thread-4 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m04:28:59.396032 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 04:28:59.349815 => 04:28:59.395515
[0m04:28:59.398605 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:28:59.401922 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 04:28:59.401538 => 04:28:59.401553
[0m04:28:59.406090 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m04:28:59.411585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:28:59.414330 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m04:28:59.417224 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m04:28:59.419632 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m04:28:59.422490 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m04:28:59.428631 [debug] [MainThread]: Command end result
[0m04:28:59.533816 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m04:28:59.535803 [info ] [MainThread]: Building catalog
[0m04:28:59.541870 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m04:28:59.561022 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:28:59.563357 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m04:28:59.565667 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:28:59.580452 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m04:28:59.582881 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m04:28:59.585498 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m04:28:59.595725 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m04:28:59.600646 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m04:28:59.603621 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m04:28:59.658557 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m04:28:59.661839 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.221729, "process_user_time": 5.22658, "process_kernel_time": 0.266763, "process_mem_max_rss": "120932", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:28:59.663961 [debug] [MainThread]: Command `dbt docs generate` succeeded at 04:28:59.663695 after 2.22 seconds
[0m04:28:59.665922 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m04:28:59.668126 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m04:28:59.670166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2ab43110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2ab43510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d2b00b6d0>]}
[0m04:28:59.672867 [debug] [MainThread]: Flushing usage events
[0m04:32:07.565424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe702ca8890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe702ca98d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe702c99110>]}


============================== 04:32:07.578382 | ee6b78f2-e59a-4341-a259-9c032cfc0d24 ==============================
[0m04:32:07.578382 [info ] [MainThread]: Running with dbt=1.7.11
[0m04:32:07.581330 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt debug -t dev', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:32:07.584438 [info ] [MainThread]: dbt version: 1.7.11
[0m04:32:07.585901 [info ] [MainThread]: python version: 3.11.13
[0m04:32:07.587582 [info ] [MainThread]: python path: /usr/local/bin/python3.11
[0m04:32:07.589165 [info ] [MainThread]: os info: Linux-5.15.146.1-microsoft-standard-WSL2-x86_64-with-glibc2.41
[0m04:32:07.724338 [info ] [MainThread]: Using profiles dir at /usr/app
[0m04:32:07.725573 [info ] [MainThread]: Using profiles.yml file at /usr/app/profiles.yml
[0m04:32:07.726949 [info ] [MainThread]: Using dbt_project.yml file at /usr/app/dbt_project.yml
[0m04:32:07.728373 [info ] [MainThread]: adapter type: postgres
[0m04:32:07.729565 [info ] [MainThread]: adapter version: 1.7.11
[0m04:32:07.830940 [info ] [MainThread]: Configuration:
[0m04:32:07.832876 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m04:32:07.834313 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m04:32:07.835808 [info ] [MainThread]: Required dependencies:
[0m04:32:07.837164 [debug] [MainThread]: Executing "git --help"
[0m04:32:07.841410 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m04:32:07.842685 [debug] [MainThread]: STDERR: "b''"
[0m04:32:07.843973 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m04:32:07.845329 [info ] [MainThread]: Connection:
[0m04:32:07.846601 [info ] [MainThread]:   host: postgres
[0m04:32:07.847804 [info ] [MainThread]:   port: 5432
[0m04:32:07.849356 [info ] [MainThread]:   user: analytics
[0m04:32:07.851490 [info ] [MainThread]:   database: warehouse
[0m04:32:07.853810 [info ] [MainThread]:   schema: analytics
[0m04:32:07.855027 [info ] [MainThread]:   connect_timeout: 10
[0m04:32:07.856444 [info ] [MainThread]:   role: None
[0m04:32:07.857724 [info ] [MainThread]:   search_path: None
[0m04:32:07.859058 [info ] [MainThread]:   keepalives_idle: 0
[0m04:32:07.860647 [info ] [MainThread]:   sslmode: None
[0m04:32:07.862905 [info ] [MainThread]:   sslcert: None
[0m04:32:07.864997 [info ] [MainThread]:   sslkey: None
[0m04:32:07.866604 [info ] [MainThread]:   sslrootcert: None
[0m04:32:07.868280 [info ] [MainThread]:   application_name: dbt
[0m04:32:07.869829 [info ] [MainThread]:   retries: 1
[0m04:32:07.871589 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m04:32:07.873531 [debug] [MainThread]: Acquiring new postgres connection 'debug'
[0m04:32:07.875202 [debug] [MainThread]: Using postgres connection "debug"
[0m04:32:07.877210 [debug] [MainThread]: On debug: select 1 as id
[0m04:32:07.878924 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:32:07.890429 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m04:32:07.892763 [debug] [MainThread]: On debug: Close
[0m04:32:07.893948 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m04:32:07.896592 [info ] [MainThread]: [32mAll checks passed![0m
[0m04:32:07.899837 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.42345405, "process_user_time": 3.08309, "process_kernel_time": 0.149181, "process_mem_max_rss": "111612", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m04:32:07.901435 [debug] [MainThread]: Command `dbt debug` succeeded at 04:32:07.901264 after 0.43 seconds
[0m04:32:07.902631 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m04:32:07.903786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7026dfdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70782b810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70388af50>]}
[0m04:32:07.904793 [debug] [MainThread]: Flushing usage events
[0m05:14:54.817422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbda57b4c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbda57a90d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbda57a9f90>]}


============================== 05:14:54.825075 | e8438b76-9212-44c3-ac4b-07df9dd6da4f ==============================
[0m05:14:54.825075 [info ] [MainThread]: Running with dbt=1.7.11
[0m05:14:54.826369 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt deps', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m05:14:54.932005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e8438b76-9212-44c3-ac4b-07df9dd6da4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbda585fe50>]}
[0m05:14:54.938390 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m05:14:54.951570 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m05:14:54.954110 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.19988935, "process_user_time": 2.80779, "process_kernel_time": 0.309756, "process_mem_max_rss": "104976", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m05:14:54.955615 [debug] [MainThread]: Command `dbt deps` succeeded at 05:14:54.955379 after 0.20 seconds
[0m05:14:54.957188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbda57f6ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbda5880690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbdaa34f850>]}
[0m05:14:54.958445 [debug] [MainThread]: Flushing usage events
[0m05:14:58.479535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc316667990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3166667d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc316666cd0>]}


============================== 05:14:58.487160 | 8f52ef23-7aaa-4cab-b216-9407d4e7fcf5 ==============================
[0m05:14:58.487160 [info ] [MainThread]: Running with dbt=1.7.11
[0m05:14:58.488745 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m05:14:58.699315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8f52ef23-7aaa-4cab-b216-9407d4e7fcf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc315973090>]}
[0m05:14:58.803618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8f52ef23-7aaa-4cab-b216-9407d4e7fcf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc315900150>]}
[0m05:14:58.806412 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m05:14:58.828058 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m05:14:59.182504 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:14:59.183643 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:14:59.191732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8f52ef23-7aaa-4cab-b216-9407d4e7fcf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc315948dd0>]}
[0m05:14:59.231660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8f52ef23-7aaa-4cab-b216-9407d4e7fcf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31550e490>]}
[0m05:14:59.233893 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m05:14:59.235495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f52ef23-7aaa-4cab-b216-9407d4e7fcf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc315972b50>]}
[0m05:14:59.239216 [info ] [MainThread]: 
[0m05:14:59.241849 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m05:14:59.247695 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m05:14:59.263026 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m05:14:59.265225 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m05:14:59.267165 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:14:59.281306 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.0 seconds
[0m05:14:59.284477 [debug] [ThreadPool]: On list_warehouse: Close
[0m05:14:59.289372 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_snapshots)
[0m05:14:59.290861 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m05:14:59.292133 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m05:14:59.293443 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m05:14:59.300140 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:14:59.303575 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:14:59.307170 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:14:59.311778 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:14:59.313809 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m05:14:59.316148 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m05:14:59.318336 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m05:14:59.320436 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m05:14:59.322700 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m05:14:59.325091 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:14:59.327512 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:14:59.330293 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:14:59.342246 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.343071 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.343577 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:14:59.344417 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:14:59.345219 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.345784 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m05:14:59.346800 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.347139 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m05:14:59.348538 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:14:59.350664 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:14:59.352401 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m05:14:59.353320 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m05:14:59.354820 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:14:59.355245 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:14:59.356899 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m05:14:59.357234 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:14:59.357859 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:14:59.360050 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m05:14:59.361780 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m05:14:59.363829 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m05:14:59.366681 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m05:14:59.369117 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m05:14:59.372562 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m05:14:59.374342 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m05:14:59.384155 [debug] [MainThread]: Using postgres connection "master"
[0m05:14:59.386202 [debug] [MainThread]: On master: BEGIN
[0m05:14:59.387868 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:14:59.396216 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.398216 [debug] [MainThread]: Using postgres connection "master"
[0m05:14:59.400123 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m05:14:59.405893 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m05:14:59.409415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8f52ef23-7aaa-4cab-b216-9407d4e7fcf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc3164b1090>]}
[0m05:14:59.411853 [debug] [MainThread]: On master: ROLLBACK
[0m05:14:59.414262 [debug] [MainThread]: Using postgres connection "master"
[0m05:14:59.416811 [debug] [MainThread]: On master: BEGIN
[0m05:14:59.419673 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.421494 [debug] [MainThread]: On master: COMMIT
[0m05:14:59.423232 [debug] [MainThread]: Using postgres connection "master"
[0m05:14:59.425037 [debug] [MainThread]: On master: COMMIT
[0m05:14:59.427428 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m05:14:59.429526 [debug] [MainThread]: On master: Close
[0m05:14:59.432393 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m05:14:59.433707 [info ] [MainThread]: 
[0m05:14:59.443349 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m05:14:59.444997 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m05:14:59.446460 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m05:14:59.447333 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m05:14:59.457429 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 05:14:59.448189 => 05:14:59.457141
[0m05:14:59.459461 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m05:14:59.521973 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m05:14:59.544794 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m05:14:59.547088 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m05:14:59.548985 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m05:14:59.557621 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.560293 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m05:14:59.562074 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m05:14:59.564869 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m05:14:59.566826 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m05:14:59.568960 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 05:14:59.461457 => 05:14:59.568718
[0m05:14:59.571363 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m05:14:59.577465 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m05:14:59.579660 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f52ef23-7aaa-4cab-b216-9407d4e7fcf5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc314d66890>]}
[0m05:14:59.581956 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.13s]
[0m05:14:59.583393 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m05:14:59.587413 [debug] [MainThread]: Using postgres connection "master"
[0m05:14:59.588590 [debug] [MainThread]: On master: BEGIN
[0m05:14:59.589698 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m05:14:59.597655 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:14:59.599128 [debug] [MainThread]: On master: COMMIT
[0m05:14:59.601453 [debug] [MainThread]: Using postgres connection "master"
[0m05:14:59.604157 [debug] [MainThread]: On master: COMMIT
[0m05:14:59.607071 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m05:14:59.608519 [debug] [MainThread]: On master: Close
[0m05:14:59.610637 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:14:59.612319 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m05:14:59.613349 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m05:14:59.614624 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m05:14:59.615871 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m05:14:59.617071 [info ] [MainThread]: 
[0m05:14:59.619318 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.38 seconds (0.38s).
[0m05:14:59.621160 [debug] [MainThread]: Command end result
[0m05:14:59.659149 [info ] [MainThread]: 
[0m05:14:59.660845 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m05:14:59.663254 [info ] [MainThread]: 
[0m05:14:59.665018 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m05:14:59.666829 [info ] [MainThread]: 
[0m05:14:59.670712 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m05:14:59.674492 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 1.2575403, "process_user_time": 3.444906, "process_kernel_time": 0.110156, "process_mem_max_rss": "121104", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m05:14:59.676664 [debug] [MainThread]: Command `dbt snapshot` failed at 05:14:59.676362 after 1.26 seconds
[0m05:14:59.678680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31667b790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc31b057d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc317cc5150>]}
[0m05:14:59.680802 [debug] [MainThread]: Flushing usage events
[0m05:15:05.152478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2f32eb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2f7f3a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2f32ec90>]}


============================== 05:15:05.161394 | 0943fd54-c5fa-4ecb-8826-ae252f2062ee ==============================
[0m05:15:05.161394 [info ] [MainThread]: Running with dbt=1.7.11
[0m05:15:05.163259 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt docs generate', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:15:05.376043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0943fd54-c5fa-4ecb-8826-ae252f2062ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2e718f10>]}
[0m05:15:05.489704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0943fd54-c5fa-4ecb-8826-ae252f2062ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2e7f85d0>]}
[0m05:15:05.492011 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m05:15:05.516839 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m05:15:05.848620 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:15:05.849936 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:15:05.857524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0943fd54-c5fa-4ecb-8826-ae252f2062ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2df6d1d0>]}
[0m05:15:05.872063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0943fd54-c5fa-4ecb-8826-ae252f2062ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2dfb3590>]}
[0m05:15:05.873579 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m05:15:05.876942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0943fd54-c5fa-4ecb-8826-ae252f2062ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2e7b2990>]}
[0m05:15:05.882271 [info ] [MainThread]: 
[0m05:15:05.884925 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m05:15:05.890527 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m05:15:05.893480 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m05:15:05.894829 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m05:15:05.896212 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m05:15:05.911547 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:15:05.916442 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:15:05.920893 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:15:05.924760 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:15:05.926017 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m05:15:05.928109 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m05:15:05.929738 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m05:15:05.931335 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m05:15:05.934127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:05.935875 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:05.937569 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:05.939413 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:05.949460 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:05.950733 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:05.951198 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:05.951806 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:05.952242 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:15:05.954191 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:15:05.956406 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:15:05.958457 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:15:05.960119 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m05:15:05.962289 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m05:15:05.964281 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m05:15:05.966691 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m05:15:05.971384 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:05.973190 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:05.975169 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:05.977318 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m05:15:05.977762 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:05.980116 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m05:15:05.983124 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m05:15:05.985528 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m05:15:05.987787 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m05:15:05.990605 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m05:15:05.992639 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m05:15:05.996043 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m05:15:06.008393 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:06.010186 [debug] [MainThread]: On master: BEGIN
[0m05:15:06.012455 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:15:06.022753 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:15:06.025665 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:06.028485 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m05:15:06.037404 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:06.042360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0943fd54-c5fa-4ecb-8826-ae252f2062ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2e723950>]}
[0m05:15:06.045140 [debug] [MainThread]: On master: ROLLBACK
[0m05:15:06.047810 [debug] [MainThread]: On master: Close
[0m05:15:06.050816 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m05:15:06.052647 [info ] [MainThread]: 
[0m05:15:06.062956 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m05:15:06.065843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m05:15:06.067389 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m05:15:06.076241 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m05:15:06.096617 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 05:15:06.068843 => 05:15:06.096270
[0m05:15:06.098131 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m05:15:06.100680 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 05:15:06.100363 => 05:15:06.100388
[0m05:15:06.103031 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m05:15:06.106428 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m05:15:06.107135 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m05:15:06.107743 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:15:06.108302 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:15:06.109575 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.orders_enriched)
[0m05:15:06.111862 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m05:15:06.114025 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m05:15:06.116420 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m05:15:06.118455 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m05:15:06.120837 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m05:15:06.123159 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:15:06.125801 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:15:06.132562 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m05:15:06.137820 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 05:15:06.133907 => 05:15:06.137492
[0m05:15:06.153020 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m05:15:06.158445 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m05:15:06.162555 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m05:15:06.168280 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 05:15:06.167865 => 05:15:06.167892
[0m05:15:06.170724 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m05:15:06.172038 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:15:06.172800 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 05:15:06.128393 => 05:15:06.172495
[0m05:15:06.173483 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 05:15:06.138833 => 05:15:06.173126
[0m05:15:06.174216 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 05:15:06.153939 => 05:15:06.173985
[0m05:15:06.176104 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m05:15:06.177689 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m05:15:06.179150 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:15:06.181061 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:15:06.183712 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:15:06.186052 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 05:15:06.185784 => 05:15:06.185801
[0m05:15:06.188405 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 05:15:06.188153 => 05:15:06.188164
[0m05:15:06.190877 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 05:15:06.190637 => 05:15:06.190647
[0m05:15:06.197845 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m05:15:06.201112 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m05:15:06.204019 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:15:06.207807 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:15:06.213360 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:15:06.216109 [debug] [Thread-2 (]: Began running node model.sales_analytics.dim_customer
[0m05:15:06.218498 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m05:15:06.221392 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m05:15:06.224188 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.dim_customer)
[0m05:15:06.227583 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m05:15:06.230208 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:15:06.232393 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.dim_customer
[0m05:15:06.234054 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m05:15:06.235001 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 05:15:06.192921 => 05:15:06.234602
[0m05:15:06.243834 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m05:15:06.248037 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m05:15:06.257813 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m05:15:06.259595 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:15:06.265628 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 05:15:06.265248 => 05:15:06.265270
[0m05:15:06.268159 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:15:06.270344 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:15:06.272204 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 05:15:06.249443 => 05:15:06.271847
[0m05:15:06.273257 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m05:15:06.273855 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (compile): 05:15:06.244704 => 05:15:06.273601
[0m05:15:06.274465 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 05:15:06.236815 => 05:15:06.274216
[0m05:15:06.275907 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m05:15:06.277856 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:15:06.280193 [debug] [Thread-2 (]: Began executing node model.sales_analytics.dim_customer
[0m05:15:06.281907 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:15:06.284397 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 05:15:06.283978 => 05:15:06.283991
[0m05:15:06.292528 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m05:15:06.294422 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (execute): 05:15:06.294133 => 05:15:06.294149
[0m05:15:06.296894 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 05:15:06.296596 => 05:15:06.296606
[0m05:15:06.299991 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m05:15:06.304941 [debug] [Thread-2 (]: Finished running node model.sales_analytics.dim_customer
[0m05:15:06.307775 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:15:06.311097 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:15:06.312800 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:15:06.328166 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:15:06.330900 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m05:15:06.333479 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m05:15:06.334786 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 05:15:06.286525 => 05:15:06.334471
[0m05:15:06.336586 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m05:15:06.338512 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:15:06.340502 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:15:06.342713 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:15:06.345299 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:15:06.353117 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m05:15:06.360356 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m05:15:06.362318 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 05:15:06.362041 => 05:15:06.362054
[0m05:15:06.370900 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m05:15:06.378059 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:15:06.381987 [debug] [Thread-4 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:15:06.384981 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m05:15:06.386247 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 05:15:06.347607 => 05:15:06.385613
[0m05:15:06.387236 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 05:15:06.364724 => 05:15:06.386784
[0m05:15:06.388421 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 05:15:06.354821 => 05:15:06.387951
[0m05:15:06.389045 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:15:06.391391 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:15:06.394279 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:15:06.397110 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:15:06.408868 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m05:15:06.410762 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 05:15:06.410250 => 05:15:06.410274
[0m05:15:06.413483 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 05:15:06.413255 => 05:15:06.413264
[0m05:15:06.416543 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 05:15:06.416180 => 05:15:06.416192
[0m05:15:06.422225 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:15:06.425108 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:15:06.427556 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:15:06.429617 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:15:06.435723 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m05:15:06.437697 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:15:06.443812 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m05:15:06.445781 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 05:15:06.399289 => 05:15:06.445561
[0m05:15:06.447997 [debug] [Thread-4 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:15:06.449975 [debug] [Thread-4 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 05:15:06.449740 => 05:15:06.449751
[0m05:15:06.452239 [debug] [Thread-4 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:15:06.461335 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 05:15:06.439327 => 05:15:06.461096
[0m05:15:06.462836 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:15:06.464894 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 05:15:06.464681 => 05:15:06.464690
[0m05:15:06.467299 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:15:06.469616 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:15:06.470916 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m05:15:06.472687 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m05:15:06.474410 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m05:15:06.476115 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m05:15:06.479242 [debug] [MainThread]: Command end result
[0m05:15:06.547345 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m05:15:06.548972 [info ] [MainThread]: Building catalog
[0m05:15:06.553121 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m05:15:06.566795 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m05:15:06.568419 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m05:15:06.570103 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:06.577785 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:06.579481 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m05:15:06.581178 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m05:15:06.586997 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:06.590257 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m05:15:06.592186 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m05:15:06.626159 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m05:15:06.628219 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.5379286, "process_user_time": 3.653869, "process_kernel_time": 0.172065, "process_mem_max_rss": "120932", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m05:15:06.629776 [debug] [MainThread]: Command `dbt docs generate` succeeded at 05:15:06.629592 after 1.54 seconds
[0m05:15:06.631225 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m05:15:06.632312 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m05:15:06.633422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2f38b450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c31681b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c2e7d3110>]}
[0m05:15:06.634794 [debug] [MainThread]: Flushing usage events
[0m05:15:52.048675 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa645112cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa6455db910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa646832010>]}


============================== 05:15:52.056113 | 12f7d773-da5f-48b3-b0b5-7fb955e10a26 ==============================
[0m05:15:52.056113 [info ] [MainThread]: Running with dbt=1.7.11
[0m05:15:52.058569 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m05:15:52.160700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '12f7d773-da5f-48b3-b0b5-7fb955e10a26', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa645162550>]}
[0m05:15:52.166307 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m05:15:52.176932 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m05:15:52.179147 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.20109233, "process_user_time": 2.927581, "process_kernel_time": 0.130337, "process_mem_max_rss": "104860", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m05:15:52.180824 [debug] [MainThread]: Command `dbt deps` succeeded at 05:15:52.180593 after 0.20 seconds
[0m05:15:52.182037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64516af50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64516a9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa64516ae90>]}
[0m05:15:52.183223 [debug] [MainThread]: Flushing usage events
[0m05:15:55.649671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa18ccebd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa18cce7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa18ccf450>]}


============================== 05:15:55.656805 | 4320cf0b-bf93-4a83-93dd-58289619a389 ==============================
[0m05:15:55.656805 [info ] [MainThread]: Running with dbt=1.7.11
[0m05:15:55.658225 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m05:15:55.877135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4320cf0b-bf93-4a83-93dd-58289619a389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa1814db90>]}
[0m05:15:55.988734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4320cf0b-bf93-4a83-93dd-58289619a389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa17d019d0>]}
[0m05:15:55.990679 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m05:15:56.012294 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m05:15:56.185593 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:15:56.187251 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:15:56.195088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4320cf0b-bf93-4a83-93dd-58289619a389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa18d22e90>]}
[0m05:15:56.240989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4320cf0b-bf93-4a83-93dd-58289619a389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa17d8c750>]}
[0m05:15:56.242418 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m05:15:56.243739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4320cf0b-bf93-4a83-93dd-58289619a389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa17dd9110>]}
[0m05:15:56.246956 [info ] [MainThread]: 
[0m05:15:56.248737 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m05:15:56.251844 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m05:15:56.267232 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m05:15:56.269158 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m05:15:56.270588 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:56.279697 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m05:15:56.282341 [debug] [ThreadPool]: On list_warehouse: Close
[0m05:15:56.284857 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m05:15:56.287738 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m05:15:56.295353 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m05:15:56.296748 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m05:15:56.297837 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m05:15:56.306805 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.308580 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m05:15:56.310121 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m05:15:56.311854 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m05:15:56.313831 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m05:15:56.315232 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m05:15:56.316564 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m05:15:56.322021 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m05:15:56.323551 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m05:15:56.327110 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_analytics_staging)
[0m05:15:56.328076 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m05:15:56.329118 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m05:15:56.330476 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m05:15:56.336826 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:15:56.340200 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:15:56.343087 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:15:56.345879 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:15:56.347455 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m05:15:56.348407 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m05:15:56.349772 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m05:15:56.350996 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m05:15:56.352233 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m05:15:56.353558 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:56.354617 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:56.355985 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:15:56.363968 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.365365 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:15:56.365974 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.366694 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.367168 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.367612 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m05:15:56.368971 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:15:56.370118 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:15:56.371490 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:15:56.373350 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m05:15:56.374318 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m05:15:56.375503 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m05:15:56.376214 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:56.380523 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m05:15:56.381058 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:56.381577 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:56.381994 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:56.382988 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m05:15:56.384776 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m05:15:56.387055 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m05:15:56.389093 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m05:15:56.392004 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m05:15:56.392933 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m05:15:56.393885 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m05:15:56.403667 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:56.405134 [debug] [MainThread]: On master: BEGIN
[0m05:15:56.406520 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:15:56.414522 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.415958 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:56.417461 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m05:15:56.422900 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m05:15:56.425453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4320cf0b-bf93-4a83-93dd-58289619a389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa181de9d0>]}
[0m05:15:56.426976 [debug] [MainThread]: On master: ROLLBACK
[0m05:15:56.428433 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:56.429753 [debug] [MainThread]: On master: BEGIN
[0m05:15:56.431330 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.432594 [debug] [MainThread]: On master: COMMIT
[0m05:15:56.433846 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:56.435061 [debug] [MainThread]: On master: COMMIT
[0m05:15:56.436468 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m05:15:56.437589 [debug] [MainThread]: On master: Close
[0m05:15:56.439139 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m05:15:56.440402 [info ] [MainThread]: 
[0m05:15:56.450413 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m05:15:56.452064 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m05:15:56.454042 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now snapshot.sales_analytics.customers_snapshot)
[0m05:15:56.455464 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m05:15:56.466259 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 05:15:56.457090 => 05:15:56.465965
[0m05:15:56.467836 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m05:15:56.535085 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m05:15:56.551055 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m05:15:56.552584 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m05:15:56.553773 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m05:15:56.561223 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.563245 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m05:15:56.565030 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m05:15:56.567292 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "analytics_staging.src_orders" does not exist
LINE 32: from "warehouse"."analytics_staging"."src_orders"
              ^

[0m05:15:56.568675 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: ROLLBACK
[0m05:15:56.570670 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 05:15:56.469581 => 05:15:56.570444
[0m05:15:56.572227 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m05:15:56.577161 [debug] [Thread-1 (]: Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m05:15:56.579036 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4320cf0b-bf93-4a83-93dd-58289619a389', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa17598710>]}
[0m05:15:56.580944 [error] [Thread-1 (]: 1 of 1 ERROR snapshotting snapshots.customers_snapshot ......................... [[31mERROR[0m in 0.13s]
[0m05:15:56.582245 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m05:15:56.585662 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:56.586620 [debug] [MainThread]: On master: BEGIN
[0m05:15:56.587584 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m05:15:56.594398 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:15:56.596614 [debug] [MainThread]: On master: COMMIT
[0m05:15:56.599486 [debug] [MainThread]: Using postgres connection "master"
[0m05:15:56.601408 [debug] [MainThread]: On master: COMMIT
[0m05:15:56.604747 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m05:15:56.605696 [debug] [MainThread]: On master: Close
[0m05:15:56.607149 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:15:56.608829 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m05:15:56.609657 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m05:15:56.610681 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m05:15:56.611635 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m05:15:56.613160 [info ] [MainThread]: 
[0m05:15:56.615056 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.36 seconds (0.36s).
[0m05:15:56.617017 [debug] [MainThread]: Command end result
[0m05:15:56.650310 [info ] [MainThread]: 
[0m05:15:56.652613 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m05:15:56.654304 [info ] [MainThread]: 
[0m05:15:56.655719 [error] [MainThread]:   Database Error in snapshot customers_snapshot (snapshots/customers_snapshot.sql)
  relation "analytics_staging.src_orders" does not exist
  LINE 32: from "warehouse"."analytics_staging"."src_orders"
                ^
  compiled Code at target/run/sales_analytics/snapshots/customers_snapshot.sql
[0m05:15:56.657129 [info ] [MainThread]: 
[0m05:15:56.658412 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m05:15:56.660433 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_wall_clock_time": 1.0775816, "process_user_time": 3.5757, "process_kernel_time": 0.089891, "process_mem_max_rss": "121724", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m05:15:56.662284 [debug] [MainThread]: Command `dbt snapshot` failed at 05:15:56.662105 after 1.08 seconds
[0m05:15:56.664311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa1918f3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa19129050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa1d85f910>]}
[0m05:15:56.666086 [debug] [MainThread]: Flushing usage events
[0m05:16:02.301344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8ab2a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8ab3d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8ab39d0>]}


============================== 05:16:02.310680 | 9ee17ba0-61ca-4a19-8e08-6b81cda09228 ==============================
[0m05:16:02.310680 [info ] [MainThread]: Running with dbt=1.7.11
[0m05:16:02.312500 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs generate', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m05:16:02.547607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9ee17ba0-61ca-4a19-8e08-6b81cda09228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8561a90>]}
[0m05:16:02.657174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9ee17ba0-61ca-4a19-8e08-6b81cda09228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8568e10>]}
[0m05:16:02.659713 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m05:16:02.680805 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m05:16:02.924631 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:16:02.926248 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:16:02.934633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9ee17ba0-61ca-4a19-8e08-6b81cda09228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b7da6690>]}
[0m05:16:02.952902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9ee17ba0-61ca-4a19-8e08-6b81cda09228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b7d73890>]}
[0m05:16:02.954007 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m05:16:02.955127 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9ee17ba0-61ca-4a19-8e08-6b81cda09228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42bc0fa050>]}
[0m05:16:02.958444 [info ] [MainThread]: 
[0m05:16:02.960796 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m05:16:02.964185 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m05:16:02.966621 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m05:16:02.968272 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m05:16:02.970202 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m05:16:02.985049 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:16:02.988182 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:16:02.992167 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:16:02.995987 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:16:02.997480 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m05:16:02.999475 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m05:16:03.002285 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m05:16:03.004429 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m05:16:03.006104 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:16:03.008247 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:16:03.010561 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:16:03.012712 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:16:03.024288 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:16:03.026362 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m05:16:03.028523 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m05:16:03.032777 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:16:03.035704 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m05:16:03.037890 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m05:16:03.041131 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:16:03.042893 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m05:16:03.043302 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:16:03.044827 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m05:16:03.046451 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m05:16:03.046973 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:16:03.050113 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m05:16:03.051901 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:16:03.052345 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m05:16:03.056788 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m05:16:03.057370 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:16:03.058803 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m05:16:03.061314 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m05:16:03.063906 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m05:16:03.069452 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m05:16:03.070052 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:16:03.073953 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m05:16:03.075913 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m05:16:03.083415 [debug] [MainThread]: Using postgres connection "master"
[0m05:16:03.085782 [debug] [MainThread]: On master: BEGIN
[0m05:16:03.087976 [debug] [MainThread]: Opening a new connection, currently in state init
[0m05:16:03.096467 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m05:16:03.098545 [debug] [MainThread]: Using postgres connection "master"
[0m05:16:03.100516 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m05:16:03.106218 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m05:16:03.109589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9ee17ba0-61ca-4a19-8e08-6b81cda09228', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8aa40d0>]}
[0m05:16:03.111962 [debug] [MainThread]: On master: ROLLBACK
[0m05:16:03.114474 [debug] [MainThread]: On master: Close
[0m05:16:03.117535 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m05:16:03.119006 [info ] [MainThread]: 
[0m05:16:03.130390 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m05:16:03.132635 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m05:16:03.135350 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m05:16:03.143379 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m05:16:03.160727 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 05:16:03.137051 => 05:16:03.160165
[0m05:16:03.162073 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m05:16:03.163483 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 05:16:03.163078 => 05:16:03.163110
[0m05:16:03.165608 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m05:16:03.169152 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m05:16:03.170157 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m05:16:03.170738 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:16:03.171344 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:16:03.172867 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m05:16:03.175038 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now snapshot.sales_analytics.customers_snapshot)
[0m05:16:03.177051 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m05:16:03.178818 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m05:16:03.180058 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m05:16:03.181263 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m05:16:03.183446 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:16:03.185147 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:16:03.190097 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m05:16:03.196457 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 05:16:03.191981 => 05:16:03.196035
[0m05:16:03.216688 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m05:16:03.224350 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m05:16:03.226965 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m05:16:03.230987 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 05:16:03.230347 => 05:16:03.230373
[0m05:16:03.233938 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 05:16:03.198514 => 05:16:03.233591
[0m05:16:03.234934 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 05:16:03.186656 => 05:16:03.234622
[0m05:16:03.235682 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 05:16:03.217150 => 05:16:03.235304
[0m05:16:03.237037 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m05:16:03.238478 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:16:03.239859 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m05:16:03.241537 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:16:03.243109 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:16:03.244932 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 05:16:03.244647 => 05:16:03.244662
[0m05:16:03.246598 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 05:16:03.246336 => 05:16:03.246349
[0m05:16:03.248061 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 05:16:03.247749 => 05:16:03.247763
[0m05:16:03.249953 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m05:16:03.252764 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m05:16:03.255575 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m05:16:03.258415 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m05:16:03.260426 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:16:03.262865 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:16:03.265657 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m05:16:03.268178 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m05:16:03.274852 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m05:16:03.277149 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m05:16:03.280011 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.dim_customer)
[0m05:16:03.282907 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m05:16:03.287036 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:16:03.289714 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m05:16:03.291882 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m05:16:03.299679 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m05:16:03.305213 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m05:16:03.306148 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 05:16:03.270037 => 05:16:03.305762
[0m05:16:03.315679 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m05:16:03.320796 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:16:03.324031 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 05:16:03.323646 => 05:16:03.323659
[0m05:16:03.327052 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m05:16:03.328596 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:16:03.330599 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 05:16:03.301423 => 05:16:03.330274
[0m05:16:03.331641 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m05:16:03.332178 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 05:16:03.307245 => 05:16:03.331970
[0m05:16:03.332928 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 05:16:03.293610 => 05:16:03.332651
[0m05:16:03.334563 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m05:16:03.336418 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:16:03.338632 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m05:16:03.340834 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:16:03.343136 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 05:16:03.342841 => 05:16:03.342853
[0m05:16:03.349781 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m05:16:03.351790 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 05:16:03.351492 => 05:16:03.351511
[0m05:16:03.353245 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 05:16:03.353002 => 05:16:03.353015
[0m05:16:03.354931 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m05:16:03.359205 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m05:16:03.361648 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m05:16:03.364280 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:16:03.366128 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:16:03.367772 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:16:03.370431 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m05:16:03.373140 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m05:16:03.374551 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 05:16:03.344969 => 05:16:03.374289
[0m05:16:03.375984 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m05:16:03.377946 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:16:03.380256 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:16:03.382346 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:16:03.384651 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:16:03.391927 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m05:16:03.397585 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m05:16:03.399976 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 05:16:03.399579 => 05:16:03.399594
[0m05:16:03.406368 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m05:16:03.413339 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m05:16:03.417058 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:16:03.419397 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m05:16:03.420070 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 05:16:03.393498 => 05:16:03.419701
[0m05:16:03.420778 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 05:16:03.386889 => 05:16:03.420478
[0m05:16:03.421687 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:16:03.423653 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 05:16:03.402417 => 05:16:03.423366
[0m05:16:03.424199 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:16:03.426319 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:16:03.432855 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m05:16:03.434818 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:16:03.437321 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 05:16:03.436989 => 05:16:03.436998
[0m05:16:03.439869 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 05:16:03.439636 => 05:16:03.439644
[0m05:16:03.443811 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 05:16:03.443581 => 05:16:03.443588
[0m05:16:03.446252 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m05:16:03.448973 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m05:16:03.451986 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m05:16:03.453517 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:16:03.456328 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 05:16:03.428286 => 05:16:03.456042
[0m05:16:03.457037 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m05:16:03.458388 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:16:03.460127 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:16:03.461775 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 05:16:03.461554 => 05:16:03.461563
[0m05:16:03.469216 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m05:16:03.470945 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m05:16:03.490427 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 05:16:03.462930 => 05:16:03.490055
[0m05:16:03.491938 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:16:03.493857 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 05:16:03.493633 => 05:16:03.493643
[0m05:16:03.496121 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m05:16:03.499648 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:16:03.500760 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m05:16:03.502218 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m05:16:03.504083 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m05:16:03.506019 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m05:16:03.509338 [debug] [MainThread]: Command end result
[0m05:16:03.555982 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m05:16:03.557604 [info ] [MainThread]: Building catalog
[0m05:16:03.561805 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m05:16:03.573629 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m05:16:03.575582 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m05:16:03.577645 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:16:03.587529 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m05:16:03.589802 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m05:16:03.591638 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m05:16:03.597537 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m05:16:03.615746 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m05:16:03.617953 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m05:16:03.649991 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m05:16:03.652258 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.4186835, "process_user_time": 3.638645, "process_kernel_time": 0.247864, "process_mem_max_rss": "120672", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m05:16:03.653550 [debug] [MainThread]: Command `dbt docs generate` succeeded at 05:16:03.653407 after 1.42 seconds
[0m05:16:03.654603 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m05:16:03.655684 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m05:16:03.656948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8ab7e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b8ab7f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42b84bc450>]}
[0m05:16:03.658546 [debug] [MainThread]: Flushing usage events
[0m06:25:55.894995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1236e8ced0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1237343b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1237343910>]}


============================== 06:25:55.905737 | 707081ba-981e-47a8-a535-3df1cb324bcc ==============================
[0m06:25:55.905737 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:25:55.906815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:25:55.994680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '707081ba-981e-47a8-a535-3df1cb324bcc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1236d75750>]}
[0m06:25:55.997364 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:25:56.005685 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:25:56.008217 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16747405, "process_user_time": 2.363597, "process_kernel_time": 0.250381, "process_mem_max_rss": "105056", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:25:56.009647 [debug] [MainThread]: Command `dbt deps` succeeded at 06:25:56.009447 after 0.17 seconds
[0m06:25:56.010617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1236e87150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1236e84d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1236f5c990>]}
[0m06:25:56.011883 [debug] [MainThread]: Flushing usage events
[0m06:25:59.220364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1f636190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f209bac90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1f636c90>]}


============================== 06:25:59.228169 | 268101fe-ddd2-4e96-b232-48ab35a4b72f ==============================
[0m06:25:59.228169 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:25:59.230423 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m06:25:59.409084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1ed7f790>]}
[0m06:25:59.499551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1ed2a310>]}
[0m06:25:59.501178 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:25:59.516096 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:25:59.678791 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:25:59.679752 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:25:59.685274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1e570cd0>]}
[0m06:25:59.711031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1e957710>]}
[0m06:25:59.712450 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:25:59.713866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1ed0bc90>]}
[0m06:25:59.718019 [info ] [MainThread]: 
[0m06:25:59.720603 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:25:59.724315 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:25:59.727196 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:25:59.730797 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:25:59.745947 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:25:59.748789 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:25:59.752710 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:25:59.754289 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:25:59.755805 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:25:59.758014 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:25:59.759646 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:25:59.761349 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:25:59.762496 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:25:59.779375 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m06:25:59.780099 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m06:25:59.780601 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m06:25:59.783346 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:25:59.786032 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:25:59.788753 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:25:59.796967 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_intermediate)
[0m06:25:59.797879 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_staging)
[0m06:25:59.798692 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_marts)
[0m06:25:59.800664 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_intermediate"
"
[0m06:25:59.802858 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_staging"
"
[0m06:25:59.805119 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_marts"
"
[0m06:25:59.811714 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m06:25:59.815133 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m06:25:59.819087 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m06:25:59.820383 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: BEGIN
[0m06:25:59.821768 [debug] [ThreadPool]: On create_warehouse_analytics_staging: BEGIN
[0m06:25:59.823034 [debug] [ThreadPool]: On create_warehouse_analytics_marts: BEGIN
[0m06:25:59.824274 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:25:59.825540 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:25:59.826524 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:25:59.833852 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.834755 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.835532 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m06:25:59.836234 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.837004 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m06:25:59.838052 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_intermediate"} */
create schema if not exists "analytics_intermediate"
[0m06:25:59.839349 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m06:25:59.840232 [debug] [ThreadPool]: On create_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_staging"} */
create schema if not exists "analytics_staging"
[0m06:25:59.841888 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:25:59.842520 [debug] [ThreadPool]: On create_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_marts"} */
create schema if not exists "analytics_marts"
[0m06:25:59.844125 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:25:59.845451 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: COMMIT
[0m06:25:59.847021 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:25:59.848253 [debug] [ThreadPool]: On create_warehouse_analytics_staging: COMMIT
[0m06:25:59.849591 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m06:25:59.851245 [debug] [ThreadPool]: On create_warehouse_analytics_marts: COMMIT
[0m06:25:59.852541 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m06:25:59.853485 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: COMMIT
[0m06:25:59.854768 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m06:25:59.855720 [debug] [ThreadPool]: On create_warehouse_analytics_staging: COMMIT
[0m06:25:59.858867 [debug] [ThreadPool]: On create_warehouse_analytics_marts: COMMIT
[0m06:25:59.876036 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:25:59.878213 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: Close
[0m06:25:59.879230 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:25:59.879752 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:25:59.882579 [debug] [ThreadPool]: On create_warehouse_analytics_marts: Close
[0m06:25:59.884616 [debug] [ThreadPool]: On create_warehouse_analytics_staging: Close
[0m06:25:59.890761 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_staging, now list_warehouse_snapshots)
[0m06:25:59.891820 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_marts, now list_warehouse_analytics_intermediate)
[0m06:25:59.892650 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_intermediate, now list_warehouse_analytics_staging)
[0m06:25:59.893555 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:25:59.898730 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:25:59.902503 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:25:59.906268 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:25:59.909362 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:25:59.910014 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:25:59.910722 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:25:59.911504 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:25:59.912307 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:25:59.913031 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:25:59.913753 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:25:59.914440 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:25:59.915118 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:25:59.922322 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.923160 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.925151 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:25:59.927165 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:25:59.931184 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.932448 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:25:59.933598 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:25:59.934146 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.934822 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:25:59.937252 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:25:59.938557 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:25:59.939000 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:25:59.939987 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:25:59.940452 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:25:59.944502 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:25:59.945019 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:25:59.948369 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:25:59.949262 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:25:59.950502 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:25:59.952703 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:25:59.954935 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:25:59.957375 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:25:59.960762 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:25:59.963691 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:25:59.970718 [debug] [MainThread]: Using postgres connection "master"
[0m06:25:59.972523 [debug] [MainThread]: On master: BEGIN
[0m06:25:59.974384 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:25:59.981482 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:25:59.983224 [debug] [MainThread]: Using postgres connection "master"
[0m06:25:59.985200 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:25:59.989777 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m06:25:59.992243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1e998d90>]}
[0m06:25:59.993969 [debug] [MainThread]: On master: ROLLBACK
[0m06:25:59.995821 [debug] [MainThread]: Using postgres connection "master"
[0m06:25:59.997441 [debug] [MainThread]: On master: BEGIN
[0m06:25:59.999518 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:26:00.001091 [debug] [MainThread]: On master: COMMIT
[0m06:26:00.002656 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:00.003647 [debug] [MainThread]: On master: COMMIT
[0m06:26:00.004882 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:26:00.006269 [debug] [MainThread]: On master: Close
[0m06:26:00.007666 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:26:00.009316 [info ] [MainThread]: 
[0m06:26:00.020113 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m06:26:00.021843 [info ] [Thread-1 (]: 1 of 4 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m06:26:00.025217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.src_orders)
[0m06:26:00.027401 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m06:26:00.036862 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m06:26:00.056458 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 06:26:00.029519 => 06:26:00.055883
[0m06:26:00.059627 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m06:26:00.097847 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m06:26:00.125809 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.126675 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m06:26:00.127383 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:26:00.133700 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:26:00.134710 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.135542 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m06:26:00.137416 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m06:26:00.144357 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.145439 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m06:26:00.146756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:26:00.169417 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.171749 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m06:26:00.174554 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:26:00.188101 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.190067 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m06:26:00.200420 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m06:26:00.206618 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.208541 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:26:00.210589 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:26:00.213120 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m06:26:00.214972 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.216411 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m06:26:00.237394 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:26:00.249052 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m06:26:00.254111 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:26:00.254884 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m06:26:00.255904 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m06:26:00.257537 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 06:26:00.062155 => 06:26:00.257380
[0m06:26:00.258318 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m06:26:00.259580 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1e1bd890>]}
[0m06:26:00.260580 [info ] [Thread-1 (]: 1 of 4 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 0.24s]
[0m06:26:00.262209 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m06:26:00.264167 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m06:26:00.264647 [debug] [Thread-4 (]: Began running node model.sales_analytics.orders_enriched
[0m06:26:00.265634 [info ] [Thread-3 (]: 2 of 4 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m06:26:00.266882 [info ] [Thread-4 (]: 3 of 4 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m06:26:00.268546 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.dim_customer)
[0m06:26:00.269751 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.orders_enriched)
[0m06:26:00.271076 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m06:26:00.272270 [debug] [Thread-4 (]: Began compiling node model.sales_analytics.orders_enriched
[0m06:26:00.279648 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m06:26:00.283998 [debug] [Thread-4 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m06:26:00.294683 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (compile): 06:26:00.281457 => 06:26:00.294181
[0m06:26:00.295401 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 06:26:00.273066 => 06:26:00.295119
[0m06:26:00.297092 [debug] [Thread-4 (]: Began executing node model.sales_analytics.orders_enriched
[0m06:26:00.298936 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m06:26:00.340306 [debug] [Thread-4 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m06:26:00.340958 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m06:26:00.353097 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.355491 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m06:26:00.357152 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m06:26:00.358292 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:26:00.359922 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: BEGIN
[0m06:26:00.361321 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:26:00.365452 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m06:26:00.366899 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.368436 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m06:26:00.369570 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m06:26:00.371534 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:26:00.372847 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- 

-- with current as (
--     select *
--     from "warehouse"."snapshots"."customers_snapshot"
--     where dbt_valid_to is null
-- ),

-- deduped as (
--     select
--         customer_id,
--         country,
--         status,
--         dbt_valid_from,
--         row_number() over (
--             partition by customer_id
--             order by dbt_valid_from desc
--         ) as rn
--     from current
-- )

-- select
--     customer_id,
--     country,
--     status,
--     dbt_valid_from as valid_from
-- from deduped
-- where rn = 1



with snapshot_data as (
    select
        customer_id,
        country,
        status,
        dbt_valid_from,
        dbt_valid_to
    from "warehouse"."snapshots"."customers_snapshot"
)

select
    customer_id,
    country,
    status,
    dbt_valid_from as valid_from,
    dbt_valid_to   as valid_to,
    case when dbt_valid_to is null then true else false end as is_current
from snapshot_data
order by customer_id, dbt_valid_from
  );
  
[0m06:26:00.375171 [debug] [Thread-3 (]: Postgres adapter: Postgres error: relation "snapshots.customers_snapshot" does not exist
LINE 50:     from "warehouse"."snapshots"."customers_snapshot"
                  ^

[0m06:26:00.376833 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: ROLLBACK
[0m06:26:00.379146 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 06:26:00.322865 => 06:26:00.378891
[0m06:26:00.379607 [debug] [Thread-4 (]: SQL status: SELECT 4291 in 0.0 seconds
[0m06:26:00.381312 [debug] [Thread-3 (]: On model.sales_analytics.dim_customer: Close
[0m06:26:00.385376 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.390686 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m06:26:00.392416 [debug] [Thread-3 (]: Database Error in model dim_customer (models/marts/dim_customer.sql)
  relation "snapshots.customers_snapshot" does not exist
  LINE 50:     from "warehouse"."snapshots"."customers_snapshot"
                    ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m06:26:00.394706 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:26:00.395732 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1dd05b10>]}
[0m06:26:00.402587 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.405074 [error] [Thread-3 (]: 2 of 4 ERROR creating sql table model analytics_marts.dim_customer ............. [[31mERROR[0m in 0.13s]
[0m06:26:00.406602 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m06:26:00.408229 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m06:26:00.410438 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m06:26:00.416193 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.418232 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m06:26:00.430093 [debug] [Thread-4 (]: SQL status: SELECT 12 in 0.0 seconds
[0m06:26:00.433682 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.435670 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:26:00.437572 [debug] [Thread-4 (]: SQL status: COMMENT in 0.0 seconds
[0m06:26:00.441051 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m06:26:00.442929 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.445061 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m06:26:00.452978 [debug] [Thread-4 (]: SQL status: COMMIT in 0.0 seconds
[0m06:26:00.457177 [debug] [Thread-4 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m06:26:00.461719 [debug] [Thread-4 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:26:00.463821 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m06:26:00.466352 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.0 seconds
[0m06:26:00.469307 [debug] [Thread-4 (]: Timing info for model.sales_analytics.orders_enriched (execute): 06:26:00.300486 => 06:26:00.469131
[0m06:26:00.471062 [debug] [Thread-4 (]: On model.sales_analytics.orders_enriched: Close
[0m06:26:00.474085 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1e96a490>]}
[0m06:26:00.476494 [info ] [Thread-4 (]: 3 of 4 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 4291[0m in 0.20s]
[0m06:26:00.478206 [debug] [Thread-4 (]: Finished running node model.sales_analytics.orders_enriched
[0m06:26:00.480067 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m06:26:00.481109 [info ] [Thread-1 (]: 4 of 4 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m06:26:00.482454 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now model.sales_analytics.fct_daily_sales)
[0m06:26:00.483594 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m06:26:00.494263 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m06:26:00.509236 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 06:26:00.485074 => 06:26:00.508850
[0m06:26:00.511128 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m06:26:00.545222 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m06:26:00.564636 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:26:00.566486 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m06:26:00.568324 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:26:00.576275 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:26:00.578554 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:26:00.580600 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
  
    

  create  table "warehouse"."analytics_marts"."fct_daily_sales"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
    group by 1
)
select * from base
  );
  
  
[0m06:26:00.615294 [debug] [Thread-1 (]: SQL status: SELECT 61 in 0.0 seconds
[0m06:26:00.620857 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:26:00.623225 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m06:26:00.625441 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:26:00.630652 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:26:00.632226 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m06:26:00.640489 [debug] [Thread-1 (]: SQL status: SELECT 4 in 0.0 seconds
[0m06:26:00.644445 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:26:00.646464 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:26:00.648650 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:26:00.652299 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:26:00.654010 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m06:26:00.665842 [debug] [Thread-1 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m06:26:00.667616 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m06:26:00.668497 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:26:00.669333 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m06:26:00.673824 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:26:00.675493 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 06:26:00.512616 => 06:26:00.675331
[0m06:26:00.676245 [debug] [Thread-1 (]: On model.sales_analytics.fct_daily_sales: Close
[0m06:26:00.677402 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '268101fe-ddd2-4e96-b232-48ab35a4b72f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1e5c4b10>]}
[0m06:26:00.678252 [info ] [Thread-1 (]: 4 of 4 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mSELECT 61[0m in 0.20s]
[0m06:26:00.679899 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m06:26:00.682626 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:00.683387 [debug] [MainThread]: On master: BEGIN
[0m06:26:00.684074 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:26:00.689637 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:26:00.691244 [debug] [MainThread]: On master: COMMIT
[0m06:26:00.692218 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:00.692913 [debug] [MainThread]: On master: COMMIT
[0m06:26:00.694113 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:26:00.697494 [debug] [MainThread]: On master: Close
[0m06:26:00.699283 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:26:00.699987 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m06:26:00.700740 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m06:26:00.701493 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m06:26:00.702169 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m06:26:00.706442 [info ] [MainThread]: 
[0m06:26:00.708294 [info ] [MainThread]: Finished running 1 view model, 2 table models, 1 incremental model in 0 hours 0 minutes and 0.99 seconds (0.99s).
[0m06:26:00.710947 [debug] [MainThread]: Command end result
[0m06:26:00.822986 [info ] [MainThread]: 
[0m06:26:00.824900 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m06:26:00.826434 [info ] [MainThread]: 
[0m06:26:00.827896 [error] [MainThread]:   Database Error in model dim_customer (models/marts/dim_customer.sql)
  relation "snapshots.customers_snapshot" does not exist
  LINE 50:     from "warehouse"."snapshots"."customers_snapshot"
                    ^
  compiled Code at target/run/sales_analytics/models/marts/dim_customer.sql
[0m06:26:00.829563 [info ] [MainThread]: 
[0m06:26:00.831258 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m06:26:00.833948 [debug] [MainThread]: Resource report: {"command_name": "run", "command_wall_clock_time": 1.6625825, "process_user_time": 3.369932, "process_kernel_time": 0.121804, "process_mem_max_rss": "123884", "command_success": false, "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:26:00.836519 [debug] [MainThread]: Command `dbt run` failed at 06:26:00.836102 after 1.67 seconds
[0m06:26:00.838489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1f63f0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f1f63f550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0f2417b9d0>]}
[0m06:26:00.840698 [debug] [MainThread]: Flushing usage events
[0m06:26:05.872930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e19445550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e1942f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e1942e310>]}


============================== 06:26:05.880406 | eb6867ce-36c8-4c96-be6f-806e35844fac ==============================
[0m06:26:05.880406 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:26:05.881608 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt docs generate', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m06:26:06.075359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eb6867ce-36c8-4c96-be6f-806e35844fac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e18b1e110>]}
[0m06:26:06.166118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eb6867ce-36c8-4c96-be6f-806e35844fac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e18bf6190>]}
[0m06:26:06.168301 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:26:06.184035 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:26:06.382608 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:26:06.383856 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:26:06.390616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb6867ce-36c8-4c96-be6f-806e35844fac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e18369290>]}
[0m06:26:06.400687 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb6867ce-36c8-4c96-be6f-806e35844fac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e1839f7d0>]}
[0m06:26:06.401694 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:26:06.403201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb6867ce-36c8-4c96-be6f-806e35844fac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e1ca0a0d0>]}
[0m06:26:06.407072 [info ] [MainThread]: 
[0m06:26:06.409155 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:26:06.412461 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:26:06.414116 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:26:06.415310 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:26:06.422329 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:26:06.432467 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:26:06.436359 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:26:06.439216 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:26:06.442581 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:26:06.444305 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:26:06.446000 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:26:06.447499 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:26:06.448923 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:26:06.449951 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:06.451162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:06.453913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:06.455448 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:06.468252 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:26:06.471117 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:26:06.472763 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:26:06.476367 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:26:06.479034 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:26:06.480633 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:26:06.484814 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:26:06.486766 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:26:06.487143 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:26:06.488415 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:26:06.489888 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:26:06.490182 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:26:06.492924 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:26:06.493886 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:26:06.494630 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:26:06.498299 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:26:06.498821 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:26:06.500196 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:26:06.502066 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:26:06.503900 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:26:06.508709 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:26:06.509243 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:26:06.511494 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:26:06.515278 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:26:06.522397 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:06.524078 [debug] [MainThread]: On master: BEGIN
[0m06:26:06.525428 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:26:06.532696 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:26:06.534245 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:06.535154 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:26:06.539022 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:26:06.541116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb6867ce-36c8-4c96-be6f-806e35844fac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e183831d0>]}
[0m06:26:06.542177 [debug] [MainThread]: On master: ROLLBACK
[0m06:26:06.543390 [debug] [MainThread]: On master: Close
[0m06:26:06.544823 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:26:06.545694 [info ] [MainThread]: 
[0m06:26:06.556388 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m06:26:06.557988 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.src_orders)
[0m06:26:06.559240 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m06:26:06.568306 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m06:26:06.583905 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 06:26:06.560303 => 06:26:06.583234
[0m06:26:06.586377 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m06:26:06.588258 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 06:26:06.587995 => 06:26:06.588016
[0m06:26:06.590393 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m06:26:06.593245 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m06:26:06.593989 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m06:26:06.594481 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:26:06.595077 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:26:06.596227 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.orders_enriched)
[0m06:26:06.598203 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now snapshot.sales_analytics.customers_snapshot)
[0m06:26:06.600083 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m06:26:06.603965 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m06:26:06.606085 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m06:26:06.607647 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m06:26:06.609951 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:26:06.612104 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:26:06.618023 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m06:26:06.623270 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 06:26:06.619933 => 06:26:06.623010
[0m06:26:06.638096 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:26:06.643103 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:26:06.647773 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m06:26:06.651410 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 06:26:06.651084 => 06:26:06.651111
[0m06:26:06.653613 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m06:26:06.655850 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:26:06.656937 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 06:26:06.613897 => 06:26:06.656437
[0m06:26:06.658093 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 06:26:06.625337 => 06:26:06.657719
[0m06:26:06.658998 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 06:26:06.639192 => 06:26:06.658698
[0m06:26:06.659979 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m06:26:06.662236 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m06:26:06.664415 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:26:06.666709 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:26:06.668887 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:26:06.670936 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 06:26:06.670627 => 06:26:06.670642
[0m06:26:06.672919 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 06:26:06.672685 => 06:26:06.672714
[0m06:26:06.675181 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 06:26:06.675006 => 06:26:06.675015
[0m06:26:06.681277 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:26:06.683830 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m06:26:06.686278 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:26:06.689164 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:26:06.693611 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:26:06.695698 [debug] [Thread-2 (]: Began running node model.sales_analytics.dim_customer
[0m06:26:06.697601 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m06:26:06.699478 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m06:26:06.701685 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.dim_customer)
[0m06:26:06.703892 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m06:26:06.705380 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:26:06.706916 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.dim_customer
[0m06:26:06.707679 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 06:26:06.677227 => 06:26:06.707338
[0m06:26:06.709191 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m06:26:06.718023 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:26:06.723475 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m06:26:06.725626 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:26:06.739302 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m06:26:06.742869 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 06:26:06.742471 => 06:26:06.742493
[0m06:26:06.746380 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:26:06.747956 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:26:06.749821 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m06:26:06.751335 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:26:06.758903 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 06:26:06.710828 => 06:26:06.758472
[0m06:26:06.759642 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (compile): 06:26:06.719554 => 06:26:06.759296
[0m06:26:06.760160 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 06:26:06.727169 => 06:26:06.759917
[0m06:26:06.761670 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:26:06.763079 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:26:06.764625 [debug] [Thread-2 (]: Began executing node model.sales_analytics.dim_customer
[0m06:26:06.766271 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m06:26:06.769113 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 06:26:06.768865 => 06:26:06.768880
[0m06:26:06.771019 [debug] [Thread-2 (]: Timing info for model.sales_analytics.dim_customer (execute): 06:26:06.770606 => 06:26:06.770625
[0m06:26:06.772591 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 06:26:06.772355 => 06:26:06.772365
[0m06:26:06.774859 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:26:06.776978 [debug] [Thread-2 (]: Finished running node model.sales_analytics.dim_customer
[0m06:26:06.779135 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m06:26:06.782870 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:26:06.785329 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 06:26:06.753192 => 06:26:06.785046
[0m06:26:06.786346 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:26:06.786737 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:26:06.787501 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m06:26:06.789799 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:26:06.792558 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m06:26:06.795135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m06:26:06.797206 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:26:06.799177 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 06:26:06.799012 => 06:26:06.799019
[0m06:26:06.801475 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:26:06.803905 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:26:06.812982 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:26:06.816036 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:26:06.826211 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:26:06.836025 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:26:06.840767 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:26:06.847920 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m06:26:06.850395 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:26:06.858410 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 06:26:06.805946 => 06:26:06.857984
[0m06:26:06.859191 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:26:06.859868 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 06:26:06.818702 => 06:26:06.859636
[0m06:26:06.861008 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:26:06.862486 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 06:26:06.828630 => 06:26:06.862206
[0m06:26:06.863977 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:26:06.865943 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 06:26:06.865605 => 06:26:06.865621
[0m06:26:06.867223 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:26:06.869260 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 06:26:06.868929 => 06:26:06.868942
[0m06:26:06.872177 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:26:06.874497 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 06:26:06.874169 => 06:26:06.874183
[0m06:26:06.877049 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:26:06.878866 [debug] [Thread-3 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:26:06.879864 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 06:26:06.852610 => 06:26:06.879520
[0m06:26:06.882182 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:26:06.886005 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m06:26:06.888032 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:26:06.891738 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:26:06.893834 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 06:26:06.893578 => 06:26:06.893588
[0m06:26:06.902957 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:26:06.905370 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:26:06.934131 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 06:26:06.895638 => 06:26:06.933706
[0m06:26:06.936568 [debug] [Thread-3 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:26:06.938942 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 06:26:06.938667 => 06:26:06.938678
[0m06:26:06.941857 [debug] [Thread-3 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:26:06.946300 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:26:06.948253 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m06:26:06.950336 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m06:26:06.952443 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m06:26:06.954580 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m06:26:06.960068 [debug] [MainThread]: Command end result
[0m06:26:07.026579 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m06:26:07.028033 [info ] [MainThread]: Building catalog
[0m06:26:07.031464 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m06:26:07.041753 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m06:26:07.043140 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m06:26:07.044495 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:07.056944 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:26:07.058513 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m06:26:07.059869 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m06:26:07.064262 [debug] [ThreadPool]: SQL status: SELECT 27 in 0.0 seconds
[0m06:26:07.070334 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m06:26:07.072337 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m06:26:07.110746 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m06:26:07.112901 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.2956519, "process_user_time": 3.06811, "process_kernel_time": 0.230609, "process_mem_max_rss": "121484", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:26:07.114299 [debug] [MainThread]: Command `dbt docs generate` succeeded at 06:26:07.114157 after 1.30 seconds
[0m06:26:07.115387 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m06:26:07.116414 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m06:26:07.117506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e1948b590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e1948b910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4e1ac8ba10>]}
[0m06:26:07.119035 [debug] [MainThread]: Flushing usage events
[0m06:29:02.106364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab185d0a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab185d2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab185d2b90>]}


============================== 06:29:02.113374 | 592a54c3-1dfd-482c-8fc8-dd75ab179643 ==============================
[0m06:29:02.113374 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:29:02.115168 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:29:02.205156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '592a54c3-1dfd-482c-8fc8-dd75ab179643', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab18688a50>]}
[0m06:29:02.209418 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:29:02.218455 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:29:02.220146 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.16752289, "process_user_time": 2.582988, "process_kernel_time": 0.079783, "process_mem_max_rss": "105116", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:29:02.221223 [debug] [MainThread]: Command `dbt deps` succeeded at 06:29:02.221052 after 0.17 seconds
[0m06:29:02.222196 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab185d26d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab18623dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab18622750>]}
[0m06:29:02.223216 [debug] [MainThread]: Flushing usage events
[0m06:29:05.462544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc030a13b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0309fe810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc030a122d0>]}


============================== 06:29:05.471377 | ca3b6a15-9080-4bca-b41e-ff27e0728e94 ==============================
[0m06:29:05.471377 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:29:05.472844 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select staging intermediate', 'send_anonymous_usage_stats': 'True'}
[0m06:29:05.658311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02fd15950>]}
[0m06:29:05.750768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02fd01c90>]}
[0m06:29:05.752260 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:29:05.767171 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:29:05.978257 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:29:05.979972 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:29:05.989655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0309fef50>]}
[0m06:29:06.034757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02fdc1b50>]}
[0m06:29:06.036718 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:29:06.038027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02fdfba10>]}
[0m06:29:06.041710 [info ] [MainThread]: 
[0m06:29:06.043757 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:29:06.049463 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:29:06.052820 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:29:06.072507 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:29:06.076462 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:29:06.078387 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:29:06.080859 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:29:06.083420 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:06.085031 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:06.097348 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m06:29:06.097937 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m06:29:06.100091 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:29:06.101962 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:29:06.106408 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_intermediate)
[0m06:29:06.107410 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_snapshots)
[0m06:29:06.108331 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:29:06.109649 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:29:06.117465 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:06.119993 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:06.123202 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:06.126377 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:06.127825 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:29:06.128727 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:29:06.129659 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:29:06.130919 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:29:06.132284 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:29:06.133220 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:29:06.134145 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:06.135510 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:06.144148 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.145576 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.145977 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:06.146378 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.147310 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.148529 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:06.150220 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:29:06.152239 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:06.154528 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:06.156902 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:29:06.161385 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:29:06.162629 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:06.164709 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:29:06.170043 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:29:06.172743 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:29:06.173518 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:06.177414 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:29:06.178298 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:06.180405 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:29:06.182725 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:29:06.184785 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:29:06.187501 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:29:06.191777 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:29:06.195333 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:29:06.203935 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:06.205792 [debug] [MainThread]: On master: BEGIN
[0m06:29:06.207470 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:29:06.217433 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.219454 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:06.221444 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:29:06.229277 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:06.232349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02fd9ff90>]}
[0m06:29:06.234565 [debug] [MainThread]: On master: ROLLBACK
[0m06:29:06.236944 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:06.239038 [debug] [MainThread]: On master: BEGIN
[0m06:29:06.242172 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.244459 [debug] [MainThread]: On master: COMMIT
[0m06:29:06.246668 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:06.248855 [debug] [MainThread]: On master: COMMIT
[0m06:29:06.251697 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:06.253965 [debug] [MainThread]: On master: Close
[0m06:29:06.256958 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:29:06.258581 [info ] [MainThread]: 
[0m06:29:06.272020 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m06:29:06.273963 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m06:29:06.275613 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m06:29:06.276603 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m06:29:06.285356 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m06:29:06.296967 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 06:29:06.277376 => 06:29:06.296624
[0m06:29:06.298339 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m06:29:06.345358 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m06:29:06.360624 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.362423 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m06:29:06.364030 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:29:06.370857 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.372376 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.373493 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m06:29:06.375939 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m06:29:06.382769 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.384342 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders" rename to "src_orders__dbt_backup"
[0m06:29:06.386501 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:29:06.390323 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.391715 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m06:29:06.394221 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:29:06.417770 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.419550 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m06:29:06.421966 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:06.434873 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.436644 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m06:29:06.446350 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m06:29:06.451533 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.452548 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:29:06.453542 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:06.455212 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m06:29:06.456142 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.456795 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m06:29:06.460934 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:29:06.467816 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m06:29:06.473205 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:29:06.474139 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m06:29:06.478526 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m06:29:06.480731 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 06:29:06.299580 => 06:29:06.480554
[0m06:29:06.481687 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m06:29:06.482918 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02f55f710>]}
[0m06:29:06.483894 [info ] [Thread-1 (]: 1 of 2 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 0.21s]
[0m06:29:06.485355 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m06:29:06.487256 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m06:29:06.488269 [info ] [Thread-3 (]: 2 of 2 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m06:29:06.490772 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.orders_enriched)
[0m06:29:06.492167 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m06:29:06.495638 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m06:29:06.507335 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 06:29:06.492788 => 06:29:06.506819
[0m06:29:06.512328 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m06:29:06.541066 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m06:29:06.554890 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.556459 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m06:29:06.557871 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:29:06.565149 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.566750 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.568248 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m06:29:06.581128 [debug] [Thread-3 (]: SQL status: SELECT 8582 in 0.0 seconds
[0m06:29:06.586803 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.588628 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched" rename to "orders_enriched__dbt_backup"
[0m06:29:06.590652 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:29:06.594550 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.596059 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m06:29:06.597902 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:29:06.605246 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.606745 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m06:29:06.608203 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:06.612877 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.614351 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m06:29:06.620891 [debug] [Thread-3 (]: SQL status: SELECT 12 in 0.0 seconds
[0m06:29:06.623806 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.625180 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:29:06.626926 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:06.628866 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m06:29:06.630451 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.631800 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m06:29:06.649687 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m06:29:06.654996 [debug] [Thread-3 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m06:29:06.659801 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:29:06.661522 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m06:29:06.667413 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m06:29:06.670726 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 06:29:06.513560 => 06:29:06.670300
[0m06:29:06.671949 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: Close
[0m06:29:06.673685 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca3b6a15-9080-4bca-b41e-ff27e0728e94', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02f134890>]}
[0m06:29:06.674882 [info ] [Thread-3 (]: 2 of 2 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 8582[0m in 0.18s]
[0m06:29:06.676454 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m06:29:06.679122 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:06.679850 [debug] [MainThread]: On master: BEGIN
[0m06:29:06.680563 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:29:06.685998 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:06.686902 [debug] [MainThread]: On master: COMMIT
[0m06:29:06.687613 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:06.688330 [debug] [MainThread]: On master: COMMIT
[0m06:29:06.689122 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:06.689848 [debug] [MainThread]: On master: Close
[0m06:29:06.691000 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:29:06.691697 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m06:29:06.693306 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m06:29:06.694594 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m06:29:06.695775 [debug] [MainThread]: Connection 'model.sales_analytics.src_orders' was properly closed.
[0m06:29:06.696693 [info ] [MainThread]: 
[0m06:29:06.697971 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 0.65 seconds (0.65s).
[0m06:29:06.700502 [debug] [MainThread]: Command end result
[0m06:29:06.745615 [info ] [MainThread]: 
[0m06:29:06.748533 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:29:06.749692 [info ] [MainThread]: 
[0m06:29:06.750830 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m06:29:06.753398 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3576546, "process_user_time": 3.251282, "process_kernel_time": 0.161054, "process_mem_max_rss": "122392", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:29:06.755105 [debug] [MainThread]: Command `dbt run` succeeded at 06:29:06.754945 after 1.36 seconds
[0m06:29:06.756495 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc0315dcfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc02fd81450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc030d3bcd0>]}
[0m06:29:06.757756 [debug] [MainThread]: Flushing usage events
[0m06:29:09.909112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c5810710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c57f2f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c8302950>]}


============================== 06:29:09.918343 | cfb18687-32a7-419d-8c71-8c1d54e31d7d ==============================
[0m06:29:09.918343 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:29:09.919724 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt snapshot', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:29:10.102324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cfb18687-32a7-419d-8c71-8c1d54e31d7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c4d48790>]}
[0m06:29:10.197076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cfb18687-32a7-419d-8c71-8c1d54e31d7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c6c02ad0>]}
[0m06:29:10.199717 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:29:10.222075 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:29:10.467591 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:29:10.469576 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:29:10.477537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cfb18687-32a7-419d-8c71-8c1d54e31d7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c459c910>]}
[0m06:29:10.516617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cfb18687-32a7-419d-8c71-8c1d54e31d7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c5649490>]}
[0m06:29:10.518398 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:29:10.519829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cfb18687-32a7-419d-8c71-8c1d54e31d7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c4da5d10>]}
[0m06:29:10.523238 [info ] [MainThread]: 
[0m06:29:10.526085 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:29:10.529412 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:29:10.547265 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:29:10.549432 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:29:10.551554 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:10.562080 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m06:29:10.565041 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:29:10.568106 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m06:29:10.569985 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m06:29:10.578175 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m06:29:10.579923 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m06:29:10.581408 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:29:10.589056 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.590851 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m06:29:10.592534 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m06:29:10.594714 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:29:10.596942 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m06:29:10.598709 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m06:29:10.600327 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m06:29:10.605760 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:29:10.607824 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m06:29:10.612057 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_snapshots)
[0m06:29:10.613068 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:29:10.614056 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:29:10.615270 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:29:10.620866 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:10.624419 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:10.628558 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:10.631148 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:10.631973 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:29:10.632696 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:29:10.633392 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:29:10.634083 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:29:10.634742 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:29:10.635421 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:10.636072 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:10.636796 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:10.643920 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.644834 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.646344 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.646795 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:10.647744 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.648472 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:10.649499 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:10.650452 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:29:10.651688 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:10.652991 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:29:10.654084 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:29:10.655922 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:29:10.659653 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:29:10.663245 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:29:10.664039 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:10.664538 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:10.665148 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:10.666447 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:29:10.668686 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:29:10.671237 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:29:10.673355 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:29:10.676823 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:29:10.678181 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:29:10.679487 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:29:10.688123 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:10.689772 [debug] [MainThread]: On master: BEGIN
[0m06:29:10.691312 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:29:10.698919 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.700541 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:10.702246 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:29:10.708681 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:10.712088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cfb18687-32a7-419d-8c71-8c1d54e31d7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c496be90>]}
[0m06:29:10.714019 [debug] [MainThread]: On master: ROLLBACK
[0m06:29:10.715911 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:10.717575 [debug] [MainThread]: On master: BEGIN
[0m06:29:10.719850 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.721954 [debug] [MainThread]: On master: COMMIT
[0m06:29:10.724453 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:10.726844 [debug] [MainThread]: On master: COMMIT
[0m06:29:10.729804 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:10.732306 [debug] [MainThread]: On master: Close
[0m06:29:10.735473 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:29:10.737352 [info ] [MainThread]: 
[0m06:29:10.748168 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m06:29:10.750183 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m06:29:10.751890 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now snapshot.sales_analytics.customers_snapshot)
[0m06:29:10.753103 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m06:29:10.763123 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 06:29:10.754462 => 06:29:10.762758
[0m06:29:10.765199 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m06:29:10.827362 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m06:29:10.841638 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m06:29:10.843621 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m06:29:10.845268 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:29:10.852088 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.853095 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m06:29:10.854125 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m06:29:10.913762 [debug] [Thread-1 (]: SQL status: SELECT 10000 in 0.0 seconds
[0m06:29:10.937139 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m06:29:10.938842 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m06:29:10.941010 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m06:29:10.963238 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:29:10.967304 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 06:29:10.766699 => 06:29:10.966521
[0m06:29:10.969569 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m06:29:10.972200 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfb18687-32a7-419d-8c71-8c1d54e31d7d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c4199a90>]}
[0m06:29:10.976854 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSELECT 10000[0m in 0.22s]
[0m06:29:10.979301 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m06:29:10.982133 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:10.983399 [debug] [MainThread]: On master: BEGIN
[0m06:29:10.984233 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:29:10.991779 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:10.992850 [debug] [MainThread]: On master: COMMIT
[0m06:29:10.993690 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:10.994460 [debug] [MainThread]: On master: COMMIT
[0m06:29:10.995339 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:10.996090 [debug] [MainThread]: On master: Close
[0m06:29:10.997346 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:29:10.998029 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m06:29:10.998963 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m06:29:11.000020 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m06:29:11.000953 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m06:29:11.002067 [info ] [MainThread]: 
[0m06:29:11.003222 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m06:29:11.005229 [debug] [MainThread]: Command end result
[0m06:29:11.046776 [info ] [MainThread]: 
[0m06:29:11.048144 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:29:11.049690 [info ] [MainThread]: 
[0m06:29:11.051544 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m06:29:11.053500 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 1.1965437, "process_user_time": 3.113088, "process_kernel_time": 0.139689, "process_mem_max_rss": "122184", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:29:11.056876 [debug] [MainThread]: Command `dbt snapshot` succeeded at 06:29:11.056571 after 1.20 seconds
[0m06:29:11.058987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2c6c02b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ca1e3d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa2ca1e3990>]}
[0m06:29:11.060878 [debug] [MainThread]: Flushing usage events
[0m06:29:14.624784 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f811488ed90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8114872790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f811487add0>]}


============================== 06:29:14.641934 | 67519ce8-b134-4c0d-a006-a6f622e419e3 ==============================
[0m06:29:14.641934 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:29:14.644146 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --select marts', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:29:14.964763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8113f1edd0>]}
[0m06:29:15.118725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8113fcda50>]}
[0m06:29:15.121335 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:29:15.150704 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:29:15.404089 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:29:15.405520 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:29:15.415585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81143158d0>]}
[0m06:29:15.454887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8113f6f890>]}
[0m06:29:15.456370 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:29:15.458299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8113fcdc50>]}
[0m06:29:15.462299 [info ] [MainThread]: 
[0m06:29:15.465448 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:29:15.469362 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:29:15.488937 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:29:15.491327 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:29:15.493657 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:15.507425 [debug] [ThreadPool]: SQL status: SELECT 14 in 0.0 seconds
[0m06:29:15.511402 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:29:15.516348 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now list_warehouse_analytics_staging)
[0m06:29:15.518196 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:29:15.519998 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:29:15.522862 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:29:15.532732 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:15.537074 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:15.542013 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:15.546454 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:15.548367 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:29:15.550522 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:29:15.552776 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:29:15.555009 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:29:15.557542 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:29:15.560168 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:15.562938 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:15.566021 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:15.578462 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:15.580053 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:15.580811 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:15.581436 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:15.583070 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:15.583759 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:15.586714 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:29:15.588991 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:15.591405 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:15.593779 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:29:15.597469 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:29:15.599678 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:29:15.600327 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:15.607745 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:29:15.608563 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:15.609308 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:15.613881 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:15.616515 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:29:15.619251 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:29:15.623053 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:29:15.626370 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:29:15.630756 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:29:15.632411 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:29:15.633860 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:29:15.647966 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:15.650442 [debug] [MainThread]: On master: BEGIN
[0m06:29:15.652520 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:29:15.662992 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:15.665015 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:15.666853 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:29:15.673916 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:15.677656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8113fd8150>]}
[0m06:29:15.679825 [debug] [MainThread]: On master: ROLLBACK
[0m06:29:15.682186 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:15.684008 [debug] [MainThread]: On master: BEGIN
[0m06:29:15.686605 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:15.688294 [debug] [MainThread]: On master: COMMIT
[0m06:29:15.690011 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:15.691946 [debug] [MainThread]: On master: COMMIT
[0m06:29:15.694044 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:15.695834 [debug] [MainThread]: On master: Close
[0m06:29:15.698261 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:29:15.699764 [info ] [MainThread]: 
[0m06:29:15.714941 [debug] [Thread-1 (]: Began running node model.sales_analytics.dim_customer
[0m06:29:15.715828 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m06:29:15.717656 [info ] [Thread-1 (]: 1 of 2 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m06:29:15.720023 [info ] [Thread-2 (]: 2 of 2 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m06:29:15.724798 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.dim_customer)
[0m06:29:15.728786 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.fct_daily_sales)
[0m06:29:15.731365 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.dim_customer
[0m06:29:15.733207 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m06:29:15.749833 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m06:29:15.771075 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m06:29:15.784458 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 06:29:15.751050 => 06:29:15.783693
[0m06:29:15.786254 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (compile): 06:29:15.734957 => 06:29:15.785539
[0m06:29:15.787862 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m06:29:15.790222 [debug] [Thread-1 (]: Began executing node model.sales_analytics.dim_customer
[0m06:29:15.951448 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m06:29:15.953583 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:15.957478 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
    

  create temporary table "fct_daily_sales__dbt_tmp062915879564"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
      and date_trunc('day', order_ts)::date >= (
        coalesce( (select max(sales_date) from "warehouse"."analytics_marts"."fct_daily_sales"), '1900-01-01'::date )
        - interval '2 day'
      )
    
    group by 1
)
select * from base
  );
  
  
[0m06:29:15.960150 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:29:15.974819 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:15.977817 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: BEGIN
[0m06:29:15.980311 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:29:15.992344 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:15.994173 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:15.996109 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- 

-- with current as (
--     select *
--     from "warehouse"."snapshots"."customers_snapshot"
--     where dbt_valid_to is null
-- ),

-- deduped as (
--     select
--         customer_id,
--         country,
--         status,
--         dbt_valid_from,
--         row_number() over (
--             partition by customer_id
--             order by dbt_valid_from desc
--         ) as rn
--     from current
-- )

-- select
--     customer_id,
--     country,
--     status,
--     dbt_valid_from as valid_from
-- from deduped
-- where rn = 1



with snapshot_data as (
    select
        customer_id,
        country,
        status,
        dbt_valid_from,
        dbt_valid_to
    from "warehouse"."snapshots"."customers_snapshot"
)

select
    customer_id,
    country,
    status,
    dbt_valid_from as valid_from,
    dbt_valid_to   as valid_to,
    case when dbt_valid_to is null then true else false end as is_current
from snapshot_data
order by customer_id, dbt_valid_from
  );
  
[0m06:29:15.996919 [debug] [Thread-2 (]: SQL status: SELECT 3 in 0.0 seconds
[0m06:29:16.012394 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.014244 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m06:29:16.016382 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:16.017977 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.019556 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp062915879564'
        
      order by ordinal_position

  
[0m06:29:16.020546 [debug] [Thread-1 (]: SQL status: SELECT 10000 in 0.0 seconds
[0m06:29:16.034014 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:16.034787 [debug] [Thread-2 (]: SQL status: SELECT 4 in 0.0 seconds
[0m06:29:16.037146 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
alter table "warehouse"."analytics_marts"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m06:29:16.048461 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.051686 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:29:16.053093 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m06:29:16.090985 [debug] [Thread-2 (]: SQL status: SELECT 4 in 0.0 seconds
[0m06:29:16.099236 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:16.123184 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  comment on table "warehouse"."analytics_marts"."dim_customer" is $dbt_comment_literal_block$Current SCD2 customer dimension from snapshots$dbt_comment_literal_block$;

  
[0m06:29:16.125892 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.128112 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:16.129242 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales__dbt_tmp062915879564'
        
      order by ordinal_position

  
[0m06:29:16.145925 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:16.148509 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m06:29:16.152686 [debug] [Thread-2 (]: SQL status: SELECT 4 in 0.0 seconds
[0m06:29:16.161181 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.162741 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m06:29:16.163703 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m06:29:16.169811 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:16.170583 [debug] [Thread-2 (]: SQL status: SELECT 4 in 0.0 seconds
[0m06:29:16.171923 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".customer_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".status is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".country is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".valid_from is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:29:16.188314 [debug] [Thread-2 (]: 
    In "warehouse"."analytics_marts"."fct_daily_sales":
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m06:29:16.190423 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:16.214598 [debug] [Thread-2 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m06:29:16.216444 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: COMMIT
[0m06:29:16.220913 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:16.223140 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: COMMIT
[0m06:29:16.237252 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.239096 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
        
            delete from "warehouse"."analytics_marts"."fct_daily_sales"
            where (
                sales_date) in (
                select (sales_date)
                from "fct_daily_sales__dbt_tmp062915879564"
            );

        
    

    insert into "warehouse"."analytics_marts"."fct_daily_sales" ("sales_date", "orders", "units_sold", "gross_revenue")
    (
        select "sales_date", "orders", "units_sold", "gross_revenue"
        from "fct_daily_sales__dbt_tmp062915879564"
    )
  
[0m06:29:16.242415 [debug] [Thread-2 (]: SQL status: INSERT 0 3 in 0.0 seconds
[0m06:29:16.243944 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:29:16.247351 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.260408 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_marts"."dim_customer__dbt_backup"
[0m06:29:16.262393 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m06:29:16.273029 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:29:16.275529 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:16.277560 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
drop table if exists "warehouse"."analytics_marts"."dim_customer__dbt_backup" cascade
[0m06:29:16.284672 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.287744 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m06:29:16.289115 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m06:29:16.293225 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (execute): 06:29:15.815660 => 06:29:16.292889
[0m06:29:16.297741 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: Close
[0m06:29:16.300361 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f811331fed0>]}
[0m06:29:16.300988 [debug] [Thread-2 (]: SQL status: SELECT 4 in 0.0 seconds
[0m06:29:16.302834 [info ] [Thread-1 (]: 1 of 2 OK created sql table model analytics_marts.dim_customer ................. [[32mSELECT 10000[0m in 0.58s]
[0m06:29:16.307325 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.309099 [debug] [Thread-1 (]: Finished running node model.sales_analytics.dim_customer
[0m06:29:16.311033 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:29:16.316229 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m06:29:16.322065 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.323968 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m06:29:16.362138 [debug] [Thread-2 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m06:29:16.397157 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m06:29:16.403897 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:29:16.406214 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m06:29:16.427661 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m06:29:16.431568 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 06:29:15.792983 => 06:29:16.431261
[0m06:29:16.434405 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: Close
[0m06:29:16.437947 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '67519ce8-b134-4c0d-a006-a6f622e419e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8113f8aed0>]}
[0m06:29:16.441242 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mINSERT 0 3[0m in 0.71s]
[0m06:29:16.443883 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m06:29:16.449213 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:16.451477 [debug] [MainThread]: On master: BEGIN
[0m06:29:16.454058 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:29:16.466945 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:16.471945 [debug] [MainThread]: On master: COMMIT
[0m06:29:16.474693 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:16.476979 [debug] [MainThread]: On master: COMMIT
[0m06:29:16.480296 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:16.482741 [debug] [MainThread]: On master: Close
[0m06:29:16.485699 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:29:16.487876 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m06:29:16.490426 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m06:29:16.492852 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m06:29:16.495678 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m06:29:16.498669 [info ] [MainThread]: 
[0m06:29:16.500446 [info ] [MainThread]: Finished running 1 table model, 1 incremental model in 0 hours 0 minutes and 1.03 seconds (1.03s).
[0m06:29:16.503080 [debug] [MainThread]: Command end result
[0m06:29:16.553842 [info ] [MainThread]: 
[0m06:29:16.556494 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:29:16.560277 [info ] [MainThread]: 
[0m06:29:16.562696 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m06:29:16.565511 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.0460274, "process_user_time": 4.146112, "process_kernel_time": 0.229784, "process_mem_max_rss": "123220", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:29:16.568348 [debug] [MainThread]: Command `dbt run` succeeded at 06:29:16.568075 after 2.05 seconds
[0m06:29:16.570631 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8113f8aed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f811940fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f811940fa50>]}
[0m06:29:16.574607 [debug] [MainThread]: Flushing usage events
[0m06:29:20.997925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa596d370d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5971efbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa596d36f50>]}


============================== 06:29:21.007930 | fe7beb42-c77c-4a74-9912-86d682a93393 ==============================
[0m06:29:21.007930 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:29:21.011665 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt test', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m06:29:21.291133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fe7beb42-c77c-4a74-9912-86d682a93393', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa596149310>]}
[0m06:29:21.429681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fe7beb42-c77c-4a74-9912-86d682a93393', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa597125cd0>]}
[0m06:29:21.432915 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:29:21.465041 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:29:21.713392 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:29:21.714709 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:29:21.724234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fe7beb42-c77c-4a74-9912-86d682a93393', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5959ea8d0>]}
[0m06:29:21.760839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fe7beb42-c77c-4a74-9912-86d682a93393', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa595dae010>]}
[0m06:29:21.762764 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:29:21.764645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe7beb42-c77c-4a74-9912-86d682a93393', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa59612a5d0>]}
[0m06:29:21.770267 [info ] [MainThread]: 
[0m06:29:21.773869 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:29:21.778091 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:29:21.783680 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:29:21.786266 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:29:21.787762 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:29:21.807855 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:21.811125 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:21.817605 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:21.822573 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:21.824936 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:29:21.827453 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:29:21.829252 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:29:21.831919 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:29:21.834550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:21.837078 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:21.839502 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:21.841510 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:21.854388 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:21.855277 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:21.855931 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:21.856973 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:21.857617 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:21.858982 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:21.860963 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:21.863214 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:29:21.865887 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:21.868215 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:29:21.870962 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:29:21.875397 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:29:21.877375 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m06:29:21.881598 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:21.884749 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:29:21.885541 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:21.886126 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:21.889237 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:29:21.892172 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:29:21.894557 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:29:21.898368 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:29:21.900935 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:29:21.904567 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:29:21.907051 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:29:21.919786 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:21.921790 [debug] [MainThread]: On master: BEGIN
[0m06:29:21.923952 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:29:21.935737 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:21.938430 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:21.940885 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:29:21.949379 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:21.953994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe7beb42-c77c-4a74-9912-86d682a93393', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5986eba50>]}
[0m06:29:21.956918 [debug] [MainThread]: On master: ROLLBACK
[0m06:29:21.959871 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:21.962419 [debug] [MainThread]: On master: BEGIN
[0m06:29:21.965792 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:21.968379 [debug] [MainThread]: On master: COMMIT
[0m06:29:21.971062 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:21.973851 [debug] [MainThread]: On master: COMMIT
[0m06:29:21.977020 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:21.979529 [debug] [MainThread]: On master: Close
[0m06:29:21.981773 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:29:21.984291 [info ] [MainThread]: 
[0m06:29:22.004106 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:22.005403 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:22.006226 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:22.007292 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:22.008773 [info ] [Thread-1 (]: 1 of 10 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m06:29:22.010837 [info ] [Thread-2 (]: 2 of 10 START test not_null_fct_daily_sales_gross_revenue ...................... [RUN]
[0m06:29:22.013234 [info ] [Thread-3 (]: 3 of 10 START test not_null_fct_daily_sales_orders ............................. [RUN]
[0m06:29:22.016117 [info ] [Thread-4 (]: 4 of 10 START test not_null_fct_daily_sales_sales_date ......................... [RUN]
[0m06:29:22.019448 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m06:29:22.022486 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m06:29:22.025705 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m06:29:22.028360 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m06:29:22.030374 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:22.032476 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:22.036020 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:22.038564 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:22.084534 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:29:22.085757 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:29:22.093901 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:29:22.102202 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:29:22.132015 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 06:29:22.087006 => 06:29:22.131409
[0m06:29:22.132990 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 06:29:22.095493 => 06:29:22.132461
[0m06:29:22.134126 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 06:29:22.064419 => 06:29:22.133641
[0m06:29:22.135639 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:22.137521 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:22.138722 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 06:29:22.040796 => 06:29:22.138272
[0m06:29:22.141110 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:22.171868 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:29:22.172489 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:29:22.175610 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:22.181806 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:29:22.193836 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:29:22.226162 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:29:22.229183 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: BEGIN
[0m06:29:22.230282 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:29:22.232116 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m06:29:22.233707 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:29:22.235117 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: BEGIN
[0m06:29:22.237165 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:29:22.240366 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m06:29:22.242350 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:29:22.244085 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: BEGIN
[0m06:29:22.246148 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:29:22.247732 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.251238 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:29:22.255335 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:29:22.258792 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.259998 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sales_date
from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is null



      
    ) dbt_internal_test
[0m06:29:22.262200 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:29:22.262984 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.266228 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.267178 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select gross_revenue
from "warehouse"."analytics_marts"."fct_daily_sales"
where gross_revenue is null



      
    ) dbt_internal_test
[0m06:29:22.267944 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.271117 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:29:22.276915 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 06:29:22.168325 => 06:29:22.276545
[0m06:29:22.280871 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.281614 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:29:22.284452 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "warehouse"."analytics_marts"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m06:29:22.287660 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: ROLLBACK
[0m06:29:22.292654 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 06:29:22.178331 => 06:29:22.292273
[0m06:29:22.295540 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orders
from "warehouse"."analytics_marts"."fct_daily_sales"
where orders is null



      
    ) dbt_internal_test
[0m06:29:22.300872 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: Close
[0m06:29:22.301630 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.303150 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: ROLLBACK
[0m06:29:22.307800 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.309617 [info ] [Thread-4 (]: 4 of 10 PASS not_null_fct_daily_sales_sales_date ............................... [[32mPASS[0m in 0.28s]
[0m06:29:22.313468 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 06:29:22.189899 => 06:29:22.313090
[0m06:29:22.316269 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: Close
[0m06:29:22.320067 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 06:29:22.143722 => 06:29:22.319577
[0m06:29:22.323355 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:22.325979 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m06:29:22.329842 [info ] [Thread-2 (]: 2 of 10 PASS not_null_fct_daily_sales_gross_revenue ............................ [[32mPASS[0m in 0.31s]
[0m06:29:22.331493 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: ROLLBACK
[0m06:29:22.333512 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:22.337074 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: Close
[0m06:29:22.338687 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:22.342153 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: Close
[0m06:29:22.344592 [info ] [Thread-4 (]: 5 of 10 START test not_null_orders_enriched_line_amount ........................ [RUN]
[0m06:29:22.347884 [info ] [Thread-1 (]: 1 of 10 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.33s]
[0m06:29:22.351291 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:22.357251 [info ] [Thread-3 (]: 3 of 10 PASS not_null_fct_daily_sales_orders ................................... [[32mPASS[0m in 0.33s]
[0m06:29:22.360541 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m06:29:22.364841 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:22.368901 [info ] [Thread-2 (]: 6 of 10 START test not_null_src_orders_order_id ................................ [RUN]
[0m06:29:22.372152 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:22.374564 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:22.377060 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:22.381712 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m06:29:22.385022 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:22.398920 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:29:22.401202 [info ] [Thread-1 (]: 7 of 10 START test not_null_src_orders_order_line_id ........................... [RUN]
[0m06:29:22.403987 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:22.406711 [info ] [Thread-3 (]: 8 of 10 START test not_null_src_orders_order_ts ................................ [RUN]
[0m06:29:22.411766 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m06:29:22.425536 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:29:22.429362 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m06:29:22.433737 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:22.439051 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:22.453506 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 06:29:22.388067 => 06:29:22.453022
[0m06:29:22.454588 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:29:22.462856 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 06:29:22.416103 => 06:29:22.461963
[0m06:29:22.468129 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:29:22.470764 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:22.476466 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:22.488564 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:29:22.501644 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:29:22.505638 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 06:29:22.456548 => 06:29:22.505037
[0m06:29:22.507878 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 06:29:22.441559 => 06:29:22.507148
[0m06:29:22.509982 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:22.512333 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:22.519242 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:29:22.527055 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:29:22.528013 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:29:22.531414 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:29:22.534213 [debug] [Thread-4 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: BEGIN
[0m06:29:22.536587 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: BEGIN
[0m06:29:22.538645 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m06:29:22.540711 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:29:22.552563 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:29:22.553865 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.555620 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.556591 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: BEGIN
[0m06:29:22.558813 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:29:22.559910 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:29:22.561970 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:29:22.564490 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:29:22.567175 [debug] [Thread-4 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select line_amount
from "warehouse"."analytics_intermediate"."orders_enriched"
where line_amount is null



      
    ) dbt_internal_test
[0m06:29:22.569863 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: BEGIN
[0m06:29:22.572350 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "warehouse"."analytics_staging"."src_orders"
where order_id is null



      
    ) dbt_internal_test
[0m06:29:22.579921 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.581715 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:29:22.584963 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.588982 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 06:29:22.480856 => 06:29:22.588543
[0m06:29:22.589999 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.593457 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:29:22.595700 [debug] [Thread-4 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: ROLLBACK
[0m06:29:22.599678 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 06:29:22.491067 => 06:29:22.599276
[0m06:29:22.601762 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.602529 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_ts
from "warehouse"."analytics_staging"."src_orders"
where order_ts is null



      
    ) dbt_internal_test
[0m06:29:22.605210 [debug] [Thread-4 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: Close
[0m06:29:22.607360 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: ROLLBACK
[0m06:29:22.610247 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:29:22.615962 [info ] [Thread-4 (]: 5 of 10 PASS not_null_orders_enriched_line_amount .............................. [[32mPASS[0m in 0.26s]
[0m06:29:22.617155 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.619428 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: Close
[0m06:29:22.621116 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_line_id
from "warehouse"."analytics_staging"."src_orders"
where order_line_id is null



      
    ) dbt_internal_test
[0m06:29:22.623633 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:22.628546 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 06:29:22.514418 => 06:29:22.628049
[0m06:29:22.631753 [info ] [Thread-2 (]: 6 of 10 PASS not_null_src_orders_order_id ...................................... [[32mPASS[0m in 0.25s]
[0m06:29:22.638559 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:22.640026 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.641824 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: ROLLBACK
[0m06:29:22.644935 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:22.647580 [info ] [Thread-4 (]: 9 of 10 START test not_null_src_orders_quantity ................................ [RUN]
[0m06:29:22.653531 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 06:29:22.522355 => 06:29:22.653019
[0m06:29:22.656850 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: Close
[0m06:29:22.658421 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:22.661721 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m06:29:22.663829 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: ROLLBACK
[0m06:29:22.668823 [info ] [Thread-3 (]: 8 of 10 PASS not_null_src_orders_order_ts ...................................... [[32mPASS[0m in 0.24s]
[0m06:29:22.671132 [info ] [Thread-2 (]: 10 of 10 START test unique_fct_daily_sales_sales_date .......................... [RUN]
[0m06:29:22.673247 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:22.675973 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: Close
[0m06:29:22.677894 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:22.680711 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m06:29:22.693389 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:29:22.696769 [info ] [Thread-1 (]: 7 of 10 PASS not_null_src_orders_order_line_id ................................. [[32mPASS[0m in 0.29s]
[0m06:29:22.702962 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:22.707314 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:22.725872 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:29:22.730325 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 06:29:22.683371 => 06:29:22.729733
[0m06:29:22.733011 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:22.740263 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:29:22.747258 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 06:29:22.709351 => 06:29:22.746264
[0m06:29:22.750197 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:22.756951 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:29:22.761003 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:29:22.763425 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: BEGIN
[0m06:29:22.765473 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m06:29:22.773996 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:29:22.775862 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: BEGIN
[0m06:29:22.777961 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.778860 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:29:22.781262 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:29:22.785793 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "warehouse"."analytics_staging"."src_orders"
where quantity is null



      
    ) dbt_internal_test
[0m06:29:22.790530 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.795024 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 06:29:22.735866 => 06:29:22.794603
[0m06:29:22.795790 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.797630 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: ROLLBACK
[0m06:29:22.799948 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:29:22.802812 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: Close
[0m06:29:22.805215 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    sales_date as unique_field,
    count(*) as n_records

from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is not null
group by sales_date
having count(*) > 1



      
    ) dbt_internal_test
[0m06:29:22.808824 [info ] [Thread-4 (]: 9 of 10 PASS not_null_src_orders_quantity ...................................... [[32mPASS[0m in 0.15s]
[0m06:29:22.813400 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:22.814465 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:22.820817 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 06:29:22.751997 => 06:29:22.820340
[0m06:29:22.822923 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: ROLLBACK
[0m06:29:22.825696 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: Close
[0m06:29:22.829596 [info ] [Thread-2 (]: 10 of 10 PASS unique_fct_daily_sales_sales_date ................................ [[32mPASS[0m in 0.15s]
[0m06:29:22.832669 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:22.840305 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:22.842947 [debug] [MainThread]: On master: BEGIN
[0m06:29:22.847208 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:29:22.864025 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:22.866919 [debug] [MainThread]: On master: COMMIT
[0m06:29:22.869060 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:22.871358 [debug] [MainThread]: On master: COMMIT
[0m06:29:22.874491 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:29:22.876794 [debug] [MainThread]: On master: Close
[0m06:29:22.880576 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:29:22.883228 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992' was properly closed.
[0m06:29:22.885461 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_quantity.741e0fed47' was properly closed.
[0m06:29:22.887784 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m06:29:22.889880 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_line_id.c30084a184' was properly closed.
[0m06:29:22.892499 [info ] [MainThread]: 
[0m06:29:22.895226 [info ] [MainThread]: Finished running 10 tests in 0 hours 0 minutes and 1.12 seconds (1.12s).
[0m06:29:22.903010 [debug] [MainThread]: Command end result
[0m06:29:22.956423 [info ] [MainThread]: 
[0m06:29:22.959230 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:29:22.963299 [info ] [MainThread]: 
[0m06:29:22.965546 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
[0m06:29:22.969255 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.0487816, "process_user_time": 4.93717, "process_kernel_time": 0.190663, "process_mem_max_rss": "121720", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:29:22.971745 [debug] [MainThread]: Command `dbt test` succeeded at 06:29:22.971375 after 2.05 seconds
[0m06:29:22.973617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa596d87550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa5980fe3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa596194c90>]}
[0m06:29:22.976154 [debug] [MainThread]: Flushing usage events
[0m06:29:29.461349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bae7ef550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5baea29210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bae7ee7d0>]}


============================== 06:29:29.472120 | 0fd0372c-c741-45a1-acee-f180d1174cf3 ==============================
[0m06:29:29.472120 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:29:29.475198 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'debug': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:29:29.727072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0fd0372c-c741-45a1-acee-f180d1174cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5badd03ed0>]}
[0m06:29:29.884958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0fd0372c-c741-45a1-acee-f180d1174cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bae65d650>]}
[0m06:29:29.887829 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:29:29.914283 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:29:30.433860 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:29:30.436833 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:29:30.449966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0fd0372c-c741-45a1-acee-f180d1174cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bad524f90>]}
[0m06:29:30.474765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0fd0372c-c741-45a1-acee-f180d1174cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bad56b950>]}
[0m06:29:30.477250 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:29:30.479907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fd0372c-c741-45a1-acee-f180d1174cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5baddb0990>]}
[0m06:29:30.487634 [info ] [MainThread]: 
[0m06:29:30.491525 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:29:30.497288 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:29:30.499454 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:29:30.501791 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:29:30.504549 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:29:30.544938 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:30.549220 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:30.557275 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:30.561907 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:30.564187 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:29:30.566578 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:29:30.568832 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:29:30.570799 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:29:30.572825 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:30.575136 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:30.577257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:30.579555 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:30.591215 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:30.591797 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:30.592916 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:30.593533 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:30.594239 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:29:30.596380 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:29:30.598766 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:29:30.601076 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:29:30.603355 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:29:30.605018 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:29:30.607304 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:29:30.610134 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:29:30.617724 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:30.619151 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m06:29:30.622788 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:30.623559 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:30.627566 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:29:30.632069 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:29:30.636471 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:29:30.640170 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:29:30.643421 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:29:30.646159 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:29:30.649082 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:29:30.651958 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:29:30.672036 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:30.674402 [debug] [MainThread]: On master: BEGIN
[0m06:29:30.676625 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:29:30.689513 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:29:30.692200 [debug] [MainThread]: Using postgres connection "master"
[0m06:29:30.694579 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:29:30.704398 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:29:30.709210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fd0372c-c741-45a1-acee-f180d1174cf3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5baf2559d0>]}
[0m06:29:30.711868 [debug] [MainThread]: On master: ROLLBACK
[0m06:29:30.715091 [debug] [MainThread]: On master: Close
[0m06:29:30.718670 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:29:30.721179 [info ] [MainThread]: 
[0m06:29:30.742835 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m06:29:30.746290 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.src_orders)
[0m06:29:30.749416 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m06:29:30.768046 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m06:29:30.792420 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 06:29:30.752142 => 06:29:30.791893
[0m06:29:30.795119 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m06:29:30.797154 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 06:29:30.796626 => 06:29:30.796662
[0m06:29:30.800862 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m06:29:30.805952 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m06:29:30.806950 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m06:29:30.807950 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:30.809283 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:30.811318 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.orders_enriched)
[0m06:29:30.814055 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now snapshot.sales_analytics.customers_snapshot)
[0m06:29:30.817459 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m06:29:30.820915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m06:29:30.823390 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m06:29:30.825660 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m06:29:30.828302 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:30.830864 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:30.837993 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m06:29:30.846160 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 06:29:30.840150 => 06:29:30.845636
[0m06:29:30.876419 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:29:30.879116 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:29:30.883602 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m06:29:30.890291 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 06:29:30.889329 => 06:29:30.889359
[0m06:29:30.895245 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m06:29:30.896952 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 06:29:30.870487 => 06:29:30.896142
[0m06:29:30.898110 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 06:29:30.833192 => 06:29:30.897646
[0m06:29:30.899566 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:30.902195 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:30.903390 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 06:29:30.847445 => 06:29:30.902796
[0m06:29:30.905162 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m06:29:30.907986 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m06:29:30.911246 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 06:29:30.910688 => 06:29:30.910719
[0m06:29:30.913635 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:30.916926 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 06:29:30.916534 => 06:29:30.916550
[0m06:29:30.919358 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:30.922726 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:29:30.925183 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 06:29:30.924776 => 06:29:30.924794
[0m06:29:30.928433 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m06:29:30.938325 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:29:30.940839 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:30.944201 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:29:30.947277 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m06:29:30.952554 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m06:29:30.954475 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m06:29:30.957529 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.dim_customer)
[0m06:29:30.960304 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:30.963844 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.fct_daily_sales)
[0m06:29:30.966410 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m06:29:30.979002 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:29:30.981094 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m06:29:30.989085 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 06:29:30.930403 => 06:29:30.988668
[0m06:29:30.990218 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m06:29:31.013419 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m06:29:31.015561 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:31.018303 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 06:29:30.968712 => 06:29:31.017485
[0m06:29:31.022026 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 06:29:31.021562 => 06:29:31.021588
[0m06:29:31.024356 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:31.027505 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:29:31.030114 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 06:29:31.029384 => 06:29:31.029400
[0m06:29:31.031557 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 06:29:30.983163 => 06:29:31.030996
[0m06:29:31.032437 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 06:29:30.994163 => 06:29:31.032090
[0m06:29:31.034880 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:31.038461 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:29:31.041448 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m06:29:31.044090 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m06:29:31.047572 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m06:29:31.051303 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 06:29:31.050786 => 06:29:31.050824
[0m06:29:31.053849 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 06:29:31.053468 => 06:29:31.053482
[0m06:29:31.056817 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:31.060434 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m06:29:31.063678 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m06:29:31.073147 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:29:31.076418 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:31.079150 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:31.080165 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:31.084496 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m06:29:31.087788 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m06:29:31.090644 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m06:29:31.093486 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:31.096453 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:31.099069 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:31.108799 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:29:31.117569 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 06:29:31.066215 => 06:29:31.117141
[0m06:29:31.119546 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:29:31.128411 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:29:31.132157 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:31.137923 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 06:29:31.137471 => 06:29:31.137492
[0m06:29:31.140903 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:29:31.143169 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:31.144420 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 06:29:31.121304 => 06:29:31.143960
[0m06:29:31.145250 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 06:29:31.101347 => 06:29:31.144895
[0m06:29:31.147015 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m06:29:31.148048 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 06:29:31.111394 => 06:29:31.147662
[0m06:29:31.150133 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:31.152996 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:31.155703 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:31.158356 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:31.161231 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 06:29:31.160848 => 06:29:31.160861
[0m06:29:31.164031 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 06:29:31.163676 => 06:29:31.163689
[0m06:29:31.173494 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:29:31.175536 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 06:29:31.175063 => 06:29:31.175083
[0m06:29:31.178666 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:29:31.181946 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:29:31.187070 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:29:31.189330 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:31.195414 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m06:29:31.197411 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:31.210159 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:29:31.213060 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 06:29:31.166545 => 06:29:31.212605
[0m06:29:31.215323 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:31.217836 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 06:29:31.217477 => 06:29:31.217491
[0m06:29:31.221597 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:29:31.231993 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 06:29:31.199350 => 06:29:31.231600
[0m06:29:31.234604 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:31.237257 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 06:29:31.236916 => 06:29:31.236930
[0m06:29:31.240458 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:29:31.245212 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:29:31.247467 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m06:29:31.249723 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m06:29:31.252095 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m06:29:31.254353 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m06:29:31.259404 [debug] [MainThread]: Command end result
[0m06:29:31.336643 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m06:29:31.338447 [info ] [MainThread]: Building catalog
[0m06:29:31.344456 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m06:29:31.362502 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m06:29:31.364970 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m06:29:31.367145 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:29:31.378172 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:29:31.380925 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m06:29:31.383058 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m06:29:31.389991 [debug] [ThreadPool]: SQL status: SELECT 41 in 0.0 seconds
[0m06:29:31.399415 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m06:29:31.401555 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m06:29:31.441752 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m06:29:31.444510 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 2.0585737, "process_user_time": 4.465252, "process_kernel_time": 0.162004, "process_mem_max_rss": "121336", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:29:31.446514 [debug] [MainThread]: Command `dbt docs generate` succeeded at 06:29:31.446309 after 2.06 seconds
[0m06:29:31.448155 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m06:29:31.449785 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m06:29:31.451685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bae62b850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bafbd2790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bb31e4fd0>]}
[0m06:29:31.453512 [debug] [MainThread]: Flushing usage events
[0m06:30:05.626236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04ee1db5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04ee221850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04ee1db010>]}


============================== 06:30:05.634459 | 0c9ce24e-4b26-46c5-af51-cd33a000494e ==============================
[0m06:30:05.634459 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:30:05.635584 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m06:30:05.734902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0c9ce24e-4b26-46c5-af51-cd33a000494e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04ee232f90>]}
[0m06:30:05.740338 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:30:05.751692 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:30:05.753812 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.19888908, "process_user_time": 2.663491, "process_kernel_time": 0.129683, "process_mem_max_rss": "105028", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:30:05.755068 [debug] [MainThread]: Command `dbt deps` succeeded at 06:30:05.754856 after 0.20 seconds
[0m06:30:05.756136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04f2d73a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04f2d737d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04ee965450>]}
[0m06:30:05.759431 [debug] [MainThread]: Flushing usage events
[0m06:30:09.042201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b6210c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b651bf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b61f6450>]}


============================== 06:30:09.048742 | fff58a0f-5cc4-4313-b9c5-c18603527ecc ==============================
[0m06:30:09.048742 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:30:09.049885 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select staging intermediate', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m06:30:09.231991 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b57a1e10>]}
[0m06:30:09.326218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b57c9b10>]}
[0m06:30:09.328625 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:30:09.346690 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:30:09.514272 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:30:09.515373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:30:09.522367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b4f1ad90>]}
[0m06:30:09.552650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b53339d0>]}
[0m06:30:09.554231 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:30:09.555589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b7243c50>]}
[0m06:30:09.559158 [info ] [MainThread]: 
[0m06:30:09.561754 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:30:09.565699 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:30:09.567181 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:30:09.583073 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:30:09.586459 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:30:09.589025 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:30:09.591818 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:30:09.593557 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:09.595121 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:09.605792 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m06:30:09.606703 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m06:30:09.609137 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:30:09.611549 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:30:09.616448 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_intermediate)
[0m06:30:09.617326 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_staging)
[0m06:30:09.619215 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_intermediate"
"
[0m06:30:09.621680 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_staging"
"
[0m06:30:09.629807 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m06:30:09.632635 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m06:30:09.634146 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: BEGIN
[0m06:30:09.635797 [debug] [ThreadPool]: On create_warehouse_analytics_staging: BEGIN
[0m06:30:09.637130 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:09.639103 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:09.646268 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.647744 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m06:30:09.648214 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.649363 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_intermediate"} */
create schema if not exists "analytics_intermediate"
[0m06:30:09.650757 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m06:30:09.652779 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:30:09.653767 [debug] [ThreadPool]: On create_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_staging"} */
create schema if not exists "analytics_staging"
[0m06:30:09.655879 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: COMMIT
[0m06:30:09.657955 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:30:09.658731 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m06:30:09.660981 [debug] [ThreadPool]: On create_warehouse_analytics_staging: COMMIT
[0m06:30:09.662681 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: COMMIT
[0m06:30:09.664297 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m06:30:09.667111 [debug] [ThreadPool]: On create_warehouse_analytics_staging: COMMIT
[0m06:30:09.685426 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:30:09.688165 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: Close
[0m06:30:09.704147 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:30:09.707205 [debug] [ThreadPool]: On create_warehouse_analytics_staging: Close
[0m06:30:09.713774 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_staging, now list_warehouse_analytics_intermediate)
[0m06:30:09.715384 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_intermediate, now list_warehouse_analytics_marts)
[0m06:30:09.716937 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:30:09.718508 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:30:09.727474 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:09.731634 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:09.735583 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:09.739147 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:09.740648 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:30:09.742446 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:30:09.744203 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:30:09.746223 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:30:09.748242 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:09.750156 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:09.752314 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:09.754556 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:09.763167 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.763739 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.764317 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.765067 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:09.765616 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.767071 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:09.769003 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:09.770776 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:30:09.772824 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:09.775025 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:30:09.777260 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:30:09.780191 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:30:09.782132 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:09.784516 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:30:09.785016 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:09.785348 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:09.785707 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:09.786849 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:30:09.789006 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:30:09.791451 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:30:09.794229 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:30:09.797474 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:30:09.798814 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:30:09.800380 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:30:09.808362 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:09.810069 [debug] [MainThread]: On master: BEGIN
[0m06:30:09.811852 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:30:09.818685 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.820403 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:09.822233 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:30:09.826771 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:09.829173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b5362bd0>]}
[0m06:30:09.830959 [debug] [MainThread]: On master: ROLLBACK
[0m06:30:09.832841 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:09.849511 [debug] [MainThread]: On master: BEGIN
[0m06:30:09.853141 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.854274 [debug] [MainThread]: On master: COMMIT
[0m06:30:09.855167 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:09.856115 [debug] [MainThread]: On master: COMMIT
[0m06:30:09.857078 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:09.857807 [debug] [MainThread]: On master: Close
[0m06:30:09.858932 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:30:09.860084 [info ] [MainThread]: 
[0m06:30:09.870429 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m06:30:09.871638 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m06:30:09.873403 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.src_orders)
[0m06:30:09.874698 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m06:30:09.886430 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m06:30:09.906958 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 06:30:09.875477 => 06:30:09.906442
[0m06:30:09.908884 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m06:30:09.948294 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m06:30:09.971246 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:09.973436 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m06:30:09.975900 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:30:09.984668 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:09.986812 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:09.989577 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m06:30:09.993251 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m06:30:10.002031 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:10.004117 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m06:30:10.006653 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:30:10.030067 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:10.032123 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m06:30:10.034648 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:10.048470 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:10.050448 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m06:30:10.059982 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m06:30:10.065566 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:10.067466 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:30:10.069562 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:10.072211 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m06:30:10.074384 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:10.076532 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m06:30:10.093657 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:30:10.105689 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m06:30:10.113680 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m06:30:10.114614 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m06:30:10.115673 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m06:30:10.117615 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 06:30:09.910356 => 06:30:10.117463
[0m06:30:10.118379 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m06:30:10.119565 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b4fb3b50>]}
[0m06:30:10.120595 [info ] [Thread-1 (]: 1 of 2 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 0.25s]
[0m06:30:10.122118 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m06:30:10.123946 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m06:30:10.125022 [info ] [Thread-3 (]: 2 of 2 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m06:30:10.126793 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.orders_enriched)
[0m06:30:10.127588 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m06:30:10.130764 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m06:30:10.143319 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 06:30:10.128234 => 06:30:10.142693
[0m06:30:10.144677 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m06:30:10.171591 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m06:30:10.191104 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.192789 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m06:30:10.194618 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:30:10.201968 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:10.203727 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.205585 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m06:30:10.213643 [debug] [Thread-3 (]: SQL status: SELECT 4291 in 0.0 seconds
[0m06:30:10.218628 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.220306 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m06:30:10.222657 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:30:10.230396 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.232403 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m06:30:10.234634 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:10.238611 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.239696 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m06:30:10.245937 [debug] [Thread-3 (]: SQL status: SELECT 12 in 0.0 seconds
[0m06:30:10.248324 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.249248 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:30:10.250249 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:10.251779 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m06:30:10.252629 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.253417 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m06:30:10.257220 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m06:30:10.260875 [debug] [Thread-3 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m06:30:10.264817 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m06:30:10.265755 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m06:30:10.266916 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m06:30:10.268945 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 06:30:10.145456 => 06:30:10.268752
[0m06:30:10.269915 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: Close
[0m06:30:10.271474 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fff58a0f-5cc4-4313-b9c5-c18603527ecc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b5374910>]}
[0m06:30:10.272707 [info ] [Thread-3 (]: 2 of 2 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 4291[0m in 0.14s]
[0m06:30:10.275502 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m06:30:10.278642 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:10.279587 [debug] [MainThread]: On master: BEGIN
[0m06:30:10.280491 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:30:10.286727 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:10.290368 [debug] [MainThread]: On master: COMMIT
[0m06:30:10.292032 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:10.295061 [debug] [MainThread]: On master: COMMIT
[0m06:30:10.296336 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:10.297280 [debug] [MainThread]: On master: Close
[0m06:30:10.298734 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:30:10.299611 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m06:30:10.301535 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m06:30:10.303098 [debug] [MainThread]: Connection 'model.sales_analytics.src_orders' was properly closed.
[0m06:30:10.304485 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m06:30:10.305607 [info ] [MainThread]: 
[0m06:30:10.306705 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m06:30:10.308449 [debug] [MainThread]: Command end result
[0m06:30:10.338131 [info ] [MainThread]: 
[0m06:30:10.340336 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:30:10.341647 [info ] [MainThread]: 
[0m06:30:10.343438 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m06:30:10.345629 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.3657128, "process_user_time": 3.356579, "process_kernel_time": 0.169323, "process_mem_max_rss": "122220", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:30:10.347501 [debug] [MainThread]: Command `dbt run` succeeded at 06:30:10.347299 after 1.37 seconds
[0m06:30:10.348829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b7366d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b6057510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72b6057450>]}
[0m06:30:10.350154 [debug] [MainThread]: Flushing usage events
[0m06:30:13.717050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269c3f950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269f67c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269c3fa50>]}


============================== 06:30:13.726119 | 9356ea64-d160-4a71-9e89-56d89cbcf017 ==============================
[0m06:30:13.726119 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:30:13.727554 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt snapshot', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m06:30:13.945772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9356ea64-d160-4a71-9e89-56d89cbcf017', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269564c50>]}
[0m06:30:14.059402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9356ea64-d160-4a71-9e89-56d89cbcf017', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269e23e90>]}
[0m06:30:14.061857 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:30:14.086444 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:30:14.323521 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:30:14.324758 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:30:14.333165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9356ea64-d160-4a71-9e89-56d89cbcf017', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269ad1f10>]}
[0m06:30:14.373243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9356ea64-d160-4a71-9e89-56d89cbcf017', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f526916c6d0>]}
[0m06:30:14.374716 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:30:14.376620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9356ea64-d160-4a71-9e89-56d89cbcf017', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269539450>]}
[0m06:30:14.380092 [info ] [MainThread]: 
[0m06:30:14.381994 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:30:14.384897 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:30:14.404761 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:30:14.406620 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:30:14.408129 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:14.421783 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m06:30:14.425025 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:30:14.428557 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m06:30:14.430637 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m06:30:14.440674 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m06:30:14.442729 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m06:30:14.444570 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:14.453378 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.455479 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m06:30:14.457363 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m06:30:14.459785 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:30:14.462544 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m06:30:14.464352 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m06:30:14.466186 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m06:30:14.472102 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:30:14.474151 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m06:30:14.479569 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_analytics_intermediate)
[0m06:30:14.481061 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:30:14.482595 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:30:14.484432 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:30:14.492821 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:14.496659 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:14.500992 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:14.505479 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:14.507649 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:30:14.509685 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:30:14.511444 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:30:14.513633 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:30:14.515676 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:14.517729 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:14.519470 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:14.521540 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:14.532952 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.534138 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.535222 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:14.535928 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.537056 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.537579 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:14.539870 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:30:14.542264 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:14.544529 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:14.546783 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:30:14.550661 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:30:14.552356 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:30:14.553021 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:14.558787 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:30:14.559307 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:14.559926 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:14.560914 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:14.561538 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:30:14.564470 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:30:14.568443 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:30:14.570925 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:30:14.575207 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:30:14.576689 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:30:14.578554 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:30:14.590463 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:14.592859 [debug] [MainThread]: On master: BEGIN
[0m06:30:14.594975 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:30:14.604659 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.606940 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:14.609119 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:30:14.615448 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:14.618567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9356ea64-d160-4a71-9e89-56d89cbcf017', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269547fd0>]}
[0m06:30:14.619892 [debug] [MainThread]: On master: ROLLBACK
[0m06:30:14.621230 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:14.622280 [debug] [MainThread]: On master: BEGIN
[0m06:30:14.623856 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.624913 [debug] [MainThread]: On master: COMMIT
[0m06:30:14.625949 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:14.626965 [debug] [MainThread]: On master: COMMIT
[0m06:30:14.628129 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:14.629170 [debug] [MainThread]: On master: Close
[0m06:30:14.631076 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:30:14.633754 [info ] [MainThread]: 
[0m06:30:14.650812 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m06:30:14.652363 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m06:30:14.659442 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m06:30:14.661315 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m06:30:14.678179 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 06:30:14.662452 => 06:30:14.677794
[0m06:30:14.681423 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m06:30:14.762335 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m06:30:14.788383 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m06:30:14.791516 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m06:30:14.794629 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:30:14.806853 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.808256 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m06:30:14.809503 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m06:30:14.856922 [debug] [Thread-1 (]: SQL status: SELECT 5000 in 0.0 seconds
[0m06:30:14.885428 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m06:30:14.887959 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m06:30:14.890103 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m06:30:14.896802 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:30:14.900141 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 06:30:14.683083 => 06:30:14.899829
[0m06:30:14.902258 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m06:30:14.904978 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9356ea64-d160-4a71-9e89-56d89cbcf017', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f526916c150>]}
[0m06:30:14.907039 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSELECT 5000[0m in 0.25s]
[0m06:30:14.909211 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m06:30:14.913100 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:14.914382 [debug] [MainThread]: On master: BEGIN
[0m06:30:14.915995 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:30:14.925287 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:14.927238 [debug] [MainThread]: On master: COMMIT
[0m06:30:14.929064 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:14.930284 [debug] [MainThread]: On master: COMMIT
[0m06:30:14.931940 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:14.933251 [debug] [MainThread]: On master: Close
[0m06:30:14.935737 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:30:14.939140 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m06:30:14.941332 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m06:30:14.943181 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m06:30:14.945066 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m06:30:14.947012 [info ] [MainThread]: 
[0m06:30:14.948761 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m06:30:14.952758 [debug] [MainThread]: Command end result
[0m06:30:14.990153 [info ] [MainThread]: 
[0m06:30:14.992281 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:30:14.993989 [info ] [MainThread]: 
[0m06:30:14.995861 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m06:30:14.998790 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 1.3566315, "process_user_time": 3.471776, "process_kernel_time": 0.149645, "process_mem_max_rss": "121668", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:30:15.000930 [debug] [MainThread]: Command `dbt snapshot` succeeded at 06:30:15.000672 after 1.36 seconds
[0m06:30:15.002554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269a96f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5269a96f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f526e369310>]}
[0m06:30:15.006918 [debug] [MainThread]: Flushing usage events
[0m06:30:19.489693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dad0c2f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dae107a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dad0c0390>]}


============================== 06:30:19.498621 | 813003df-69aa-4db2-b227-71caba286801 ==============================
[0m06:30:19.498621 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:30:19.500472 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/usr/app/logs', 'debug': 'False', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --select marts', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m06:30:19.769146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dac39a450>]}
[0m06:30:19.933629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dad0c0490>]}
[0m06:30:19.936286 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:30:19.966493 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:30:20.320574 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:30:20.321973 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:30:20.331468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dad0baf10>]}
[0m06:30:20.368710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dac3fc410>]}
[0m06:30:20.370387 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:30:20.372295 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dabf99310>]}
[0m06:30:20.375548 [info ] [MainThread]: 
[0m06:30:20.378327 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:30:20.383533 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m06:30:20.405165 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m06:30:20.407278 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m06:30:20.409535 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:20.422646 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m06:30:20.425728 [debug] [ThreadPool]: On list_warehouse: Close
[0m06:30:20.429640 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_marts)
[0m06:30:20.431601 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_marts"
"
[0m06:30:20.440426 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m06:30:20.442312 [debug] [ThreadPool]: On create_warehouse_analytics_marts: BEGIN
[0m06:30:20.443823 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:20.451953 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.454252 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m06:30:20.456347 [debug] [ThreadPool]: On create_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_marts"} */
create schema if not exists "analytics_marts"
[0m06:30:20.459080 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m06:30:20.461501 [debug] [ThreadPool]: On create_warehouse_analytics_marts: COMMIT
[0m06:30:20.463548 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m06:30:20.465474 [debug] [ThreadPool]: On create_warehouse_analytics_marts: COMMIT
[0m06:30:20.471878 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m06:30:20.473264 [debug] [ThreadPool]: On create_warehouse_analytics_marts: Close
[0m06:30:20.477552 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_marts, now list_warehouse_analytics_marts)
[0m06:30:20.478879 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:30:20.480351 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:30:20.487536 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:30:20.490906 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:20.495059 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:20.498959 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:20.503828 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:20.505540 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:30:20.506961 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:30:20.508290 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:30:20.509330 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:30:20.511179 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:30:20.512920 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:20.514508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:20.516334 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:20.527585 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.528582 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.530002 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.530585 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:20.531706 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.532618 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:20.534357 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:20.535907 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:30:20.537394 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:20.539181 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:30:20.541063 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:30:20.543826 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:30:20.546774 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m06:30:20.550190 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:30:20.550977 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:20.551569 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:20.552443 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:20.553647 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:30:20.556095 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:30:20.558973 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:30:20.561962 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:30:20.565674 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:30:20.567161 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:30:20.568627 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:30:20.580538 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:20.582123 [debug] [MainThread]: On master: BEGIN
[0m06:30:20.583296 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:30:20.591733 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.593156 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:20.594438 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:30:20.601906 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:20.606075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dac3e4750>]}
[0m06:30:20.607889 [debug] [MainThread]: On master: ROLLBACK
[0m06:30:20.609764 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:20.611102 [debug] [MainThread]: On master: BEGIN
[0m06:30:20.613007 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.615049 [debug] [MainThread]: On master: COMMIT
[0m06:30:20.617197 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:20.619336 [debug] [MainThread]: On master: COMMIT
[0m06:30:20.621642 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:20.623750 [debug] [MainThread]: On master: Close
[0m06:30:20.626575 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:30:20.628123 [info ] [MainThread]: 
[0m06:30:20.642350 [debug] [Thread-1 (]: Began running node model.sales_analytics.dim_customer
[0m06:30:20.643323 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m06:30:20.645145 [info ] [Thread-1 (]: 1 of 2 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m06:30:20.649597 [info ] [Thread-2 (]: 2 of 2 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m06:30:20.652896 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.dim_customer)
[0m06:30:20.654782 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now model.sales_analytics.fct_daily_sales)
[0m06:30:20.656344 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.dim_customer
[0m06:30:20.657973 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m06:30:20.672474 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m06:30:20.689516 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m06:30:20.700672 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 06:30:20.673444 => 06:30:20.699711
[0m06:30:20.701783 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (compile): 06:30:20.659188 => 06:30:20.701404
[0m06:30:20.703144 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m06:30:20.704738 [debug] [Thread-1 (]: Began executing node model.sales_analytics.dim_customer
[0m06:30:20.837628 [debug] [Thread-2 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m06:30:20.840761 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m06:30:20.855084 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:30:20.856672 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:20.857869 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m06:30:20.859658 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: BEGIN
[0m06:30:20.861374 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:30:20.862917 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:30:20.872560 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.873239 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:20.874970 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:30:20.877365 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:20.879619 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
  
    

  create  table "warehouse"."analytics_marts"."fct_daily_sales"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
    group by 1
)
select * from base
  );
  
  
[0m06:30:20.881804 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- 

-- with current as (
--     select *
--     from "warehouse"."snapshots"."customers_snapshot"
--     where dbt_valid_to is null
-- ),

-- deduped as (
--     select
--         customer_id,
--         country,
--         status,
--         dbt_valid_from,
--         row_number() over (
--             partition by customer_id
--             order by dbt_valid_from desc
--         ) as rn
--     from current
-- )

-- select
--     customer_id,
--     country,
--     status,
--     dbt_valid_from as valid_from
-- from deduped
-- where rn = 1



with snapshot_data as (
    select
        customer_id,
        country,
        status,
        dbt_valid_from,
        dbt_valid_to
    from "warehouse"."snapshots"."customers_snapshot"
)

select
    customer_id,
    country,
    status,
    dbt_valid_from as valid_from,
    dbt_valid_to   as valid_to,
    case when dbt_valid_to is null then true else false end as is_current
from snapshot_data
order by customer_id, dbt_valid_from
  );
  
[0m06:30:20.894555 [debug] [Thread-1 (]: SQL status: SELECT 5000 in 0.0 seconds
[0m06:30:20.905717 [debug] [Thread-2 (]: SQL status: SELECT 61 in 0.0 seconds
[0m06:30:20.906840 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:20.931416 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
alter table "warehouse"."analytics_marts"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m06:30:20.942904 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:30:20.945116 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m06:30:20.946423 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m06:30:20.957929 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:20.959753 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:20.960745 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  comment on table "warehouse"."analytics_marts"."dim_customer" is $dbt_comment_literal_block$Current SCD2 customer dimension from snapshots$dbt_comment_literal_block$;

  
[0m06:30:20.980832 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:30:20.982074 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:20.982655 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m06:30:20.988188 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:20.992258 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m06:30:21.001767 [debug] [Thread-2 (]: SQL status: SELECT 4 in 0.0 seconds
[0m06:30:21.010715 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:30:21.011431 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m06:30:21.013212 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:30:21.018283 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:21.020831 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:21.022106 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".customer_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".status is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".country is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".valid_from is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m06:30:21.027777 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:30:21.030411 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m06:30:21.032247 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m06:30:21.035839 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: COMMIT
[0m06:30:21.038523 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:21.040517 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: COMMIT
[0m06:30:21.057692 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m06:30:21.068312 [debug] [Thread-2 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m06:30:21.072826 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_marts"."dim_customer__dbt_backup"
[0m06:30:21.075380 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m06:30:21.084656 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m06:30:21.086576 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m06:30:21.089143 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
drop table if exists "warehouse"."analytics_marts"."dim_customer__dbt_backup" cascade
[0m06:30:21.091341 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m06:30:21.094485 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m06:30:21.098656 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (execute): 06:30:20.729096 => 06:30:21.098349
[0m06:30:21.099501 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m06:30:21.101519 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: Close
[0m06:30:21.104313 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 06:30:20.706599 => 06:30:21.104048
[0m06:30:21.107811 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dab31ffd0>]}
[0m06:30:21.109348 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: Close
[0m06:30:21.111699 [info ] [Thread-1 (]: 1 of 2 OK created sql table model analytics_marts.dim_customer ................. [[32mSELECT 5000[0m in 0.46s]
[0m06:30:21.114232 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '813003df-69aa-4db2-b227-71caba286801', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dab307ad0>]}
[0m06:30:21.116060 [debug] [Thread-1 (]: Finished running node model.sales_analytics.dim_customer
[0m06:30:21.117975 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mSELECT 61[0m in 0.46s]
[0m06:30:21.120945 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m06:30:21.125691 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:21.129727 [debug] [MainThread]: On master: BEGIN
[0m06:30:21.132091 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:30:21.143670 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:21.145742 [debug] [MainThread]: On master: COMMIT
[0m06:30:21.148137 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:21.150393 [debug] [MainThread]: On master: COMMIT
[0m06:30:21.153075 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:21.155381 [debug] [MainThread]: On master: Close
[0m06:30:21.158660 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:30:21.160408 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m06:30:21.162485 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m06:30:21.164619 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m06:30:21.166372 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m06:30:21.168426 [info ] [MainThread]: 
[0m06:30:21.169776 [info ] [MainThread]: Finished running 1 table model, 1 incremental model in 0 hours 0 minutes and 0.79 seconds (0.79s).
[0m06:30:21.172346 [debug] [MainThread]: Command end result
[0m06:30:21.211268 [info ] [MainThread]: 
[0m06:30:21.213218 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:30:21.215736 [info ] [MainThread]: 
[0m06:30:21.217708 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m06:30:21.220343 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.8083572, "process_user_time": 4.767211, "process_kernel_time": 0.209, "process_mem_max_rss": "123144", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:30:21.222690 [debug] [MainThread]: Command `dbt run` succeeded at 06:30:21.222469 after 1.81 seconds
[0m06:30:21.224926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4dacf1b590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4db1a9b8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4db1a9b850>]}
[0m06:30:21.228212 [debug] [MainThread]: Flushing usage events
[0m06:30:25.966935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8546d4a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8546d4e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe854b20d50>]}


============================== 06:30:25.976972 | 003fa5c8-bce1-48dd-a17d-0d6d01e5a884 ==============================
[0m06:30:25.976972 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:30:25.980045 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True'}
[0m06:30:26.253643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '003fa5c8-bce1-48dd-a17d-0d6d01e5a884', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8552a0d50>]}
[0m06:30:26.411051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '003fa5c8-bce1-48dd-a17d-0d6d01e5a884', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8546bec90>]}
[0m06:30:26.413723 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:30:26.444531 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:30:26.705639 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:30:26.707538 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:30:26.717651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '003fa5c8-bce1-48dd-a17d-0d6d01e5a884', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8533a8990>]}
[0m06:30:26.764337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '003fa5c8-bce1-48dd-a17d-0d6d01e5a884', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe853bb7150>]}
[0m06:30:26.765810 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:30:26.767501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '003fa5c8-bce1-48dd-a17d-0d6d01e5a884', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8537cdb50>]}
[0m06:30:26.772170 [info ] [MainThread]: 
[0m06:30:26.775581 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:30:26.781026 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:30:26.783000 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:30:26.786642 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:30:26.788996 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:30:26.807716 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:26.812198 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:26.816910 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:26.821441 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:26.823391 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:30:26.825663 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:30:26.827398 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:30:26.828843 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:30:26.830769 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:26.832906 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:26.834863 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:26.836825 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:26.847822 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:26.849326 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:26.850545 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:26.851323 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:26.851796 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:26.852333 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:30:26.854018 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:26.855908 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:26.857533 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:26.861414 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:30:26.863654 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:30:26.864887 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:26.866077 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:30:26.872600 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:30:26.873474 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:26.874260 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:26.876625 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:30:26.879164 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:30:26.879889 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m06:30:26.882534 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:30:26.886778 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:30:26.889398 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:30:26.891734 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:30:26.895278 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:30:26.905680 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:26.907779 [debug] [MainThread]: On master: BEGIN
[0m06:30:26.910062 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:30:26.918988 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:26.920556 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:26.922061 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:30:26.930222 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:26.933690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '003fa5c8-bce1-48dd-a17d-0d6d01e5a884', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe85470f890>]}
[0m06:30:26.935197 [debug] [MainThread]: On master: ROLLBACK
[0m06:30:26.936866 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:26.938443 [debug] [MainThread]: On master: BEGIN
[0m06:30:26.940652 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:26.941978 [debug] [MainThread]: On master: COMMIT
[0m06:30:26.943550 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:26.945174 [debug] [MainThread]: On master: COMMIT
[0m06:30:26.947103 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:26.948754 [debug] [MainThread]: On master: Close
[0m06:30:26.951158 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:30:26.952468 [info ] [MainThread]: 
[0m06:30:26.969602 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:26.971114 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:26.972900 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:26.974424 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:26.976732 [info ] [Thread-1 (]: 1 of 10 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m06:30:26.978676 [info ] [Thread-2 (]: 2 of 10 START test not_null_fct_daily_sales_gross_revenue ...................... [RUN]
[0m06:30:26.980465 [info ] [Thread-3 (]: 3 of 10 START test not_null_fct_daily_sales_orders ............................. [RUN]
[0m06:30:26.982319 [info ] [Thread-4 (]: 4 of 10 START test not_null_fct_daily_sales_sales_date ......................... [RUN]
[0m06:30:26.984847 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m06:30:26.987073 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m06:30:26.989218 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m06:30:26.992094 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m06:30:26.995772 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:26.997506 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:26.999465 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:27.001400 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:27.044386 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:30:27.047941 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:30:27.055077 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:30:27.063732 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:30:27.077513 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 06:30:27.026018 => 06:30:27.076946
[0m06:30:27.079395 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 06:30:27.057031 => 06:30:27.078852
[0m06:30:27.080264 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:27.081304 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 06:30:27.003100 => 06:30:27.080810
[0m06:30:27.082728 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 06:30:27.048470 => 06:30:27.082404
[0m06:30:27.084081 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:27.110452 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:27.111073 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:30:27.114306 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:27.120690 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:30:27.128440 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:30:27.137896 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:30:27.150184 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:30:27.151793 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:30:27.153338 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: BEGIN
[0m06:30:27.154273 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:30:27.155981 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m06:30:27.158160 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:30:27.159478 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:30:27.162432 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: BEGIN
[0m06:30:27.164997 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:30:27.168202 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: BEGIN
[0m06:30:27.173588 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m06:30:27.177471 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:30:27.180786 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.182242 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:30:27.183635 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select gross_revenue
from "warehouse"."analytics_marts"."fct_daily_sales"
where gross_revenue is null



      
    ) dbt_internal_test
[0m06:30:27.185416 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.186439 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.187930 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.188670 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:30:27.189330 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.194335 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 06:30:27.086583 => 06:30:27.193994
[0m06:30:27.197252 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:30:27.200194 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "warehouse"."analytics_marts"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m06:30:27.203292 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:30:27.205861 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: ROLLBACK
[0m06:30:27.208254 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sales_date
from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is null



      
    ) dbt_internal_test
[0m06:30:27.212583 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orders
from "warehouse"."analytics_marts"."fct_daily_sales"
where orders is null



      
    ) dbt_internal_test
[0m06:30:27.213435 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.215863 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: Close
[0m06:30:27.219415 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.221419 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.223883 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 06:30:27.123477 => 06:30:27.223438
[0m06:30:27.227251 [info ] [Thread-2 (]: 2 of 10 PASS not_null_fct_daily_sales_gross_revenue ............................ [[32mPASS[0m in 0.24s]
[0m06:30:27.230930 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 06:30:27.117136 => 06:30:27.230456
[0m06:30:27.234573 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 06:30:27.133828 => 06:30:27.234184
[0m06:30:27.237167 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m06:30:27.239758 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:27.241898 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: ROLLBACK
[0m06:30:27.245817 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: ROLLBACK
[0m06:30:27.248403 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: Close
[0m06:30:27.250631 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:27.253796 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: Close
[0m06:30:27.255697 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: Close
[0m06:30:27.258890 [info ] [Thread-1 (]: 1 of 10 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.27s]
[0m06:30:27.260330 [info ] [Thread-2 (]: 5 of 10 START test not_null_orders_enriched_line_amount ........................ [RUN]
[0m06:30:27.262847 [info ] [Thread-4 (]: 4 of 10 PASS not_null_fct_daily_sales_sales_date ............................... [[32mPASS[0m in 0.27s]
[0m06:30:27.264803 [info ] [Thread-3 (]: 3 of 10 PASS not_null_fct_daily_sales_orders ................................... [[32mPASS[0m in 0.28s]
[0m06:30:27.266482 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:27.269362 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m06:30:27.272249 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:27.274936 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:27.278943 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:27.282462 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:27.285318 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:27.288050 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:27.290343 [info ] [Thread-1 (]: 6 of 10 START test not_null_src_orders_order_id ................................ [RUN]
[0m06:30:27.303127 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:30:27.305218 [info ] [Thread-4 (]: 7 of 10 START test not_null_src_orders_order_line_id ........................... [RUN]
[0m06:30:27.308860 [info ] [Thread-3 (]: 8 of 10 START test not_null_src_orders_order_ts ................................ [RUN]
[0m06:30:27.311805 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m06:30:27.316539 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m06:30:27.320323 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m06:30:27.322619 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:27.325409 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:27.328722 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:27.342927 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:30:27.354168 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:30:27.355251 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 06:30:27.292981 => 06:30:27.354755
[0m06:30:27.366463 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:30:27.372730 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:27.381659 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:30:27.385969 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 06:30:27.332465 => 06:30:27.385360
[0m06:30:27.387184 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 06:30:27.356833 => 06:30:27.386598
[0m06:30:27.388381 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 06:30:27.344974 => 06:30:27.387929
[0m06:30:27.390223 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:27.393213 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:27.396632 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:27.407392 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:30:27.414577 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:30:27.415679 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:30:27.422288 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:30:27.429812 [debug] [Thread-2 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: BEGIN
[0m06:30:27.434819 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:30:27.440483 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:30:27.442482 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:30:27.444106 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: BEGIN
[0m06:30:27.446041 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:30:27.446862 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: BEGIN
[0m06:30:27.449716 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:30:27.450912 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.453083 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: BEGIN
[0m06:30:27.455955 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:30:27.460841 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:30:27.462860 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m06:30:27.466945 [debug] [Thread-2 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select line_amount
from "warehouse"."analytics_intermediate"."orders_enriched"
where line_amount is null



      
    ) dbt_internal_test
[0m06:30:27.470462 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.472992 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:30:27.474672 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.476359 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "warehouse"."analytics_staging"."src_orders"
where order_id is null



      
    ) dbt_internal_test
[0m06:30:27.478452 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.483219 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 06:30:27.376637 => 06:30:27.482704
[0m06:30:27.484304 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.488086 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:30:27.488974 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.492007 [debug] [Thread-2 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: ROLLBACK
[0m06:30:27.494675 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:30:27.497806 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_ts
from "warehouse"."analytics_staging"."src_orders"
where order_ts is null



      
    ) dbt_internal_test
[0m06:30:27.502786 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 06:30:27.399279 => 06:30:27.502358
[0m06:30:27.506369 [debug] [Thread-2 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: Close
[0m06:30:27.507721 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_line_id
from "warehouse"."analytics_staging"."src_orders"
where order_line_id is null



      
    ) dbt_internal_test
[0m06:30:27.511379 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: ROLLBACK
[0m06:30:27.512265 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.515126 [info ] [Thread-2 (]: 5 of 10 PASS not_null_orders_enriched_line_amount .............................. [[32mPASS[0m in 0.25s]
[0m06:30:27.518090 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: Close
[0m06:30:27.519037 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.522371 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 06:30:27.409719 => 06:30:27.521924
[0m06:30:27.525096 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:27.528514 [info ] [Thread-1 (]: 6 of 10 PASS not_null_src_orders_order_id ...................................... [[32mPASS[0m in 0.22s]
[0m06:30:27.532773 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 06:30:27.417681 => 06:30:27.532295
[0m06:30:27.535226 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: ROLLBACK
[0m06:30:27.538975 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:27.542235 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:27.544402 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: ROLLBACK
[0m06:30:27.547060 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: Close
[0m06:30:27.549019 [info ] [Thread-2 (]: 9 of 10 START test not_null_src_orders_quantity ................................ [RUN]
[0m06:30:27.551369 [debug] [Thread-1 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:27.567806 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: Close
[0m06:30:27.573086 [info ] [Thread-3 (]: 8 of 10 PASS not_null_src_orders_order_ts ...................................... [[32mPASS[0m in 0.25s]
[0m06:30:27.576324 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m06:30:27.579296 [info ] [Thread-1 (]: 10 of 10 START test unique_fct_daily_sales_sales_date .......................... [RUN]
[0m06:30:27.583565 [info ] [Thread-4 (]: 7 of 10 PASS not_null_src_orders_order_line_id ................................. [[32mPASS[0m in 0.27s]
[0m06:30:27.586059 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:27.589383 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:27.592527 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m06:30:27.595772 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:27.614169 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:30:27.616068 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:27.640350 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:30:27.646631 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 06:30:27.600490 => 06:30:27.646136
[0m06:30:27.648401 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:27.654701 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:30:27.659080 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 06:30:27.622838 => 06:30:27.658521
[0m06:30:27.661965 [debug] [Thread-1 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:27.670047 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:30:27.685568 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:30:27.688818 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: BEGIN
[0m06:30:27.691458 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:30:27.692562 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:30:27.696722 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: BEGIN
[0m06:30:27.698900 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:30:27.707131 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.710353 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:30:27.712351 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.713228 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "warehouse"."analytics_staging"."src_orders"
where quantity is null



      
    ) dbt_internal_test
[0m06:30:27.715244 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:30:27.718640 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    sales_date as unique_field,
    count(*) as n_records

from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is not null
group by sales_date
having count(*) > 1



      
    ) dbt_internal_test
[0m06:30:27.719963 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.722355 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:27.724981 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 06:30:27.650092 => 06:30:27.724617
[0m06:30:27.729969 [debug] [Thread-1 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 06:30:27.664647 => 06:30:27.729394
[0m06:30:27.732690 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: ROLLBACK
[0m06:30:27.735374 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: ROLLBACK
[0m06:30:27.738415 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: Close
[0m06:30:27.740581 [debug] [Thread-1 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: Close
[0m06:30:27.743266 [info ] [Thread-2 (]: 9 of 10 PASS not_null_src_orders_quantity ...................................... [[32mPASS[0m in 0.17s]
[0m06:30:27.745917 [info ] [Thread-1 (]: 10 of 10 PASS unique_fct_daily_sales_sales_date ................................ [[32mPASS[0m in 0.15s]
[0m06:30:27.747621 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:27.749738 [debug] [Thread-1 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:27.756790 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:27.758536 [debug] [MainThread]: On master: BEGIN
[0m06:30:27.760690 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:30:27.773597 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:27.775825 [debug] [MainThread]: On master: COMMIT
[0m06:30:27.777962 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:27.779761 [debug] [MainThread]: On master: COMMIT
[0m06:30:27.782474 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m06:30:27.784837 [debug] [MainThread]: On master: Close
[0m06:30:27.787556 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:30:27.788907 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_line_id.c30084a184' was properly closed.
[0m06:30:27.790539 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m06:30:27.793835 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992' was properly closed.
[0m06:30:27.796221 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_quantity.741e0fed47' was properly closed.
[0m06:30:27.798623 [info ] [MainThread]: 
[0m06:30:27.800344 [info ] [MainThread]: Finished running 10 tests in 0 hours 0 minutes and 1.02 seconds (1.02s).
[0m06:30:27.804586 [debug] [MainThread]: Command end result
[0m06:30:27.850071 [info ] [MainThread]: 
[0m06:30:27.852093 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:30:27.854149 [info ] [MainThread]: 
[0m06:30:27.855945 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
[0m06:30:27.859178 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.9718663, "process_user_time": 5.160181, "process_kernel_time": 0.246662, "process_mem_max_rss": "122160", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:30:27.863363 [debug] [MainThread]: Command `dbt test` succeeded at 06:30:27.862918 after 1.98 seconds
[0m06:30:27.865515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8547174d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe854717310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe854de69d0>]}
[0m06:30:27.867937 [debug] [MainThread]: Flushing usage events
[0m06:30:34.523305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c5a841d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c5a7e890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c5a84390>]}


============================== 06:30:34.534734 | 9aa8ce49-9f82-4309-a7ce-d53f4e012a2b ==============================
[0m06:30:34.534734 [info ] [MainThread]: Running with dbt=1.7.11
[0m06:30:34.536943 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'invocation_command': 'dbt docs generate', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:30:34.806510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9aa8ce49-9f82-4309-a7ce-d53f4e012a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c510ed50>]}
[0m06:30:34.932372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9aa8ce49-9f82-4309-a7ce-d53f4e012a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c54d5fd0>]}
[0m06:30:34.935479 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m06:30:34.964095 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m06:30:35.280627 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:30:35.282389 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:30:35.293226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9aa8ce49-9f82-4309-a7ce-d53f4e012a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c4d6cf90>]}
[0m06:30:35.307003 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9aa8ce49-9f82-4309-a7ce-d53f4e012a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c4db31d0>]}
[0m06:30:35.308735 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m06:30:35.310950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9aa8ce49-9f82-4309-a7ce-d53f4e012a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c5588e50>]}
[0m06:30:35.315140 [info ] [MainThread]: 
[0m06:30:35.317511 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:30:35.322553 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m06:30:35.324688 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m06:30:35.327774 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m06:30:35.331046 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m06:30:35.354179 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:35.357769 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:35.362798 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:35.368211 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:35.370155 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m06:30:35.372470 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m06:30:35.374329 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m06:30:35.376443 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m06:30:35.378433 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:35.380545 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:35.382504 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:35.384548 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:35.397029 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:35.398319 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:35.399340 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m06:30:35.400114 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:35.400631 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:35.402361 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m06:30:35.404323 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m06:30:35.406312 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m06:30:35.408315 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m06:30:35.410547 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m06:30:35.413736 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m06:30:35.415219 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m06:30:35.416752 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:35.420129 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m06:30:35.423306 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m06:30:35.423896 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:35.424417 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:35.427440 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m06:30:35.430005 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m06:30:35.432878 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m06:30:35.435824 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m06:30:35.438110 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m06:30:35.441882 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m06:30:35.443767 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m06:30:35.458034 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:35.460592 [debug] [MainThread]: On master: BEGIN
[0m06:30:35.462499 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:30:35.472634 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m06:30:35.474559 [debug] [MainThread]: Using postgres connection "master"
[0m06:30:35.476984 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:30:35.484859 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m06:30:35.489451 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9aa8ce49-9f82-4309-a7ce-d53f4e012a2b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c6709290>]}
[0m06:30:35.491842 [debug] [MainThread]: On master: ROLLBACK
[0m06:30:35.494628 [debug] [MainThread]: On master: Close
[0m06:30:35.497627 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:30:35.499476 [info ] [MainThread]: 
[0m06:30:35.515609 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m06:30:35.518664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m06:30:35.520791 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m06:30:35.537357 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m06:30:35.565070 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 06:30:35.522557 => 06:30:35.564265
[0m06:30:35.568556 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m06:30:35.571783 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 06:30:35.571320 => 06:30:35.571349
[0m06:30:35.576094 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m06:30:35.581136 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m06:30:35.582499 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m06:30:35.583374 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:35.584323 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:35.586529 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.orders_enriched)
[0m06:30:35.589734 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m06:30:35.593513 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m06:30:35.596797 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m06:30:35.599584 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m06:30:35.602358 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m06:30:35.604418 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:35.607292 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:35.615210 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m06:30:35.623665 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 06:30:35.617355 => 06:30:35.623187
[0m06:30:35.658051 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m06:30:35.662587 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m06:30:35.666542 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m06:30:35.672944 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 06:30:35.672236 => 06:30:35.672291
[0m06:30:35.679159 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m06:30:35.683739 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 06:30:35.625750 => 06:30:35.683085
[0m06:30:35.684910 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:35.686004 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 06:30:35.610053 => 06:30:35.685522
[0m06:30:35.688978 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:35.690150 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 06:30:35.648536 => 06:30:35.689502
[0m06:30:35.692212 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m06:30:35.694123 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m06:30:35.695858 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 06:30:35.695448 => 06:30:35.695476
[0m06:30:35.697407 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:35.699386 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:35.701862 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 06:30:35.701362 => 06:30:35.701391
[0m06:30:35.705395 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m06:30:35.708143 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 06:30:35.707724 => 06:30:35.707745
[0m06:30:35.718724 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m06:30:35.721812 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m06:30:35.724285 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:35.727864 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m06:30:35.747464 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m06:30:35.751922 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m06:30:35.754570 [debug] [Thread-1 (]: Began running node model.sales_analytics.fct_daily_sales
[0m06:30:35.757568 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.dim_customer)
[0m06:30:35.760454 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:35.763668 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.fct_daily_sales)
[0m06:30:35.766348 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m06:30:35.774840 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 06:30:35.710360 => 06:30:35.774206
[0m06:30:35.782478 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m06:30:35.784222 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m06:30:35.793741 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m06:30:35.795894 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:35.818799 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m06:30:35.821878 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 06:30:35.821333 => 06:30:35.821361
[0m06:30:35.823168 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 06:30:35.768533 => 06:30:35.822691
[0m06:30:35.827756 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m06:30:35.830033 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:35.831164 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 06:30:35.786590 => 06:30:35.830599
[0m06:30:35.833100 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:35.834375 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 06:30:35.799437 => 06:30:35.833941
[0m06:30:35.836498 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 06:30:35.836092 => 06:30:35.836108
[0m06:30:35.838986 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m06:30:35.841808 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m06:30:35.844031 [debug] [Thread-1 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m06:30:35.847260 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m06:30:35.849677 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 06:30:35.849235 => 06:30:35.849252
[0m06:30:35.851811 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:35.854365 [debug] [Thread-1 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 06:30:35.853913 => 06:30:35.853931
[0m06:30:35.859176 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m06:30:35.869740 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m06:30:35.872914 [debug] [Thread-1 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m06:30:35.875897 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:35.880477 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:35.881225 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:35.882901 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m06:30:35.885551 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m06:30:35.888851 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m06:30:35.891617 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:35.893951 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:35.896423 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:35.904865 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 06:30:35.861350 => 06:30:35.904392
[0m06:30:35.908747 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m06:30:35.918941 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m06:30:35.929299 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m06:30:35.931610 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:35.942272 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 06:30:35.941800 => 06:30:35.941816
[0m06:30:35.945326 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m06:30:35.947670 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:35.950241 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 06:30:35.898948 => 06:30:35.949728
[0m06:30:35.951639 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 06:30:35.920952 => 06:30:35.951083
[0m06:30:35.953473 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m06:30:35.954540 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 06:30:35.910853 => 06:30:35.954114
[0m06:30:35.956049 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:35.957640 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:35.959135 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:35.961106 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:35.962741 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 06:30:35.962363 => 06:30:35.962383
[0m06:30:35.964329 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 06:30:35.963969 => 06:30:35.963988
[0m06:30:35.974191 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m06:30:35.976589 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 06:30:35.975937 => 06:30:35.975955
[0m06:30:35.979702 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m06:30:35.982865 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m06:30:35.989110 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m06:30:35.991329 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:35.997169 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m06:30:35.999499 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:36.014101 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m06:30:36.016869 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 06:30:35.965554 => 06:30:36.016374
[0m06:30:36.018878 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:36.020976 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 06:30:36.020539 => 06:30:36.020558
[0m06:30:36.024071 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m06:30:36.033207 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 06:30:36.001446 => 06:30:36.032759
[0m06:30:36.035782 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:36.037942 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 06:30:36.037565 => 06:30:36.037595
[0m06:30:36.041180 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m06:30:36.045302 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:30:36.047442 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m06:30:36.049606 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m06:30:36.051821 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m06:30:36.053898 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m06:30:36.058932 [debug] [MainThread]: Command end result
[0m06:30:36.132188 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m06:30:36.134108 [info ] [MainThread]: Building catalog
[0m06:30:36.140854 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m06:30:36.159610 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m06:30:36.162329 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m06:30:36.165394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:30:36.176059 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m06:30:36.177854 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m06:30:36.180062 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m06:30:36.187628 [debug] [ThreadPool]: SQL status: SELECT 41 in 0.0 seconds
[0m06:30:36.198045 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m06:30:36.200064 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m06:30:36.243348 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m06:30:36.246468 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.8176692, "process_user_time": 4.902367, "process_kernel_time": 0.235395, "process_mem_max_rss": "120924", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m06:30:36.248403 [debug] [MainThread]: Command `dbt docs generate` succeeded at 06:30:36.248162 after 1.82 seconds
[0m06:30:36.250099 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m06:30:36.252024 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m06:30:36.254041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c5ad2c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c5ae3750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5c6e6b4d0>]}
[0m06:30:36.255860 [debug] [MainThread]: Flushing usage events
[0m14:10:27.408386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872e75b3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872d37f990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872d37dc50>]}


============================== 14:10:27.419123 | 6ec23043-3e8d-40b4-a48c-eb9765958bec ==============================
[0m14:10:27.419123 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:10:27.420858 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m14:10:27.565122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6ec23043-3e8d-40b4-a48c-eb9765958bec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872d3cac50>]}
[0m14:10:27.568699 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:10:27.578070 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m14:10:27.581092 [debug] [MainThread]: Resource report: {"command_name": "deps", "command_success": true, "command_wall_clock_time": 0.24730004, "process_user_time": 4.197015, "process_kernel_time": 0.505291, "process_mem_max_rss": "105096", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:10:27.583457 [debug] [MainThread]: Command `dbt deps` succeeded at 14:10:27.583184 after 0.25 seconds
[0m14:10:27.585100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872d3ca890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872d573010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f872ea92290>]}
[0m14:10:27.587603 [debug] [MainThread]: Flushing usage events
[0m14:10:38.344678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4856d9b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4869e1a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe486476050>]}


============================== 14:10:38.354645 | b854fcd6-a1bf-4e2b-bc44-45e893db737e ==============================
[0m14:10:38.354645 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:10:38.356399 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'profiles_dir': '/usr/app', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select staging intermediate', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m14:10:38.613856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4868cb450>]}
[0m14:10:38.740386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4868cb450>]}
[0m14:10:38.743091 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m14:10:38.767720 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m14:10:39.063125 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:10:39.065447 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:10:39.077005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4843a8150>]}
[0m14:10:39.136621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe484737250>]}
[0m14:10:39.138562 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:10:39.140251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe48477eed0>]}
[0m14:10:39.143363 [info ] [MainThread]: 
[0m14:10:39.145424 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:10:39.149526 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m14:10:39.151237 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m14:10:39.168541 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m14:10:39.172129 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m14:10:39.173855 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m14:10:39.175533 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m14:10:39.177085 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:39.178475 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:39.195609 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m14:10:39.196228 [debug] [ThreadPool]: SQL status: SELECT 10 in 0.0 seconds
[0m14:10:39.198954 [debug] [ThreadPool]: On list_warehouse: Close
[0m14:10:39.201913 [debug] [ThreadPool]: On list_warehouse: Close
[0m14:10:39.206706 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_staging)
[0m14:10:39.208184 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_intermediate)
[0m14:10:39.211028 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_staging"
"
[0m14:10:39.213141 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_intermediate"
"
[0m14:10:39.223106 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m14:10:39.227712 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m14:10:39.229397 [debug] [ThreadPool]: On create_warehouse_analytics_staging: BEGIN
[0m14:10:39.231114 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: BEGIN
[0m14:10:39.232821 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:39.234482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:39.244413 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.245904 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.246516 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m14:10:39.248530 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m14:10:39.250220 [debug] [ThreadPool]: On create_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_staging"} */
create schema if not exists "analytics_staging"
[0m14:10:39.252100 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_intermediate"} */
create schema if not exists "analytics_intermediate"
[0m14:10:39.254621 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m14:10:39.255744 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m14:10:39.257670 [debug] [ThreadPool]: On create_warehouse_analytics_staging: COMMIT
[0m14:10:39.260369 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: COMMIT
[0m14:10:39.262300 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_staging"
[0m14:10:39.264296 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_intermediate"
[0m14:10:39.266117 [debug] [ThreadPool]: On create_warehouse_analytics_staging: COMMIT
[0m14:10:39.268032 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: COMMIT
[0m14:10:39.274753 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m14:10:39.276618 [debug] [ThreadPool]: On create_warehouse_analytics_staging: Close
[0m14:10:39.298443 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m14:10:39.300999 [debug] [ThreadPool]: On create_warehouse_analytics_intermediate: Close
[0m14:10:39.307232 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_staging, now list_warehouse_analytics_marts)
[0m14:10:39.308851 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_intermediate, now list_warehouse_analytics_staging)
[0m14:10:39.310047 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m14:10:39.311273 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m14:10:39.318323 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:39.321791 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:39.324929 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:39.328790 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:39.330898 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m14:10:39.332916 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m14:10:39.334747 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m14:10:39.337978 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m14:10:39.339739 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:39.341185 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:39.342182 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:39.343403 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:39.350827 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.351281 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.352329 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:39.352806 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.353227 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.354527 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:39.356685 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m14:10:39.358333 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:39.359733 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:39.362205 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m14:10:39.366324 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m14:10:39.367861 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m14:10:39.368473 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:39.372153 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:39.373738 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m14:10:39.374278 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:39.374736 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:39.376804 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m14:10:39.378561 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m14:10:39.380698 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m14:10:39.383531 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m14:10:39.385692 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m14:10:39.388604 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m14:10:39.389861 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m14:10:39.400821 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:39.402451 [debug] [MainThread]: On master: BEGIN
[0m14:10:39.404022 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:10:39.412151 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.413605 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:39.415031 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:10:39.420725 [debug] [MainThread]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:39.422940 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe483fa3650>]}
[0m14:10:39.424337 [debug] [MainThread]: On master: ROLLBACK
[0m14:10:39.425646 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:39.426690 [debug] [MainThread]: On master: BEGIN
[0m14:10:39.428070 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.428875 [debug] [MainThread]: On master: COMMIT
[0m14:10:39.429762 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:39.430591 [debug] [MainThread]: On master: COMMIT
[0m14:10:39.431548 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:39.432473 [debug] [MainThread]: On master: Close
[0m14:10:39.433985 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:10:39.435204 [info ] [MainThread]: 
[0m14:10:39.447429 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m14:10:39.449443 [info ] [Thread-1 (]: 1 of 2 START sql view model analytics_staging.src_orders ....................... [RUN]
[0m14:10:39.451612 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.src_orders)
[0m14:10:39.452986 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m14:10:39.475523 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m14:10:39.578295 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 14:10:39.454106 => 14:10:39.577309
[0m14:10:39.580781 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m14:10:39.652868 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.src_orders"
[0m14:10:39.666968 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.668754 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: BEGIN
[0m14:10:39.670455 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:10:39.679448 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.681558 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.683918 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

  create view "warehouse"."analytics_staging"."src_orders__dbt_tmp"
    
    
  as (
    select
  cast(order_id as bigint)              as order_id,
  cast(order_line_id as bigint)         as order_line_id,
  cast(order_ts as timestamp)           as order_ts,
  cast(customer_id as bigint)           as customer_id,
  cast(product_id as bigint)            as product_id,
  cast(quantity as integer)             as quantity,
  cast(unit_price as numeric(12,2))     as unit_price,
  cast(currency as varchar(3))          as currency,
  cast(country as varchar(64))          as country,
  cast(status as varchar(16))           as status,
  cast(updated_at as timestamp)         as updated_at
from raw.orders
  );
[0m14:10:39.688325 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.0 seconds
[0m14:10:39.703196 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.704872 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
alter table "warehouse"."analytics_staging"."src_orders__dbt_tmp" rename to "src_orders"
[0m14:10:39.706801 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:10:39.740795 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.742924 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  comment on view "warehouse"."analytics_staging"."src_orders" is $dbt_comment_literal_block$Cleanly typed view over raw.orders$dbt_comment_literal_block$;

  
[0m14:10:39.745241 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:39.768125 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.770666 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'src_orders'
        
        and table_schema = 'analytics_staging'
        
      order by ordinal_position

  
[0m14:10:39.783216 [debug] [Thread-1 (]: SQL status: SELECT 11 in 0.0 seconds
[0m14:10:39.792953 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.795442 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_line_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".order_ts is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_staging"."src_orders".quantity is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m14:10:39.798145 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:39.801950 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m14:10:39.804106 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.806342 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: COMMIT
[0m14:10:39.821478 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:10:39.834461 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_staging"."src_orders__dbt_backup"
[0m14:10:39.847594 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.src_orders"
[0m14:10:39.849480 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.src_orders"} */
drop view if exists "warehouse"."analytics_staging"."src_orders__dbt_backup" cascade
[0m14:10:39.851467 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.0 seconds
[0m14:10:39.854542 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 14:10:39.582652 => 14:10:39.854198
[0m14:10:39.856283 [debug] [Thread-1 (]: On model.sales_analytics.src_orders: Close
[0m14:10:39.858823 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe483f91850>]}
[0m14:10:39.860878 [info ] [Thread-1 (]: 1 of 2 OK created sql view model analytics_staging.src_orders .................. [[32mCREATE VIEW[0m in 0.41s]
[0m14:10:39.862679 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m14:10:39.864993 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m14:10:39.866495 [info ] [Thread-3 (]: 2 of 2 START sql table model analytics_intermediate.orders_enriched ............ [RUN]
[0m14:10:39.868542 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.orders_enriched)
[0m14:10:39.870164 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m14:10:39.876102 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m14:10:39.896324 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 14:10:39.871444 => 14:10:39.895839
[0m14:10:39.898047 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m14:10:39.944848 [debug] [Thread-3 (]: Writing runtime sql for node "model.sales_analytics.orders_enriched"
[0m14:10:39.959434 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:39.961687 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: BEGIN
[0m14:10:39.964640 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m14:10:39.976098 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:39.978330 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:39.980090 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

  
    

  create  table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp"
  
  
    as
  
  (
    with base as (
  select * from "warehouse"."analytics_staging"."src_orders"
  where status = 'completed'
)
select
  order_id,
  order_line_id,
  order_ts,
  customer_id,
  product_id,
  quantity,
  unit_price,
  currency,
  country,
  status,
  updated_at,
  (quantity * unit_price)::numeric(14,2) as line_amount
from base
  );
  
[0m14:10:39.995073 [debug] [Thread-3 (]: SQL status: SELECT 4291 in 0.0 seconds
[0m14:10:40.001831 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:40.003904 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
alter table "warehouse"."analytics_intermediate"."orders_enriched__dbt_tmp" rename to "orders_enriched"
[0m14:10:40.006383 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:10:40.020870 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:40.023046 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  comment on table "warehouse"."analytics_intermediate"."orders_enriched" is $dbt_comment_literal_block$Completed order lines with computed line_amount$dbt_comment_literal_block$;

  
[0m14:10:40.026401 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:40.034900 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:40.036919 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'orders_enriched'
        
        and table_schema = 'analytics_intermediate'
        
      order by ordinal_position

  
[0m14:10:40.048239 [debug] [Thread-3 (]: SQL status: SELECT 12 in 0.0 seconds
[0m14:10:40.052967 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:40.055005 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_intermediate"."orders_enriched".line_amount is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m14:10:40.057119 [debug] [Thread-3 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:40.061105 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m14:10:40.062843 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:40.064400 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: COMMIT
[0m14:10:40.076785 [debug] [Thread-3 (]: SQL status: COMMIT in 0.0 seconds
[0m14:10:40.082128 [debug] [Thread-3 (]: Applying DROP to: "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup"
[0m14:10:40.087838 [debug] [Thread-3 (]: Using postgres connection "model.sales_analytics.orders_enriched"
[0m14:10:40.089519 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.orders_enriched"} */
drop table if exists "warehouse"."analytics_intermediate"."orders_enriched__dbt_backup" cascade
[0m14:10:40.093117 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:10:40.097213 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 14:10:39.899369 => 14:10:40.096884
[0m14:10:40.098725 [debug] [Thread-3 (]: On model.sales_analytics.orders_enriched: Close
[0m14:10:40.100654 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b854fcd6-a1bf-4e2b-bc44-45e893db737e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4847993d0>]}
[0m14:10:40.102216 [info ] [Thread-3 (]: 2 of 2 OK created sql table model analytics_intermediate.orders_enriched ....... [[32mSELECT 4291[0m in 0.23s]
[0m14:10:40.103964 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m14:10:40.108036 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:40.109940 [debug] [MainThread]: On master: BEGIN
[0m14:10:40.111262 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:10:40.119351 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:40.121491 [debug] [MainThread]: On master: COMMIT
[0m14:10:40.122741 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:40.124327 [debug] [MainThread]: On master: COMMIT
[0m14:10:40.127036 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:40.129152 [debug] [MainThread]: On master: Close
[0m14:10:40.131418 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:10:40.133108 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m14:10:40.135029 [debug] [MainThread]: Connection 'model.sales_analytics.orders_enriched' was properly closed.
[0m14:10:40.136666 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m14:10:40.138153 [debug] [MainThread]: Connection 'model.sales_analytics.src_orders' was properly closed.
[0m14:10:40.140111 [info ] [MainThread]: 
[0m14:10:40.142617 [info ] [MainThread]: Finished running 1 view model, 1 table model in 0 hours 0 minutes and 1.00 seconds (1.00s).
[0m14:10:40.144927 [debug] [MainThread]: Command end result
[0m14:10:40.181667 [info ] [MainThread]: 
[0m14:10:40.185030 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:10:40.186864 [info ] [MainThread]: 
[0m14:10:40.188746 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m14:10:40.192821 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.9492623, "process_user_time": 9.843612, "process_kernel_time": 0.441057, "process_mem_max_rss": "122340", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:10:40.195108 [debug] [MainThread]: Command `dbt run` succeeded at 14:10:40.194710 after 1.95 seconds
[0m14:10:40.196880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4862aaf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe48a24fc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe48a24fdd0>]}
[0m14:10:40.198493 [debug] [MainThread]: Flushing usage events
[0m14:10:44.592491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac51c2c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac51c0350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac51c3390>]}


============================== 14:10:44.600912 | b1f18f5e-6806-49fe-ac55-21b685022bfa ==============================
[0m14:10:44.600912 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:10:44.603165 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/usr/app/logs', 'debug': 'False', 'profiles_dir': '/usr/app', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt snapshot', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:10:44.855219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1f18f5e-6806-49fe-ac55-21b685022bfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac4991510>]}
[0m14:10:44.983109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1f18f5e-6806-49fe-ac55-21b685022bfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac5205b10>]}
[0m14:10:44.985451 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m14:10:45.005369 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m14:10:45.211860 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:10:45.213660 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:10:45.222948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1f18f5e-6806-49fe-ac55-21b685022bfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac416c390>]}
[0m14:10:45.260251 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1f18f5e-6806-49fe-ac55-21b685022bfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac4589110>]}
[0m14:10:45.262213 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:10:45.263794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1f18f5e-6806-49fe-ac55-21b685022bfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac45949d0>]}
[0m14:10:45.267124 [info ] [MainThread]: 
[0m14:10:45.269848 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:10:45.274496 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m14:10:45.293444 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m14:10:45.295711 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m14:10:45.297312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:45.309151 [debug] [ThreadPool]: SQL status: SELECT 12 in 0.0 seconds
[0m14:10:45.312394 [debug] [ThreadPool]: On list_warehouse: Close
[0m14:10:45.315751 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_snapshots)
[0m14:10:45.318164 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "snapshots"
"
[0m14:10:45.332349 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m14:10:45.334091 [debug] [ThreadPool]: On create_warehouse_snapshots: BEGIN
[0m14:10:45.335629 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:45.347156 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.349045 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m14:10:45.350364 [debug] [ThreadPool]: On create_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_snapshots"} */
create schema if not exists "snapshots"
[0m14:10:45.352255 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m14:10:45.354899 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m14:10:45.356515 [debug] [ThreadPool]: Using postgres connection "create_warehouse_snapshots"
[0m14:10:45.358154 [debug] [ThreadPool]: On create_warehouse_snapshots: COMMIT
[0m14:10:45.364429 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m14:10:45.366283 [debug] [ThreadPool]: On create_warehouse_snapshots: Close
[0m14:10:45.372060 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_snapshots, now list_warehouse_analytics_intermediate)
[0m14:10:45.373870 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m14:10:45.375819 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m14:10:45.377925 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m14:10:45.389491 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:45.393802 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:45.398923 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:45.404541 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:45.406479 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m14:10:45.408340 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m14:10:45.410041 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m14:10:45.411650 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m14:10:45.413366 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:45.414754 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:45.416166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:45.417615 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:45.429309 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.430810 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.432671 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.433400 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:45.434512 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.435457 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:45.437043 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:45.438780 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m14:10:45.440431 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:45.442198 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m14:10:45.443958 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m14:10:45.446950 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m14:10:45.451134 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:45.454965 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m14:10:45.455820 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:45.456433 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:45.457061 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:45.458632 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m14:10:45.461918 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m14:10:45.465068 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m14:10:45.468674 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m14:10:45.473349 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m14:10:45.474551 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m14:10:45.476056 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m14:10:45.491514 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:45.493200 [debug] [MainThread]: On master: BEGIN
[0m14:10:45.494531 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:10:45.506574 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.508708 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:45.510690 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:10:45.524182 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:45.529710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1f18f5e-6806-49fe-ac55-21b685022bfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac45ec610>]}
[0m14:10:45.532040 [debug] [MainThread]: On master: ROLLBACK
[0m14:10:45.534226 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:45.536133 [debug] [MainThread]: On master: BEGIN
[0m14:10:45.544120 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.546306 [debug] [MainThread]: On master: COMMIT
[0m14:10:45.548277 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:45.550191 [debug] [MainThread]: On master: COMMIT
[0m14:10:45.552341 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:45.554335 [debug] [MainThread]: On master: Close
[0m14:10:45.557934 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:10:45.560948 [info ] [MainThread]: 
[0m14:10:45.583519 [debug] [Thread-1 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m14:10:45.586016 [info ] [Thread-1 (]: 1 of 1 START snapshot snapshots.customers_snapshot ............................. [RUN]
[0m14:10:45.589125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m14:10:45.591759 [debug] [Thread-1 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m14:10:45.610776 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 14:10:45.593949 => 14:10:45.610282
[0m14:10:45.612595 [debug] [Thread-1 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m14:10:45.710424 [debug] [Thread-1 (]: Writing runtime sql for node "snapshot.sales_analytics.customers_snapshot"
[0m14:10:45.721838 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m14:10:45.723512 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: BEGIN
[0m14:10:45.724952 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:10:45.734058 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.735583 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m14:10:45.736989 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "snapshot.sales_analytics.customers_snapshot"} */

      
  
    

  create  table "warehouse"."snapshots"."customers_snapshot"
  
  
    as
  
  (
    

    select *,
        md5(coalesce(cast(customer_id as varchar ), '')
         || '|' || coalesce(cast(updated_at as varchar ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        nullif(updated_at, updated_at) as dbt_valid_to
    from (
        


-- Derive latest customer attributes from staging
select
  customer_id,
  country,
  status,
  updated_at
from "warehouse"."analytics_staging"."src_orders"

    ) sbq



  );
  
  
[0m14:10:45.762597 [debug] [Thread-1 (]: SQL status: SELECT 5000 in 0.0 seconds
[0m14:10:45.795655 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m14:10:45.797907 [debug] [Thread-1 (]: Using postgres connection "snapshot.sales_analytics.customers_snapshot"
[0m14:10:45.799290 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: COMMIT
[0m14:10:45.805060 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:10:45.807421 [debug] [Thread-1 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 14:10:45.613978 => 14:10:45.807135
[0m14:10:45.808948 [debug] [Thread-1 (]: On snapshot.sales_analytics.customers_snapshot: Close
[0m14:10:45.811040 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b1f18f5e-6806-49fe-ac55-21b685022bfa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac45210d0>]}
[0m14:10:45.812987 [info ] [Thread-1 (]: 1 of 1 OK snapshotted snapshots.customers_snapshot ............................. [[32mSELECT 5000[0m in 0.22s]
[0m14:10:45.814854 [debug] [Thread-1 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m14:10:45.818601 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:45.819747 [debug] [MainThread]: On master: BEGIN
[0m14:10:45.820862 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:10:45.828548 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:45.830035 [debug] [MainThread]: On master: COMMIT
[0m14:10:45.831506 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:45.832804 [debug] [MainThread]: On master: COMMIT
[0m14:10:45.834385 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:45.835851 [debug] [MainThread]: On master: Close
[0m14:10:45.839382 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:10:45.841400 [debug] [MainThread]: Connection 'list_warehouse_analytics_intermediate' was properly closed.
[0m14:10:45.843543 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m14:10:45.845588 [debug] [MainThread]: Connection 'snapshot.sales_analytics.customers_snapshot' was properly closed.
[0m14:10:45.847572 [debug] [MainThread]: Connection 'list_warehouse_analytics_staging' was properly closed.
[0m14:10:45.849395 [info ] [MainThread]: 
[0m14:10:45.850855 [info ] [MainThread]: Finished running 1 snapshot in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m14:10:45.853087 [debug] [MainThread]: Command end result
[0m14:10:45.887564 [info ] [MainThread]: 
[0m14:10:45.889642 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:10:45.891427 [info ] [MainThread]: 
[0m14:10:45.893202 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m14:10:45.895605 [debug] [MainThread]: Resource report: {"command_name": "snapshot", "command_success": true, "command_wall_clock_time": 1.3829541, "process_user_time": 4.645884, "process_kernel_time": 0.090897, "process_mem_max_rss": "121964", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:10:45.897590 [debug] [MainThread]: Command `dbt snapshot` succeeded at 14:10:45.897347 after 1.39 seconds
[0m14:10:45.899388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac52173d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac65fb110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac9d577d0>]}
[0m14:10:45.901357 [debug] [MainThread]: Flushing usage events
[0m14:10:52.690938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d693a7ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d690dec10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d690de590>]}


============================== 14:10:52.703741 | 89a31299-d613-4959-873f-6d8a698d74da ==============================
[0m14:10:52.703741 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:10:52.706151 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/usr/app/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --select marts', 'send_anonymous_usage_stats': 'True'}
[0m14:10:52.976309 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d683fabd0>]}
[0m14:10:53.103087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d68ff2690>]}
[0m14:10:53.106145 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m14:10:53.131497 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m14:10:53.484576 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:10:53.486153 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:10:53.496523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d67b80990>]}
[0m14:10:53.540212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d68f32b90>]}
[0m14:10:53.541895 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:10:53.543426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d6c6ba950>]}
[0m14:10:53.547452 [info ] [MainThread]: 
[0m14:10:53.549934 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:10:53.552997 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse'
[0m14:10:53.570915 [debug] [ThreadPool]: Using postgres connection "list_warehouse"
[0m14:10:53.573010 [debug] [ThreadPool]: On list_warehouse: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse"} */

    select distinct nspname from pg_namespace
  
[0m14:10:53.574539 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:53.587279 [debug] [ThreadPool]: SQL status: SELECT 13 in 0.0 seconds
[0m14:10:53.590489 [debug] [ThreadPool]: On list_warehouse: Close
[0m14:10:53.593608 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_warehouse, now create_warehouse_analytics_marts)
[0m14:10:53.595839 [debug] [ThreadPool]: Creating schema "database: "warehouse"
schema: "analytics_marts"
"
[0m14:10:53.605404 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m14:10:53.607660 [debug] [ThreadPool]: On create_warehouse_analytics_marts: BEGIN
[0m14:10:53.609467 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:53.618818 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:53.620854 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m14:10:53.623217 [debug] [ThreadPool]: On create_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "create_warehouse_analytics_marts"} */
create schema if not exists "analytics_marts"
[0m14:10:53.626142 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.0 seconds
[0m14:10:53.629851 [debug] [ThreadPool]: On create_warehouse_analytics_marts: COMMIT
[0m14:10:53.631943 [debug] [ThreadPool]: Using postgres connection "create_warehouse_analytics_marts"
[0m14:10:53.633606 [debug] [ThreadPool]: On create_warehouse_analytics_marts: COMMIT
[0m14:10:53.653803 [debug] [ThreadPool]: SQL status: COMMIT in 0.0 seconds
[0m14:10:53.656653 [debug] [ThreadPool]: On create_warehouse_analytics_marts: Close
[0m14:10:53.665058 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_warehouse_analytics_marts, now list_warehouse_analytics_marts)
[0m14:10:53.667625 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m14:10:53.670312 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m14:10:53.684623 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m14:10:53.683544 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:53.690907 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:53.695475 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:53.698887 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:53.700838 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m14:10:53.702687 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m14:10:53.704540 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m14:10:53.706319 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m14:10:53.708473 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m14:10:53.710543 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:53.712714 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:53.714651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:53.725933 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:53.726574 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:53.727596 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:53.728186 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:53.729881 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:53.732037 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:53.732615 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:53.734399 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m14:10:53.736637 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m14:10:53.738944 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m14:10:53.740479 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:53.744393 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:53.744782 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m14:10:53.745248 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.0 seconds
[0m14:10:53.747369 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m14:10:53.747865 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:53.750475 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m14:10:53.751096 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:53.751985 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m14:10:53.753593 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m14:10:53.754912 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m14:10:53.756650 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m14:10:53.759473 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m14:10:53.761259 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m14:10:53.768712 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:53.770190 [debug] [MainThread]: On master: BEGIN
[0m14:10:53.771513 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:10:53.779583 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:53.781374 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:53.783049 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:10:53.788470 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:53.791634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d67f43f50>]}
[0m14:10:53.793316 [debug] [MainThread]: On master: ROLLBACK
[0m14:10:53.795054 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:53.796516 [debug] [MainThread]: On master: BEGIN
[0m14:10:53.798785 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:53.800420 [debug] [MainThread]: On master: COMMIT
[0m14:10:53.802080 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:53.803652 [debug] [MainThread]: On master: COMMIT
[0m14:10:53.805543 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:53.807183 [debug] [MainThread]: On master: Close
[0m14:10:53.809519 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:10:53.810822 [info ] [MainThread]: 
[0m14:10:53.820671 [debug] [Thread-1 (]: Began running node model.sales_analytics.dim_customer
[0m14:10:53.821231 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m14:10:53.822403 [info ] [Thread-1 (]: 1 of 2 START sql table model analytics_marts.dim_customer ...................... [RUN]
[0m14:10:53.823926 [info ] [Thread-2 (]: 2 of 2 START sql incremental model analytics_marts.fct_daily_sales ............. [RUN]
[0m14:10:53.825689 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.dim_customer)
[0m14:10:53.827492 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.fct_daily_sales)
[0m14:10:53.829577 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.dim_customer
[0m14:10:53.831086 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m14:10:53.842378 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m14:10:53.857248 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m14:10:53.869932 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 14:10:53.843705 => 14:10:53.869437
[0m14:10:53.871685 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m14:10:53.872600 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (compile): 14:10:53.832193 => 14:10:53.872290
[0m14:10:53.895752 [debug] [Thread-1 (]: Began executing node model.sales_analytics.dim_customer
[0m14:10:54.008705 [debug] [Thread-2 (]: Writing runtime sql for node "model.sales_analytics.fct_daily_sales"
[0m14:10:54.004580 [debug] [Thread-1 (]: Writing runtime sql for node "model.sales_analytics.dim_customer"
[0m14:10:54.019877 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m14:10:54.020928 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.022458 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: BEGIN
[0m14:10:54.024557 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: BEGIN
[0m14:10:54.027087 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:10:54.029060 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:10:54.039960 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:54.041407 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:54.042060 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m14:10:54.044216 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.045719 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      
  
    

  create  table "warehouse"."analytics_marts"."fct_daily_sales"
  
  
    as
  
  (
    





with base as (
    select
        date_trunc('day', order_ts)::date as sales_date,
        count(distinct order_id)           as orders,
        sum(quantity)                      as units_sold,
        sum(quantity * unit_price)         as gross_revenue
    from "warehouse"."analytics_intermediate"."orders_enriched"
    where 1=1
    
    group by 1
)
select * from base
  );
  
  
[0m14:10:54.047830 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

  
    

  create  table "warehouse"."analytics_marts"."dim_customer__dbt_tmp"
  
  
    as
  
  (
    -- 

-- with current as (
--     select *
--     from "warehouse"."snapshots"."customers_snapshot"
--     where dbt_valid_to is null
-- ),

-- deduped as (
--     select
--         customer_id,
--         country,
--         status,
--         dbt_valid_from,
--         row_number() over (
--             partition by customer_id
--             order by dbt_valid_from desc
--         ) as rn
--     from current
-- )

-- select
--     customer_id,
--     country,
--     status,
--     dbt_valid_from as valid_from
-- from deduped
-- where rn = 1



with snapshot_data as (
    select
        customer_id,
        country,
        status,
        dbt_valid_from,
        dbt_valid_to
    from "warehouse"."snapshots"."customers_snapshot"
)

select
    customer_id,
    country,
    status,
    dbt_valid_from as valid_from,
    dbt_valid_to   as valid_to,
    case when dbt_valid_to is null then true else false end as is_current
from snapshot_data
order by customer_id, dbt_valid_from
  );
  
[0m14:10:54.059047 [debug] [Thread-1 (]: SQL status: SELECT 5000 in 0.0 seconds
[0m14:10:54.070467 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.071307 [debug] [Thread-2 (]: SQL status: SELECT 61 in 0.0 seconds
[0m14:10:54.073091 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
alter table "warehouse"."analytics_marts"."dim_customer__dbt_tmp" rename to "dim_customer"
[0m14:10:54.102983 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.0 seconds
[0m14:10:54.112006 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m14:10:54.124396 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.125556 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  comment on table "warehouse"."analytics_marts"."fct_daily_sales" is $dbt_comment_literal_block$Daily sales fact (incremental)$dbt_comment_literal_block$;

  
[0m14:10:54.127804 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  comment on table "warehouse"."analytics_marts"."dim_customer" is $dbt_comment_literal_block$Current SCD2 customer dimension from snapshots$dbt_comment_literal_block$;

  
[0m14:10:54.130178 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:54.131817 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:54.163578 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m14:10:54.171600 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.173233 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'fct_daily_sales'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m14:10:54.175372 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "warehouse".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'analytics_marts'
        
      order by ordinal_position

  
[0m14:10:54.186383 [debug] [Thread-2 (]: SQL status: SELECT 4 in 0.0 seconds
[0m14:10:54.187249 [debug] [Thread-1 (]: SQL status: SELECT 6 in 0.0 seconds
[0m14:10:54.195124 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m14:10:54.199422 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.201401 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".sales_date is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".orders is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."fct_daily_sales".gross_revenue is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m14:10:54.203752 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */

    
  
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".customer_id is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".status is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".country is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  
    
    
    comment on column "warehouse"."analytics_marts"."dim_customer".valid_from is $dbt_comment_literal_block$$dbt_comment_literal_block$;
  

  
[0m14:10:54.206511 [debug] [Thread-2 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:54.208482 [debug] [Thread-1 (]: SQL status: COMMENT in 0.0 seconds
[0m14:10:54.213322 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m14:10:54.216775 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: COMMIT
[0m14:10:54.218550 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.fct_daily_sales"} */

        create index if not exists idx_fct_daily_sales_sales_date on "warehouse"."analytics_marts"."fct_daily_sales" (sales_date)
      
[0m14:10:54.220183 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.222480 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: COMMIT
[0m14:10:54.233823 [debug] [Thread-1 (]: SQL status: COMMIT in 0.0 seconds
[0m14:10:54.234588 [debug] [Thread-2 (]: SQL status: CREATE INDEX in 0.0 seconds
[0m14:10:54.251091 [debug] [Thread-1 (]: Applying DROP to: "warehouse"."analytics_marts"."dim_customer__dbt_backup"
[0m14:10:54.253104 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m14:10:54.262683 [debug] [Thread-1 (]: Using postgres connection "model.sales_analytics.dim_customer"
[0m14:10:54.264062 [debug] [Thread-2 (]: Using postgres connection "model.sales_analytics.fct_daily_sales"
[0m14:10:54.265828 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "model.sales_analytics.dim_customer"} */
drop table if exists "warehouse"."analytics_marts"."dim_customer__dbt_backup" cascade
[0m14:10:54.267270 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: COMMIT
[0m14:10:54.269388 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.0 seconds
[0m14:10:54.272722 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (execute): 14:10:53.913584 => 14:10:54.272397
[0m14:10:54.273786 [debug] [Thread-2 (]: SQL status: COMMIT in 0.0 seconds
[0m14:10:54.274875 [debug] [Thread-1 (]: On model.sales_analytics.dim_customer: Close
[0m14:10:54.277121 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 14:10:53.873192 => 14:10:54.276856
[0m14:10:54.279581 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d67300190>]}
[0m14:10:54.280889 [debug] [Thread-2 (]: On model.sales_analytics.fct_daily_sales: Close
[0m14:10:54.282788 [info ] [Thread-1 (]: 1 of 2 OK created sql table model analytics_marts.dim_customer ................. [[32mSELECT 5000[0m in 0.45s]
[0m14:10:54.285180 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89a31299-d613-4959-873f-6d8a698d74da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d67302650>]}
[0m14:10:54.286753 [debug] [Thread-1 (]: Finished running node model.sales_analytics.dim_customer
[0m14:10:54.288511 [info ] [Thread-2 (]: 2 of 2 OK created sql incremental model analytics_marts.fct_daily_sales ........ [[32mSELECT 61[0m in 0.46s]
[0m14:10:54.291495 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m14:10:54.296156 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:54.299460 [debug] [MainThread]: On master: BEGIN
[0m14:10:54.300997 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:10:54.309684 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:54.311191 [debug] [MainThread]: On master: COMMIT
[0m14:10:54.312525 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:54.315047 [debug] [MainThread]: On master: COMMIT
[0m14:10:54.316687 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:54.318021 [debug] [MainThread]: On master: Close
[0m14:10:54.319917 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:10:54.321140 [debug] [MainThread]: Connection 'list_warehouse_analytics_marts' was properly closed.
[0m14:10:54.322272 [debug] [MainThread]: Connection 'list_warehouse_snapshots' was properly closed.
[0m14:10:54.323349 [debug] [MainThread]: Connection 'model.sales_analytics.fct_daily_sales' was properly closed.
[0m14:10:54.324690 [debug] [MainThread]: Connection 'model.sales_analytics.dim_customer' was properly closed.
[0m14:10:54.326004 [info ] [MainThread]: 
[0m14:10:54.327236 [info ] [MainThread]: Finished running 1 table model, 1 incremental model in 0 hours 0 minutes and 0.78 seconds (0.78s).
[0m14:10:54.330257 [debug] [MainThread]: Command end result
[0m14:10:54.359777 [info ] [MainThread]: 
[0m14:10:54.361380 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:10:54.365459 [info ] [MainThread]: 
[0m14:10:54.367339 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m14:10:54.369951 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.7847487, "process_user_time": 7.169654, "process_kernel_time": 0.121348, "process_mem_max_rss": "123124", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:10:54.371760 [debug] [MainThread]: Command `dbt run` succeeded at 14:10:54.371534 after 1.79 seconds
[0m14:10:54.373030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d68ef93d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d68f47390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4d6da9bb90>]}
[0m14:10:54.374355 [debug] [MainThread]: Flushing usage events
[0m14:10:58.350835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc4187910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc6f67bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc4d67190>]}


============================== 14:10:58.358140 | 5ec0b8f9-d649-4130-a018-ca419882be12 ==============================
[0m14:10:58.358140 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:10:58.359402 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt test', 'send_anonymous_usage_stats': 'True'}
[0m14:10:58.586101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5ec0b8f9-d649-4130-a018-ca419882be12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc42113d0>]}
[0m14:10:58.698137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5ec0b8f9-d649-4130-a018-ca419882be12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc3948590>]}
[0m14:10:58.700745 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m14:10:58.723639 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m14:10:58.853423 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:10:58.854453 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:10:58.862174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ec0b8f9-d649-4130-a018-ca419882be12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc39ffa90>]}
[0m14:10:58.894098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ec0b8f9-d649-4130-a018-ca419882be12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc35b9390>]}
[0m14:10:58.895295 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:10:58.896489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ec0b8f9-d649-4130-a018-ca419882be12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc3103a10>]}
[0m14:10:58.900982 [info ] [MainThread]: 
[0m14:10:58.903164 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:10:58.907811 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m14:10:58.909355 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m14:10:58.911523 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m14:10:58.913978 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m14:10:58.930545 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:58.933915 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:58.938052 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:58.942000 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:58.943852 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m14:10:58.945254 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m14:10:58.947579 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m14:10:58.949163 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m14:10:58.950541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:58.951915 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:58.953673 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:58.955049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:10:58.965115 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:58.965724 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:58.966643 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:58.967156 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:10:58.967697 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:10:58.969601 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:10:58.971434 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:10:58.972986 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m14:10:58.974277 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:10:58.976010 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m14:10:58.977542 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m14:10:58.979890 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m14:10:58.982832 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:58.984287 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:58.985492 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m14:10:58.989784 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m14:10:58.990499 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:58.993480 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m14:10:58.996330 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m14:10:58.998487 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m14:10:59.001046 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m14:10:59.003066 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m14:10:59.004543 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m14:10:59.008480 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m14:10:59.024326 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:59.026064 [debug] [MainThread]: On master: BEGIN
[0m14:10:59.027580 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:10:59.038639 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.040490 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:59.042425 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:10:59.053764 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.058313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ec0b8f9-d649-4130-a018-ca419882be12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc39ca510>]}
[0m14:10:59.060568 [debug] [MainThread]: On master: ROLLBACK
[0m14:10:59.062929 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:59.064438 [debug] [MainThread]: On master: BEGIN
[0m14:10:59.066523 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.068280 [debug] [MainThread]: On master: COMMIT
[0m14:10:59.069951 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:59.071786 [debug] [MainThread]: On master: COMMIT
[0m14:10:59.073646 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:59.075199 [debug] [MainThread]: On master: Close
[0m14:10:59.077664 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:10:59.079222 [info ] [MainThread]: 
[0m14:10:59.094253 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:10:59.095725 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:10:59.096508 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:10:59.097552 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:10:59.098586 [info ] [Thread-1 (]: 1 of 10 START test not_null_dim_customer_customer_id ........................... [RUN]
[0m14:10:59.100160 [info ] [Thread-2 (]: 2 of 10 START test not_null_fct_daily_sales_gross_revenue ...................... [RUN]
[0m14:10:59.101852 [info ] [Thread-3 (]: 3 of 10 START test not_null_fct_daily_sales_orders ............................. [RUN]
[0m14:10:59.103566 [info ] [Thread-4 (]: 4 of 10 START test not_null_fct_daily_sales_sales_date ......................... [RUN]
[0m14:10:59.105684 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m14:10:59.107999 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m14:10:59.111122 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m14:10:59.113364 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m14:10:59.114731 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:10:59.116150 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:10:59.117567 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:10:59.118908 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:10:59.165339 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m14:10:59.167385 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m14:10:59.176317 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m14:10:59.183998 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m14:10:59.195564 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 14:10:59.120042 => 14:10:59.194993
[0m14:10:59.196389 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 14:10:59.177669 => 14:10:59.196013
[0m14:10:59.197938 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:10:59.199076 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 14:10:59.168458 => 14:10:59.198459
[0m14:10:59.200032 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 14:10:59.143402 => 14:10:59.199602
[0m14:10:59.200927 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:10:59.225593 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:10:59.226285 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m14:10:59.228418 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:10:59.233471 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m14:10:59.238572 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m14:10:59.245360 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m14:10:59.253611 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m14:10:59.254886 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m14:10:59.255932 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: BEGIN
[0m14:10:59.256862 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m14:10:59.258197 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m14:10:59.258872 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: BEGIN
[0m14:10:59.260296 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:10:59.261553 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: BEGIN
[0m14:10:59.262854 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: BEGIN
[0m14:10:59.264061 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:10:59.266080 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m14:10:59.267410 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m14:10:59.273212 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.274807 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m14:10:59.276225 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.276892 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select customer_id
from "warehouse"."analytics_marts"."dim_customer"
where customer_id is null



      
    ) dbt_internal_test
[0m14:10:59.278113 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.278815 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.279429 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m14:10:59.282072 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m14:10:59.282732 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.283656 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m14:10:59.285201 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select gross_revenue
from "warehouse"."analytics_marts"."fct_daily_sales"
where gross_revenue is null



      
    ) dbt_internal_test
[0m14:10:59.286539 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select sales_date
from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is null



      
    ) dbt_internal_test
[0m14:10:59.290503 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 14:10:59.201918 => 14:10:59.290132
[0m14:10:59.291895 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select orders
from "warehouse"."analytics_marts"."fct_daily_sales"
where orders is null



      
    ) dbt_internal_test
[0m14:10:59.294520 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.295216 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.295790 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: ROLLBACK
[0m14:10:59.299941 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 14:10:59.241518 => 14:10:59.299498
[0m14:10:59.300719 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.303392 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 14:10:59.230029 => 14:10:59.303049
[0m14:10:59.305377 [debug] [Thread-1 (]: On test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc: Close
[0m14:10:59.306471 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: ROLLBACK
[0m14:10:59.309308 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 14:10:59.235170 => 14:10:59.308939
[0m14:10:59.310775 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: ROLLBACK
[0m14:10:59.313007 [info ] [Thread-1 (]: 1 of 10 PASS not_null_dim_customer_customer_id ................................. [[32mPASS[0m in 0.21s]
[0m14:10:59.314693 [debug] [Thread-2 (]: On test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a: Close
[0m14:10:59.315593 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: ROLLBACK
[0m14:10:59.317142 [debug] [Thread-4 (]: On test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41: Close
[0m14:10:59.318345 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:10:59.320163 [info ] [Thread-2 (]: 2 of 10 PASS not_null_fct_daily_sales_gross_revenue ............................ [[32mPASS[0m in 0.21s]
[0m14:10:59.321527 [debug] [Thread-3 (]: On test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff: Close
[0m14:10:59.323740 [info ] [Thread-4 (]: 4 of 10 PASS not_null_fct_daily_sales_sales_date ............................... [[32mPASS[0m in 0.21s]
[0m14:10:59.325591 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:10:59.327530 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:10:59.329494 [info ] [Thread-3 (]: 3 of 10 PASS not_null_fct_daily_sales_orders ................................... [[32mPASS[0m in 0.22s]
[0m14:10:59.331032 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:10:59.332296 [info ] [Thread-1 (]: 5 of 10 START test not_null_orders_enriched_line_amount ........................ [RUN]
[0m14:10:59.333604 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:10:59.334981 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:10:59.336410 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:10:59.338467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m14:10:59.339786 [info ] [Thread-2 (]: 6 of 10 START test not_null_src_orders_order_id ................................ [RUN]
[0m14:10:59.341315 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:10:59.343577 [info ] [Thread-4 (]: 7 of 10 START test not_null_src_orders_order_line_id ........................... [RUN]
[0m14:10:59.345257 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:10:59.347181 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m14:10:59.348377 [info ] [Thread-3 (]: 8 of 10 START test not_null_src_orders_order_ts ................................ [RUN]
[0m14:10:59.350237 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m14:10:59.358557 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m14:10:59.361088 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:10:59.362810 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m14:10:59.364250 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:10:59.372476 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m14:10:59.373836 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:10:59.383358 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m14:10:59.386168 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 14:10:59.351240 => 14:10:59.385755
[0m14:10:59.394960 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m14:10:59.398337 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:10:59.404386 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m14:10:59.405986 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 14:10:59.366241 => 14:10:59.405587
[0m14:10:59.408266 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 14:10:59.386924 => 14:10:59.407650
[0m14:10:59.410691 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:10:59.411673 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 14:10:59.375299 => 14:10:59.411200
[0m14:10:59.413728 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:10:59.422789 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m14:10:59.424911 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:10:59.426766 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m14:10:59.432043 [debug] [Thread-3 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m14:10:59.439916 [debug] [Thread-4 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m14:10:59.441832 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: BEGIN
[0m14:10:59.446856 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:10:59.452580 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m14:10:59.454270 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m14:10:59.455171 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: BEGIN
[0m14:10:59.457267 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: BEGIN
[0m14:10:59.458203 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m14:10:59.458896 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.460246 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:10:59.462916 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m14:10:59.465672 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: BEGIN
[0m14:10:59.468052 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m14:10:59.473643 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m14:10:59.476881 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select line_amount
from "warehouse"."analytics_intermediate"."orders_enriched"
where line_amount is null



      
    ) dbt_internal_test
[0m14:10:59.478079 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.479331 [debug] [Thread-3 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.481544 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m14:10:59.482455 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.483544 [debug] [Thread-3 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m14:10:59.485538 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_id
from "warehouse"."analytics_staging"."src_orders"
where order_id is null



      
    ) dbt_internal_test
[0m14:10:59.487079 [debug] [Thread-4 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.489660 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 14:10:59.400514 => 14:10:59.489234
[0m14:10:59.491838 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_ts
from "warehouse"."analytics_staging"."src_orders"
where order_ts is null



      
    ) dbt_internal_test
[0m14:10:59.495718 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.496298 [debug] [Thread-4 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m14:10:59.498267 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: ROLLBACK
[0m14:10:59.503455 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 14:10:59.415494 => 14:10:59.503059
[0m14:10:59.504266 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.506201 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select order_line_id
from "warehouse"."analytics_staging"."src_orders"
where order_line_id is null



      
    ) dbt_internal_test
[0m14:10:59.508676 [debug] [Thread-1 (]: On test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655: Close
[0m14:10:59.510598 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: ROLLBACK
[0m14:10:59.515838 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 14:10:59.427333 => 14:10:59.515411
[0m14:10:59.520360 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.521718 [info ] [Thread-1 (]: 5 of 10 PASS not_null_orders_enriched_line_amount .............................. [[32mPASS[0m in 0.18s]
[0m14:10:59.523253 [debug] [Thread-2 (]: On test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d: Close
[0m14:10:59.524452 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: ROLLBACK
[0m14:10:59.526620 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 14:10:59.436133 => 14:10:59.526374
[0m14:10:59.527901 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:10:59.529387 [info ] [Thread-2 (]: 6 of 10 PASS not_null_src_orders_order_id ...................................... [[32mPASS[0m in 0.18s]
[0m14:10:59.530398 [debug] [Thread-3 (]: On test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992: Close
[0m14:10:59.531287 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: ROLLBACK
[0m14:10:59.532322 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:10:59.533488 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:10:59.535386 [info ] [Thread-3 (]: 8 of 10 PASS not_null_src_orders_order_ts ...................................... [[32mPASS[0m in 0.17s]
[0m14:10:59.537767 [debug] [Thread-4 (]: On test.sales_analytics.not_null_src_orders_order_line_id.c30084a184: Close
[0m14:10:59.538713 [info ] [Thread-1 (]: 9 of 10 START test not_null_src_orders_quantity ................................ [RUN]
[0m14:10:59.539913 [debug] [Thread-2 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:10:59.541384 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:10:59.543398 [info ] [Thread-4 (]: 7 of 10 PASS not_null_src_orders_order_line_id ................................. [[32mPASS[0m in 0.19s]
[0m14:10:59.544701 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m14:10:59.545902 [info ] [Thread-2 (]: 10 of 10 START test unique_fct_daily_sales_sales_date .......................... [RUN]
[0m14:10:59.548000 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:10:59.548903 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:10:59.550206 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m14:10:59.557597 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m14:10:59.558604 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:10:59.569140 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m14:10:59.573459 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 14:10:59.551601 => 14:10:59.572989
[0m14:10:59.574768 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:10:59.579274 [debug] [Thread-1 (]: Writing runtime sql for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m14:10:59.581586 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 14:10:59.560321 => 14:10:59.581286
[0m14:10:59.582919 [debug] [Thread-2 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:10:59.586885 [debug] [Thread-2 (]: Writing runtime sql for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m14:10:59.593875 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m14:10:59.595288 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: BEGIN
[0m14:10:59.596213 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m14:10:59.597127 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m14:10:59.598067 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: BEGIN
[0m14:10:59.599728 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m14:10:59.605497 [debug] [Thread-1 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.606884 [debug] [Thread-1 (]: Using postgres connection "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m14:10:59.607674 [debug] [Thread-2 (]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.608749 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select quantity
from "warehouse"."analytics_staging"."src_orders"
where quantity is null



      
    ) dbt_internal_test
[0m14:10:59.609759 [debug] [Thread-2 (]: Using postgres connection "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m14:10:59.611382 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "node_id": "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    sales_date as unique_field,
    count(*) as n_records

from "warehouse"."analytics_marts"."fct_daily_sales"
where sales_date is not null
group by sales_date
having count(*) > 1



      
    ) dbt_internal_test
[0m14:10:59.612323 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.615022 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 14:10:59.576124 => 14:10:59.614689
[0m14:10:59.615530 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.0 seconds
[0m14:10:59.616397 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: ROLLBACK
[0m14:10:59.618772 [debug] [Thread-2 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 14:10:59.584246 => 14:10:59.618487
[0m14:10:59.620088 [debug] [Thread-1 (]: On test.sales_analytics.not_null_src_orders_quantity.741e0fed47: Close
[0m14:10:59.621194 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: ROLLBACK
[0m14:10:59.623082 [info ] [Thread-1 (]: 9 of 10 PASS not_null_src_orders_quantity ...................................... [[32mPASS[0m in 0.08s]
[0m14:10:59.624345 [debug] [Thread-2 (]: On test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb: Close
[0m14:10:59.625568 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:10:59.627503 [info ] [Thread-2 (]: 10 of 10 PASS unique_fct_daily_sales_sales_date ................................ [[32mPASS[0m in 0.08s]
[0m14:10:59.629521 [debug] [Thread-2 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:10:59.632543 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:59.633348 [debug] [MainThread]: On master: BEGIN
[0m14:10:59.634094 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m14:10:59.642279 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:10:59.643580 [debug] [MainThread]: On master: COMMIT
[0m14:10:59.644491 [debug] [MainThread]: Using postgres connection "master"
[0m14:10:59.645287 [debug] [MainThread]: On master: COMMIT
[0m14:10:59.646252 [debug] [MainThread]: SQL status: COMMIT in 0.0 seconds
[0m14:10:59.647176 [debug] [MainThread]: On master: Close
[0m14:10:59.648626 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:10:59.649424 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992' was properly closed.
[0m14:10:59.650196 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_order_line_id.c30084a184' was properly closed.
[0m14:10:59.650960 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_src_orders_quantity.741e0fed47' was properly closed.
[0m14:10:59.651701 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m14:10:59.652576 [info ] [MainThread]: 
[0m14:10:59.653748 [info ] [MainThread]: Finished running 10 tests in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m14:10:59.658193 [debug] [MainThread]: Command end result
[0m14:10:59.693939 [info ] [MainThread]: 
[0m14:10:59.695655 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:10:59.697466 [info ] [MainThread]: 
[0m14:10:59.698982 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=0 SKIP=0 TOTAL=10
[0m14:10:59.701118 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.4189817, "process_user_time": 4.334968, "process_kernel_time": 0.178966, "process_mem_max_rss": "121972", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:10:59.702703 [debug] [MainThread]: Command `dbt test` succeeded at 14:10:59.702455 after 1.42 seconds
[0m14:10:59.704117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc8d7fe50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc8d7fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcc417e0d0>]}
[0m14:10:59.705732 [debug] [MainThread]: Flushing usage events
[0m14:11:05.487167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89790e4090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89790e6690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89790e7410>]}


============================== 14:11:05.496479 | b1c18708-a571-4971-bf6a-631eb6624fcd ==============================
[0m14:11:05.496479 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:11:05.497832 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m14:11:05.774744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b1c18708-a571-4971-bf6a-631eb6624fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8978594310>]}
[0m14:11:05.889636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b1c18708-a571-4971-bf6a-631eb6624fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8978595a50>]}
[0m14:11:05.892264 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m14:11:05.910506 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m14:11:06.063825 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:11:06.065292 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:11:06.075079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b1c18708-a571-4971-bf6a-631eb6624fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8977da0990>]}
[0m14:11:06.090659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b1c18708-a571-4971-bf6a-631eb6624fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8977db2bd0>]}
[0m14:11:06.092311 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:11:06.093931 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1c18708-a571-4971-bf6a-631eb6624fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f89785f3c90>]}
[0m14:11:06.099804 [info ] [MainThread]: 
[0m14:11:06.103782 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:11:06.111352 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m14:11:06.113695 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m14:11:06.115512 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m14:11:06.117911 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m14:11:06.149025 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:11:06.157708 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:11:06.163563 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:11:06.169200 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:11:06.171284 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m14:11:06.174095 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m14:11:06.176563 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m14:11:06.178853 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m14:11:06.180770 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:06.182709 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:06.184369 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:06.185958 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:06.213434 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:11:06.214150 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:11:06.215358 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:11:06.215880 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:11:06.216468 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:11:06.218097 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:11:06.219976 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:11:06.221194 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:11:06.222357 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m14:11:06.223451 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m14:11:06.224540 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m14:11:06.225584 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m14:11:06.231006 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:11:06.231550 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:11:06.234192 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m14:11:06.235032 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m14:11:06.235639 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:11:06.238130 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m14:11:06.240461 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m14:11:06.245273 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m14:11:06.248737 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m14:11:06.251219 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m14:11:06.255063 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m14:11:06.256344 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m14:11:06.270213 [debug] [MainThread]: Using postgres connection "master"
[0m14:11:06.272313 [debug] [MainThread]: On master: BEGIN
[0m14:11:06.274793 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:11:06.285482 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:11:06.287634 [debug] [MainThread]: Using postgres connection "master"
[0m14:11:06.289426 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:11:06.298489 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:11:06.302528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b1c18708-a571-4971-bf6a-631eb6624fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8979d596d0>]}
[0m14:11:06.304969 [debug] [MainThread]: On master: ROLLBACK
[0m14:11:06.307062 [debug] [MainThread]: On master: Close
[0m14:11:06.309363 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:11:06.311128 [info ] [MainThread]: 
[0m14:11:06.326638 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m14:11:06.328855 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now model.sales_analytics.src_orders)
[0m14:11:06.330319 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m14:11:06.344127 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m14:11:06.360005 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 14:11:06.331482 => 14:11:06.359459
[0m14:11:06.361323 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m14:11:06.362777 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 14:11:06.362313 => 14:11:06.362341
[0m14:11:06.365120 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m14:11:06.367700 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m14:11:06.368572 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m14:11:06.369284 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:11:06.370666 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:11:06.372419 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m14:11:06.374132 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m14:11:06.376081 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m14:11:06.377632 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m14:11:06.378851 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m14:11:06.380221 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m14:11:06.381998 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:11:06.383532 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:11:06.388505 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m14:11:06.394322 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 14:11:06.389572 => 14:11:06.393974
[0m14:11:06.415602 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m14:11:06.421881 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m14:11:06.423923 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m14:11:06.427803 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 14:11:06.427355 => 14:11:06.427392
[0m14:11:06.430387 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m14:11:06.431691 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 14:11:06.416067 => 14:11:06.431321
[0m14:11:06.432357 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:11:06.432942 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 14:11:06.384584 => 14:11:06.432679
[0m14:11:06.434335 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 14:11:06.395874 => 14:11:06.434042
[0m14:11:06.434831 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:11:06.436913 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m14:11:06.438646 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m14:11:06.440392 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:11:06.442531 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 14:11:06.442198 => 14:11:06.442218
[0m14:11:06.444198 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:11:06.445716 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 14:11:06.445251 => 14:11:06.445264
[0m14:11:06.447139 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 14:11:06.446769 => 14:11:06.446781
[0m14:11:06.449391 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:11:06.456673 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m14:11:06.458574 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m14:11:06.461442 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:11:06.463242 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:11:06.465534 [debug] [Thread-3 (]: Began running node model.sales_analytics.dim_customer
[0m14:11:06.467322 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m14:11:06.469028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m14:11:06.470805 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now model.sales_analytics.dim_customer)
[0m14:11:06.472452 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.fct_daily_sales)
[0m14:11:06.473152 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 14:11:06.450838 => 14:11:06.472880
[0m14:11:06.474331 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:11:06.475571 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.dim_customer
[0m14:11:06.476647 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m14:11:06.477975 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:11:06.486212 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m14:11:06.493394 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m14:11:06.515303 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m14:11:06.516199 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 14:11:06.515850 => 14:11:06.515871
[0m14:11:06.522292 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:11:06.523623 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:11:06.525532 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m14:11:06.527261 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:11:06.535479 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 14:11:06.478814 => 14:11:06.534579
[0m14:11:06.540722 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m14:11:06.541811 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (compile): 14:11:06.487589 => 14:11:06.541441
[0m14:11:06.542517 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 14:11:06.494835 => 14:11:06.542162
[0m14:11:06.543883 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:11:06.547564 [debug] [Thread-3 (]: Began executing node model.sales_analytics.dim_customer
[0m14:11:06.549466 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m14:11:06.551528 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 14:11:06.551005 => 14:11:06.551031
[0m14:11:06.554720 [debug] [Thread-3 (]: Timing info for model.sales_analytics.dim_customer (execute): 14:11:06.553555 => 14:11:06.553591
[0m14:11:06.556936 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 14:11:06.556528 => 14:11:06.556547
[0m14:11:06.559737 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:11:06.562092 [debug] [Thread-3 (]: Finished running node model.sales_analytics.dim_customer
[0m14:11:06.563442 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 14:11:06.529181 => 14:11:06.562950
[0m14:11:06.565499 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m14:11:06.569468 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:11:06.572010 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:11:06.574951 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:11:06.575555 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:11:06.577823 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m14:11:06.579688 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 14:11:06.579285 => 14:11:06.579299
[0m14:11:06.581863 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m14:11:06.584362 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m14:11:06.586181 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:11:06.588594 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:11:06.590633 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:11:06.592627 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:11:06.603062 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m14:11:06.604854 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:11:06.614719 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m14:11:06.625401 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m14:11:06.629304 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m14:11:06.633727 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:11:06.642559 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 14:11:06.606701 => 14:11:06.641917
[0m14:11:06.643453 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 14:11:06.594137 => 14:11:06.643049
[0m14:11:06.646241 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m14:11:06.647094 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 14:11:06.616330 => 14:11:06.646709
[0m14:11:06.648373 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:11:06.650544 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:11:06.653725 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:11:06.655529 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 14:11:06.655143 => 14:11:06.655162
[0m14:11:06.656884 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 14:11:06.656532 => 14:11:06.656545
[0m14:11:06.658327 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 14:11:06.658008 => 14:11:06.658020
[0m14:11:06.660830 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:11:06.664048 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:11:06.664903 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 14:11:06.636477 => 14:11:06.664553
[0m14:11:06.666887 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:11:06.669244 [debug] [Thread-3 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:11:06.671714 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:11:06.674163 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m14:11:06.675507 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 14:11:06.675138 => 14:11:06.675150
[0m14:11:06.677278 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:11:06.680313 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:11:06.694808 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m14:11:06.722632 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 14:11:06.681966 => 14:11:06.721970
[0m14:11:06.724222 [debug] [Thread-3 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:11:06.726044 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 14:11:06.725486 => 14:11:06.725510
[0m14:11:06.728668 [debug] [Thread-3 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:11:06.732132 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:11:06.733489 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m14:11:06.735245 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m14:11:06.736643 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m14:11:06.738043 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff' was properly closed.
[0m14:11:06.743466 [debug] [MainThread]: Command end result
[0m14:11:06.824116 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m14:11:06.825927 [info ] [MainThread]: Building catalog
[0m14:11:06.831009 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m14:11:06.848222 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m14:11:06.849808 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m14:11:06.852058 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:11:06.862563 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:11:06.864236 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m14:11:06.866149 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m14:11:06.875506 [debug] [ThreadPool]: SQL status: SELECT 41 in 0.0 seconds
[0m14:11:06.889400 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m14:11:06.891135 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m14:11:06.946325 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m14:11:06.951798 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.5377425, "process_user_time": 4.116325, "process_kernel_time": 0.303102, "process_mem_max_rss": "121564", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:11:06.954454 [debug] [MainThread]: Command `dbt docs generate` succeeded at 14:11:06.954046 after 1.54 seconds
[0m14:11:06.956343 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m14:11:06.958809 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m14:11:06.960421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8979143510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8979143890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f897dcecf50>]}
[0m14:11:06.962095 [debug] [MainThread]: Flushing usage events
[0m14:30:16.643601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c50873d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c5085d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c50864d0>]}


============================== 14:30:16.651768 | 96cce6b8-063d-472f-8a14-79fd469d89b0 ==============================
[0m14:30:16.651768 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:30:16.652941 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/usr/app', 'log_path': '/usr/app/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt docs generate', 'send_anonymous_usage_stats': 'True'}
[0m14:30:16.875228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '96cce6b8-063d-472f-8a14-79fd469d89b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c4b7a250>]}
[0m14:30:16.975481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '96cce6b8-063d-472f-8a14-79fd469d89b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c4b21ad0>]}
[0m14:30:16.978247 [info ] [MainThread]: Registered adapter: postgres=1.7.11
[0m14:30:17.038665 [debug] [MainThread]: checksum: 1b58ec263fbd34ee8091684d6a2f6c1ad2902b1459e632a74eb63768af36ddb7, vars: {}, profile: , target: , version: 1.7.11
[0m14:30:17.172427 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:30:17.174440 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:30:17.182306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96cce6b8-063d-472f-8a14-79fd469d89b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c50d2510>]}
[0m14:30:17.203530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96cce6b8-063d-472f-8a14-79fd469d89b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c43c93d0>]}
[0m14:30:17.205070 [info ] [MainThread]: Found 4 models, 1 snapshot, 10 tests, 0 sources, 0 exposures, 0 metrics, 401 macros, 0 groups, 0 semantic models
[0m14:30:17.206283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96cce6b8-063d-472f-8a14-79fd469d89b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c4b67390>]}
[0m14:30:17.209320 [info ] [MainThread]: 
[0m14:30:17.211093 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m14:30:17.213445 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_intermediate'
[0m14:30:17.214699 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_marts'
[0m14:30:17.215865 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_analytics_staging'
[0m14:30:17.227910 [debug] [ThreadPool]: Acquiring new postgres connection 'list_warehouse_snapshots'
[0m14:30:17.230968 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:30:17.234862 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:30:17.238380 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:30:17.241953 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:30:17.243296 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: BEGIN
[0m14:30:17.244454 [debug] [ThreadPool]: On list_warehouse_analytics_marts: BEGIN
[0m14:30:17.245533 [debug] [ThreadPool]: On list_warehouse_analytics_staging: BEGIN
[0m14:30:17.246691 [debug] [ThreadPool]: On list_warehouse_snapshots: BEGIN
[0m14:30:17.247908 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:17.248928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:17.250001 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:17.251594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:17.267806 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:17.268502 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:17.268929 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:17.269298 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:17.270056 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_staging"
[0m14:30:17.271659 [debug] [ThreadPool]: Using postgres connection "list_warehouse_snapshots"
[0m14:30:17.273303 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_marts"
[0m14:30:17.275486 [debug] [ThreadPool]: Using postgres connection "list_warehouse_analytics_intermediate"
[0m14:30:17.276936 [debug] [ThreadPool]: On list_warehouse_analytics_staging: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_staging"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_staging'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_staging'
  
[0m14:30:17.278479 [debug] [ThreadPool]: On list_warehouse_snapshots: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_snapshots"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'snapshots'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'snapshots'
  
[0m14:30:17.280402 [debug] [ThreadPool]: On list_warehouse_analytics_marts: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_marts"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_marts'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_marts'
  
[0m14:30:17.281724 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "list_warehouse_analytics_intermediate"} */
select
      'warehouse' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'analytics_intermediate'
    union all
    select
      'warehouse' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'analytics_intermediate'
  
[0m14:30:17.287929 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:17.288554 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:17.289036 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:17.289516 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.0 seconds
[0m14:30:17.291631 [debug] [ThreadPool]: On list_warehouse_snapshots: ROLLBACK
[0m14:30:17.294164 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: ROLLBACK
[0m14:30:17.296408 [debug] [ThreadPool]: On list_warehouse_analytics_staging: ROLLBACK
[0m14:30:17.299201 [debug] [ThreadPool]: On list_warehouse_analytics_marts: ROLLBACK
[0m14:30:17.300821 [debug] [ThreadPool]: On list_warehouse_snapshots: Close
[0m14:30:17.301831 [debug] [ThreadPool]: On list_warehouse_analytics_intermediate: Close
[0m14:30:17.302322 [debug] [ThreadPool]: On list_warehouse_analytics_staging: Close
[0m14:30:17.303598 [debug] [ThreadPool]: On list_warehouse_analytics_marts: Close
[0m14:30:17.315208 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:17.316694 [debug] [MainThread]: On master: BEGIN
[0m14:30:17.317964 [debug] [MainThread]: Opening a new connection, currently in state init
[0m14:30:17.324510 [debug] [MainThread]: SQL status: BEGIN in 0.0 seconds
[0m14:30:17.325731 [debug] [MainThread]: Using postgres connection "master"
[0m14:30:17.326895 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m14:30:17.332825 [debug] [MainThread]: SQL status: SELECT 1 in 0.0 seconds
[0m14:30:17.335902 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96cce6b8-063d-472f-8a14-79fd469d89b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c4b48490>]}
[0m14:30:17.337614 [debug] [MainThread]: On master: ROLLBACK
[0m14:30:17.339202 [debug] [MainThread]: On master: Close
[0m14:30:17.341026 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m14:30:17.342219 [info ] [MainThread]: 
[0m14:30:17.354224 [debug] [Thread-1 (]: Began running node model.sales_analytics.src_orders
[0m14:30:17.356265 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_marts, now model.sales_analytics.src_orders)
[0m14:30:17.358010 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.src_orders
[0m14:30:17.366277 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.src_orders"
[0m14:30:17.376155 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (compile): 14:30:17.359155 => 14:30:17.375783
[0m14:30:17.377193 [debug] [Thread-1 (]: Began executing node model.sales_analytics.src_orders
[0m14:30:17.378337 [debug] [Thread-1 (]: Timing info for model.sales_analytics.src_orders (execute): 14:30:17.378071 => 14:30:17.378092
[0m14:30:17.379826 [debug] [Thread-1 (]: Finished running node model.sales_analytics.src_orders
[0m14:30:17.382465 [debug] [Thread-3 (]: Began running node model.sales_analytics.orders_enriched
[0m14:30:17.384400 [debug] [Thread-4 (]: Began running node snapshot.sales_analytics.customers_snapshot
[0m14:30:17.385091 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:30:17.385692 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:30:17.386812 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_intermediate, now model.sales_analytics.orders_enriched)
[0m14:30:17.388137 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly list_warehouse_snapshots, now snapshot.sales_analytics.customers_snapshot)
[0m14:30:17.389696 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_warehouse_analytics_staging, now test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d)
[0m14:30:17.391207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.src_orders, now test.sales_analytics.not_null_src_orders_order_line_id.c30084a184)
[0m14:30:17.392380 [debug] [Thread-3 (]: Began compiling node model.sales_analytics.orders_enriched
[0m14:30:17.393508 [debug] [Thread-4 (]: Began compiling node snapshot.sales_analytics.customers_snapshot
[0m14:30:17.394627 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:30:17.395744 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:30:17.401142 [debug] [Thread-3 (]: Writing injected SQL for node "model.sales_analytics.orders_enriched"
[0m14:30:17.405730 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (compile): 14:30:17.402257 => 14:30:17.405454
[0m14:30:17.422388 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d"
[0m14:30:17.427929 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_line_id.c30084a184"
[0m14:30:17.429737 [debug] [Thread-4 (]: Began executing node snapshot.sales_analytics.customers_snapshot
[0m14:30:17.432481 [debug] [Thread-4 (]: Timing info for snapshot.sales_analytics.customers_snapshot (execute): 14:30:17.432173 => 14:30:17.432195
[0m14:30:17.434619 [debug] [Thread-4 (]: Finished running node snapshot.sales_analytics.customers_snapshot
[0m14:30:17.436683 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:30:17.437651 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (compile): 14:30:17.396905 => 14:30:17.437267
[0m14:30:17.438500 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (compile): 14:30:17.423390 => 14:30:17.438224
[0m14:30:17.439205 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (compile): 14:30:17.406573 => 14:30:17.438946
[0m14:30:17.440023 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly snapshot.sales_analytics.customers_snapshot, now test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992)
[0m14:30:17.441291 [debug] [Thread-3 (]: Began executing node model.sales_analytics.orders_enriched
[0m14:30:17.442380 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:30:17.443538 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:30:17.444492 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:30:17.445717 [debug] [Thread-3 (]: Timing info for model.sales_analytics.orders_enriched (execute): 14:30:17.445435 => 14:30:17.445451
[0m14:30:17.446921 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_src_orders_order_line_id.c30084a184 (execute): 14:30:17.446630 => 14:30:17.446642
[0m14:30:17.447942 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d (execute): 14:30:17.447697 => 14:30:17.447708
[0m14:30:17.454108 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992"
[0m14:30:17.455798 [debug] [Thread-3 (]: Finished running node model.sales_analytics.orders_enriched
[0m14:30:17.457441 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_src_orders_order_line_id.c30084a184
[0m14:30:17.459091 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d
[0m14:30:17.460646 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:30:17.462498 [debug] [Thread-1 (]: Began running node model.sales_analytics.dim_customer
[0m14:30:17.464219 [debug] [Thread-2 (]: Began running node model.sales_analytics.fct_daily_sales
[0m14:30:17.466355 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.sales_analytics.orders_enriched, now test.sales_analytics.not_null_src_orders_quantity.741e0fed47)
[0m14:30:17.467998 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_line_id.c30084a184, now model.sales_analytics.dim_customer)
[0m14:30:17.469619 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_id.f41efd8d8d, now model.sales_analytics.fct_daily_sales)
[0m14:30:17.470857 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:30:17.471776 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (compile): 14:30:17.448695 => 14:30:17.471339
[0m14:30:17.472864 [debug] [Thread-1 (]: Began compiling node model.sales_analytics.dim_customer
[0m14:30:17.473900 [debug] [Thread-2 (]: Began compiling node model.sales_analytics.fct_daily_sales
[0m14:30:17.483120 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_src_orders_quantity.741e0fed47"
[0m14:30:17.484463 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:30:17.490086 [debug] [Thread-1 (]: Writing injected SQL for node "model.sales_analytics.dim_customer"
[0m14:30:17.505293 [debug] [Thread-2 (]: Writing injected SQL for node "model.sales_analytics.fct_daily_sales"
[0m14:30:17.508441 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992 (execute): 14:30:17.508133 => 14:30:17.508150
[0m14:30:17.512882 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992
[0m14:30:17.514405 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:30:17.515366 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (compile): 14:30:17.485570 => 14:30:17.514953
[0m14:30:17.517466 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_order_ts.c2e6fd0992, now test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655)
[0m14:30:17.518287 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (compile): 14:30:17.491197 => 14:30:17.517893
[0m14:30:17.518979 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (compile): 14:30:17.474784 => 14:30:17.518665
[0m14:30:17.520244 [debug] [Thread-1 (]: Began executing node model.sales_analytics.dim_customer
[0m14:30:17.521997 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:30:17.523644 [debug] [Thread-2 (]: Began executing node model.sales_analytics.fct_daily_sales
[0m14:30:17.525269 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:30:17.526707 [debug] [Thread-1 (]: Timing info for model.sales_analytics.dim_customer (execute): 14:30:17.526416 => 14:30:17.526429
[0m14:30:17.533876 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655"
[0m14:30:17.535249 [debug] [Thread-2 (]: Timing info for model.sales_analytics.fct_daily_sales (execute): 14:30:17.534935 => 14:30:17.534950
[0m14:30:17.536962 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_src_orders_quantity.741e0fed47 (execute): 14:30:17.536689 => 14:30:17.536698
[0m14:30:17.539206 [debug] [Thread-1 (]: Finished running node model.sales_analytics.dim_customer
[0m14:30:17.542560 [debug] [Thread-2 (]: Finished running node model.sales_analytics.fct_daily_sales
[0m14:30:17.544528 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_src_orders_quantity.741e0fed47
[0m14:30:17.546431 [debug] [Thread-1 (]: Began running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:30:17.547859 [debug] [Thread-2 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:30:17.548638 [debug] [Thread-3 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:30:17.550062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sales_analytics.dim_customer, now test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc)
[0m14:30:17.551467 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.sales_analytics.fct_daily_sales, now test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a)
[0m14:30:17.552178 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (compile): 14:30:17.527688 => 14:30:17.551903
[0m14:30:17.553547 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_src_orders_quantity.741e0fed47, now test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff)
[0m14:30:17.554506 [debug] [Thread-1 (]: Began compiling node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:30:17.555413 [debug] [Thread-2 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:30:17.556385 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:30:17.557422 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:30:17.563504 [debug] [Thread-1 (]: Writing injected SQL for node "test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc"
[0m14:30:17.568932 [debug] [Thread-2 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a"
[0m14:30:17.570864 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655 (execute): 14:30:17.570594 => 14:30:17.570606
[0m14:30:17.577469 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff"
[0m14:30:17.581921 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655
[0m14:30:17.584014 [debug] [Thread-4 (]: Began running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:30:17.585183 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_orders_enriched_line_amount.3f24914655, now test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41)
[0m14:30:17.586458 [debug] [Thread-4 (]: Began compiling node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:30:17.587051 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (compile): 14:30:17.572816 => 14:30:17.586762
[0m14:30:17.587711 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (compile): 14:30:17.564175 => 14:30:17.587376
[0m14:30:17.593587 [debug] [Thread-4 (]: Writing injected SQL for node "test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41"
[0m14:30:17.594155 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (compile): 14:30:17.558166 => 14:30:17.593898
[0m14:30:17.595410 [debug] [Thread-3 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:30:17.596648 [debug] [Thread-2 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:30:17.598487 [debug] [Thread-1 (]: Began executing node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:30:17.599495 [debug] [Thread-3 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff (execute): 14:30:17.599246 => 14:30:17.599257
[0m14:30:17.600460 [debug] [Thread-2 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a (execute): 14:30:17.600220 => 14:30:17.600228
[0m14:30:17.601400 [debug] [Thread-1 (]: Timing info for test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc (execute): 14:30:17.601170 => 14:30:17.601178
[0m14:30:17.602741 [debug] [Thread-3 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff
[0m14:30:17.604202 [debug] [Thread-2 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a
[0m14:30:17.604759 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (compile): 14:30:17.588367 => 14:30:17.604490
[0m14:30:17.606069 [debug] [Thread-1 (]: Finished running node test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc
[0m14:30:17.606942 [debug] [Thread-3 (]: Began running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:30:17.608237 [debug] [Thread-4 (]: Began executing node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:30:17.609832 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.sales_analytics.not_null_fct_daily_sales_orders.fcde23d7ff, now test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb)
[0m14:30:17.610776 [debug] [Thread-4 (]: Timing info for test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41 (execute): 14:30:17.610539 => 14:30:17.610547
[0m14:30:17.611600 [debug] [Thread-3 (]: Began compiling node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:30:17.613068 [debug] [Thread-4 (]: Finished running node test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41
[0m14:30:17.621227 [debug] [Thread-3 (]: Writing injected SQL for node "test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb"
[0m14:30:17.629632 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (compile): 14:30:17.613996 => 14:30:17.629311
[0m14:30:17.630624 [debug] [Thread-3 (]: Began executing node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:30:17.631703 [debug] [Thread-3 (]: Timing info for test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb (execute): 14:30:17.631405 => 14:30:17.631417
[0m14:30:17.633173 [debug] [Thread-3 (]: Finished running node test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb
[0m14:30:17.635348 [debug] [MainThread]: Connection 'master' was properly closed.
[0m14:30:17.636140 [debug] [MainThread]: Connection 'test.sales_analytics.unique_fct_daily_sales_sales_date.a576eeebfb' was properly closed.
[0m14:30:17.636882 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_dim_customer_customer_id.9775012dfc' was properly closed.
[0m14:30:17.637579 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_gross_revenue.2d27f9f22a' was properly closed.
[0m14:30:17.638228 [debug] [MainThread]: Connection 'test.sales_analytics.not_null_fct_daily_sales_sales_date.1b27eeef41' was properly closed.
[0m14:30:17.640799 [debug] [MainThread]: Command end result
[0m14:30:17.688166 [debug] [MainThread]: Acquiring new postgres connection 'generate_catalog'
[0m14:30:17.689188 [info ] [MainThread]: Building catalog
[0m14:30:17.693949 [debug] [ThreadPool]: Acquiring new postgres connection 'warehouse.information_schema'
[0m14:30:17.705225 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m14:30:17.706705 [debug] [ThreadPool]: On warehouse.information_schema: BEGIN
[0m14:30:17.707710 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:17.717625 [debug] [ThreadPool]: SQL status: BEGIN in 0.0 seconds
[0m14:30:17.719017 [debug] [ThreadPool]: Using postgres connection "warehouse.information_schema"
[0m14:30:17.720280 [debug] [ThreadPool]: On warehouse.information_schema: /* {"app": "dbt", "dbt_version": "1.7.11", "profile_name": "sales_analytics", "target_name": "dev", "connection_name": "warehouse.information_schema"} */

    
    

    select
        'warehouse' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            when 'm' then 'MATERIALIZED VIEW'
            else 'BASE TABLE'
        end as table_type,
        tbl_desc.description as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        col_desc.description as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid
    left outer join pg_catalog.pg_description tbl_desc on (tbl_desc.objoid = tbl.oid and tbl_desc.objsubid = 0)
    left outer join pg_catalog.pg_description col_desc on (col_desc.objoid = tbl.oid and col_desc.objsubid = col.attnum)
    where ((upper(sch.nspname) = upper('snapshots') and
           upper(tbl.relname) = upper('customers_snapshot')) or (upper(sch.nspname) = upper('analytics_staging') and
           upper(tbl.relname) = upper('src_orders')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('dim_customer')) or (upper(sch.nspname) = upper('analytics_intermediate') and
           upper(tbl.relname) = upper('orders_enriched')) or (upper(sch.nspname) = upper('analytics_marts') and
           upper(tbl.relname) = upper('fct_daily_sales')))
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence in ('p', 'u') -- [p]ermanent table or [u]nlogged table. Exclude [t]emporary tables
      and tbl.relkind in ('r', 'v', 'f', 'p', 'm') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table, [m]aterialized view. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
[0m14:30:17.726501 [debug] [ThreadPool]: SQL status: SELECT 41 in 0.0 seconds
[0m14:30:17.735453 [debug] [ThreadPool]: On warehouse.information_schema: ROLLBACK
[0m14:30:17.738115 [debug] [ThreadPool]: On warehouse.information_schema: Close
[0m14:30:17.779993 [info ] [MainThread]: Catalog written to /usr/app/target/catalog.json
[0m14:30:17.783034 [debug] [MainThread]: Resource report: {"command_name": "generate", "command_success": true, "command_wall_clock_time": 1.2063686, "process_user_time": 3.561259, "process_kernel_time": 0.706283, "process_mem_max_rss": "121440", "process_in_blocks": "0", "process_out_blocks": "0"}
[0m14:30:17.784698 [debug] [MainThread]: Command `dbt docs generate` succeeded at 14:30:17.784475 after 1.21 seconds
[0m14:30:17.786051 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
[0m14:30:17.787373 [debug] [MainThread]: Connection 'warehouse.information_schema' was properly closed.
[0m14:30:17.788937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c50e3690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c7d3ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f12c5115310>]}
[0m14:30:17.790843 [debug] [MainThread]: Flushing usage events
[0m14:30:21.388005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f739a60ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f739aa69190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f739a606590>]}


============================== 14:30:21.394732 | 517fec93-1905-4618-825f-3e9c313a9d60 ==============================
[0m14:30:21.394732 [info ] [MainThread]: Running with dbt=1.7.11
[0m14:30:21.396087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/usr/app', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/usr/app/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt docs serve --port 8080', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m14:30:21.592942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '517fec93-1905-4618-825f-3e9c313a9d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f739a606750>]}
[0m14:30:21.701025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '517fec93-1905-4618-825f-3e9c313a9d60', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7399d4fa90>]}
[0m14:51:22.314743 [error] [MainThread]: Encountered an error:

[0m14:51:22.325569 [error] [MainThread]: Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 91, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 76, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 169, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 198, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/requires.py", line 245, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/cli/main.py", line 324, in docs_serve
    results = task.run()
              ^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/dbt/task/serve.py", line 28, in run
    httpd.serve_forever()
  File "/usr/local/lib/python3.11/socketserver.py", line 233, in serve_forever
    ready = selector.select(poll_interval)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

[0m14:51:22.331750 [debug] [MainThread]: Resource report: {"command_name": "serve", "command_wall_clock_time": 1261.0186, "process_user_time": 3.418491, "process_kernel_time": 0.253597, "process_mem_max_rss": "111620", "process_in_blocks": "8", "command_success": false, "process_out_blocks": "0"}
[0m14:51:22.337402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f739a61ef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f739a613090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f739a613a90>]}
[0m14:51:22.339603 [debug] [MainThread]: Flushing usage events
